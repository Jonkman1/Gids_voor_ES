[
  {
    "objectID": "index.html#welkom",
    "href": "index.html#welkom",
    "title": "Gids voor Effect Sizes en Betrouwbaarheids Intervallen",
    "section": "Welkom",
    "text": "Welkom\nDeze gids voor samenwerking op het gebied van effect sizes en betrouwbaarheidsintervallen is bedoeld om academici, studenten en onderzoekers te voorzien van praktische, stapsgewijze instructies. Hij is er voor het berekenen van effect sizes en betrouwbaarheidsintervallen voor veelgebruikte statistische toetsen in de gedrags-, cognitieve en sociale wetenschappen, met name wanneer originele gegevens niet beschikbaar zijn en wanneer gerapporteerde informatie onvolledig is. De gids introduceert ook algemene achtergrondinformatie over effect sizes en betrouwbaarheidsintervallen, evenals nuttige R-pakketten voor de berekening ervan. Veel van de methoden en procedures die in deze gids worden beschreven, zijn gebaseerd op R of op R gebaseerde Shiny Apps die zijn ontwikkeld door de wetenschappelijke gemeenschap. We waren gemotiveerd om ons op R te richten omdat we de reproduceerbaarheid van onze onderzoeksresultaten willen maximaliseren en de meest reproduceerbare onderzoeksplanning en data-analyse workflow willen aanmoedigen, hoewel we waar mogelijk ook andere methoden documenteren ter referentie van onze lezers. We werken deze open educatieve bron regelmatig bij, omdat pakketten vaak worden bijgewerkt en er van tijd tot tijd nieuwe pakketten worden ontwikkeld in dit snel veranderende Open Scholarship-tijdperk."
  },
  {
    "objectID": "index.html#introductie",
    "href": "index.html#introductie",
    "title": "Gids voor Effect Sizes en Betrouwbaarheids Intervallen",
    "section": "Introductie",
    "text": "Introductie\nEffect sizes en betrouwbaarheidsintervallen zijn belangrijke maatstaven voor het interpreteren van resultaten en het kwantificeren van de omvang van bevindingen in wetenschappelijk onderzoek. Het berekenen van deze waarden kan echter een uitdaging zijn, vooral wanneer originele gegevens niet beschikbaar zijn of wanneer resultaten onvolledig zijn gerapporteerd in eerdere publicaties. Om in deze behoefte te voorzien biedt onze gezamenlijke gids praktische instructies voor het berekenen van effect sizes en betrouwbaarheidsintervallen voor veelvoorkomende statistische toetsen in de gedrags-, cognitieve en sociale wetenschappen. Onze gids bevat achtergrondinformatie over deze concepten en aanbevelingen voor nuttige R-pakketten die veel van deze berekeningen kunnen automatiseren. De nadruk ligt op R vanwege de mogelijkheden voor reproduceerbare analyses, maar we behandelen ook alternatieve methoden voor mensen zonder expertise in R. Deze gids is bedoeld als een evoluerende open educatieve bron, die wordt bijgewerkt als er nieuwe methoden en pakketten beschikbaar komen in dit snel veranderende tijdperk van open wetenschap. Door deze toegepaste instructies te compileren, is het ons doel om studenten en onderzoekers in staat te stellen deze metrieken gemakkelijk te verkrijgen, wat robuuste en transparante kwantificering van resultaten en cumulatieve wetenschappelijke vooruitgang mogelijk maakt.\n\nRichtlijnen voor bijdrage\nIedereen wordt aangemoedigd om bij te dragen aan deze gids. Houd er rekening mee dat deze gids voortdurend in ontwikkeling is en dus voor onbepaalde tijd een werk in uitvoering zal blijven. Dit is bedoeld omdat we hopen dat de gids altijd de laatste stand van de techniek op het gebied van effectgroottes en betrouwbaarheidsintervallen weergeeft. Om bij te dragen, zijn er nu twee opties:\n\nU kunt bewerkingen voorstellen en opmerkingen maken in de volgende google doc: mgto.org/effectsizeguide.\n\nU kunt bewerkingen rechtstreeks in het online boek voorstellen met behulp van Hypothes.is. Hiervoor moet je een gratis account aanmaken op hypothes.is (hypothes.is/signup; dit duurt ongeveer een minuut). Wanneer je vervolgens naar het online boek navigeert, kun je het paneel rechtsboven in het scherm openen. Daar kun je bewerkingen voorstellen en opmerkingen maken met code en latex!\n\n\n\nOpmerkingen\n\nGebruik de koppen en stijl die in dit document worden beschreven. Je kunt sneltoetsen gebruiken zoals Ctrl + Alt + 1/2/3. De normale tekst is in het lettertype Times New Roman, lettergrootte 11. De codes zijn opgemaakt met de Code Blocks add-on van Google Docs, github-thema, lettergrootte 8.\n\nGebruik de modus Suggesting in plaats van de modus Editing. Voorstellen is nu de standaardmodus voor dit document. Aarzel daarom niet om fouten te corrigeren of de inhoud direct aan te passen.\n\nVoeg een opmerking toe aan het document als je iets mist of onjuist vindt, of als je vindt dat dingen beter op een andere manier georganiseerd kunnen worden. We stellen je suggesties op prijs. Als je vragen hebt, plaats dan ook een opmerking. We zullen antwoorden en proberen duidelijkheid te verschaffen in de hoofdtekst van het document.\n\nMaak correcte citaten (in APA 7e formaat) en geef relevante links wanneer je verwijst naar een bron die niet van jezelf is.\n\n\n\nNaamsvermelding en auteurschap\nAls u van mening bent dat u voldoende hebt bijgedragen om als auteur te worden aangemerkt en u wilt als auteur van deze gids worden vermeld, aarzel dan niet en vermeld uw naam en contactgegevens hieronder. De beheerders (M.B.J., Q.X., S.K.Y. en G.F.) van deze gids zullen uw bijdrage verifiëren en u toevoegen aan de auteurslijst. Wij verwelkomen commentaar van iedereen, ongeacht of hij of zij auteur wil zijn.\nDe volgorde van auteurschap is zodanig dat M. B. J. en Q. X. de eerste twee auteurs zijn, S. K. Y. de tweede auteur en G. F. de laatste en corresponderende auteur. Alle andere bijdragers worden alfabetisch in het midden vermeld en worden allemaal beschouwd als gezamenlijke derde auteurs. Medewerkers krijgen standaard de CRediT-auteursrollen onderzoek, schrijven - oorspronkelijke concept, en schrijven - revisie & redactie. Het is mogelijk om meer rollen op zich te nemen als deelnemers dat willen. Elke verandering in deze auteursvolgorde moet goedgekeurd worden door iedereen die al als auteur vermeld staat.\n\n\nDeze gids citeren\nCiteer deze gids als volgt:\nAPA:\nJané, M., Xiao, Q., Yeung, S., *Ben-Shachar, M. S., *Caldwell, A., *Cousineau, D., *Dunleavy, D. J., *Elsherif, M., *Johnson, B., *Moreau, D., *Riesthuis, P., *Röseler, L., *Steele, J., *Vieira, F., *Zloteanu, M., & ^Feldman, G. (2024). Guide to Effect Sizes and Confidence Intervals. http://dx.doi.org/10.17605/OSF.IO/D8C4G\nBibTeX:\n@misc{jané2024,\n  title={Guide to Effect Sizes and Confidence Intervals},\n  url={osf.io/d8c4g},\n  DOI={10.17605/OSF.IO/D8C4G},\n  publisher={OSF},\n  author={Jané, Matthew B and Xiao, Qinyu and Yeung, Siu Kit and *Ben-Shachar, Mattan S and Caldwell, Aaron R and Cousineau, Denis and Dunleavy, Daniel J and Elsherif, Mahmoud M and Johnson, Blair T and Moreau, David and Riesthuis, Paul and Röseler, Lukas and Steele, James and Vieira, Felipe F and Zloteanu, Mircea and Feldman, Gilad},\n  year={2024}\n}",
    "crumbs": [
      "Basis"
    ]
  },
  {
    "objectID": "Defining-Effect-Sizes.html",
    "href": "Defining-Effect-Sizes.html",
    "title": "1  Definiëren van Effect Sizes",
    "section": "",
    "text": "Effect sizes kwantificeren de grootte van effecten (d.w.z. de sterkte van een verband, de grootte van een verschil), die de uitkomsten zijn van ons empirisch onderzoek. Effect sizes zijn zeker geen nieuw concept. Het rapporteren ervan bleef echter jarenlang grotendeels optioneel, en pas sinds kort wordt het een standaard voor de gemeenschap: wetenschappers zien het rapporteren van effect sizes (naast de traditionele statistische significantie) nu als een must en tijdschriften beginnen deze rapportage ook verplicht te stellen. Met name in 2001 en 2010 benadrukte The Publication Manual of the American Psychological Association, 5e en 6e editie, dat het “bijna altijd noodzakelijk” is (Divine et al. 2018) om effect sizes te rapporteren (APA 2010, 34; zie Fritz, Morris, and Richler 2012, die een uitgebreide samenvatting geeft van de geschiedenis en het belang van het rapporteren van effect sizes).\nEffectgroottes kunnen worden opgedeeld in brede categorieën als (1) ruwe effect sizes en (2) gestandaardiseerde effect sizes. De ruwe effect sizes zijn een samenvatting van de resultaten die worden uitgedrukt in dezelfde eenheden als de ruwe gegevens. Wanneer bijvoorbeeld kilogrammen worden gemeten, geeft een ruwe effect size een meting in kilogrammen. Neem het effect van een dieet op een behandelgroep; een controlegroep krijgt geen dieet. De verandering in gewicht kan worden uitgedrukt als het gemiddelde verschil tussen de groepen. Deze maat is ook in kg en dus een ruwe effect size. Gestandaardiseerde effect sizes uitgedrukt op een gestandaardiseerde schaal waarbij de eenheden worden uitgedrukt als standaarddeviaties (d.w.z. z-scores). Gestandaardiseerde effect sizes zijn meestal beter vergelijkbaar tussen onderzoeken die verschillende maten of eenheidsschalen gebruiken.\n\n\n\n\nAPA. 2010. Publication Manual of the American Psychological Association. American Psychological Association. https://thuvienso.hoasen.edu.vn/handle/123456789/8327.\n\n\nDivine, George W, H James Norton, Anna E Barón, and Elizabeth Juarez-Colunga. 2018. “The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians.” The American Statistician 72 (3): 278–86.\n\n\nFritz, Catherine O., Peter E. Morris, and Jennifer J. Richler. 2012. “Effect Size Estimates: Current Use, Calculations, and Interpretation.” Journal of Experimental Psychology: General 141 (1): 2–18. https://doi.org/10.1037/a0024338.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definiëren van Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Benchmarks.html#footnotes",
    "href": "Benchmarks.html#footnotes",
    "title": "2  Referentiepunten",
    "section": "",
    "text": "Sawilowsky (2009) bereidde Cohen’s richtlijnen om hele kleine effecten te omvatten (\\(d\\) = 0.01), hele grote effecten (\\(d\\) = 1.20), en enorme effecten (\\(d\\) = 2.0). Opgemerkt moet worden dat zeer grote en enorme effecten zeer zeldzaam zijn in de experimentele sociale psychologie.↩︎\nVolgens deze recente meta-analyse van effect sizes in sociale psychologiestudies “wordt aanbevolen om correlatiecoëfficiënten van .1, .25 en .40 en Hedges’ \\(g\\) (of Cohen’s \\(d\\)) van 0,15, 0,40 en 0,70 te interpreteren als kleine, middelgrote en grote effecten voor studies in de sociale psychologie.↩︎\nLet op, voor gepaarde steekproeven verwijst dit niet naar de waarschijnlijkheid van een toename/afname in gepaarde steekproeven, maar eerder naar de waarschijnlijkheid van een willekeurig gekozen waarde van X. Dit wordt in de literatuur ook wel het “relatieve” effect genoemd. Daarom zullen de resultaten verschillen van de concordantiekans die hieronder wordt gegeven.↩︎\nDeze richtlijn wordt ook aanbevolen door Gignac and Szodorai (2016). Funder and Ozer (2019) heeft ze uitgebreid met zeer kleine effecten (\\(r\\) = .05) en zeer grote effecten (\\(r\\) = .40 of groter). Volgens hen geeft een effectgrootte \\(r\\) van .05 een effect aan dat zeer klein is voor de verklaring van enkelvoudige gebeurtenissen maar potentieel op de niet al te lange termijn gevolgen kan hebben, geeft een effectgrootte r van .10 een effect aan dat nog steeds klein is op het niveau van enkelvoudige gebeurtenissen maar potentieel op de lange termijn meer gevolgen kan hebben, geeft een effectgrootte \\(r\\) van . 20 duidt op een middelgroot effect dat zelfs op de korte termijn enig verklarend en praktisch nut heeft en daarom nog belangrijker is, en een effectgrootte \\(r\\) van .30 duidt op een groot effect dat potentieel krachtig is op zowel de korte als de lange termijn. Een zeer grote effectgrootte (r = .40 of groter) in de context van psychologisch onderzoek is waarschijnlijk een grove overschatting die zelden zal worden gevonden in een grote steekproef of in een replicatie.” Maar zie hier voor controverses met dit paper.↩︎\nDe richtlijn voor Cramer’s V zijn afhankelijk van de grootte van de contingentietabel waarop het effect wordt berekend. Gebruik volgens Cohen richtlijn voor de phi-coëfficiënt gedeeld door de vierkantswortel van de kleinste dimensie min 1. Bijvoorbeeld, een gemiddeld effect voor een Cramer’s V van een 4 bij 3 tabel zou .3 / sqrt(3 - 1) = .21 zijn.↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Referentiepunten</span>"
    ]
  },
  {
    "objectID": "Reporting-Effect-Sizes.html#transparantie",
    "href": "Reporting-Effect-Sizes.html#transparantie",
    "title": "3  Rapporteren van Effect Sizes",
    "section": "3.1 Transparantie",
    "text": "3.1 Transparantie\nWanneer u effectgroottes en hun berekeningen rapporteert, moet u prioriteit geven aan transparantie en reproduceerbaarheid. Welke tool u ook gebruikt om uw effectgrootte te berekenen (R wordt hier het meest aanbevolen), u moet ervoor zorgen dat anderen gemakkelijk uw procedures kunnen volgen en dezelfde resultaten kunnen verkrijgen. Dit betekent dat als je online calculators gebruikt (wat wordt afgeraden) of standalone programma’s (JAMOVI wordt het meest aanbevolen; je kunt ook JASP gebruiken, dat op dit moment echter geen toegang geeft tot syntax), je screenshots moet toevoegen die de invoer en uitvoer vastleggen, met duidelijke uitleg. Als je R, Python of andere programmeertalen gebruikt, moet je je codes kopiëren en plakken in je aanvullend document (of je scripts indienen bij open online repositories), idealiter met annotaties en commentaar waarin de codes worden uitgelegd. inputs en outputs."
  },
  {
    "objectID": "Reporting-Effect-Sizes.html#directionaliteit",
    "href": "Reporting-Effect-Sizes.html#directionaliteit",
    "title": "3  Rapporteren van Effect Sizes",
    "section": "3.2 Directionaliteit",
    "text": "3.2 Directionaliteit\nSommige effectgroottes zijn directioneel (bijvoorbeeld Cohen’s \\(d\\), Pearson correlaties \\(r\\)), wat betekent dat ze positief of negatief kunnen zijn. Hun teken bevat belangrijke informatie en kan daarom niet worden weggelaten. Wanneer u deze effectgroottes rapporteert, maak dan duidelijk wat met wat wordt vergeleken (d.w.z. de richting van de vergelijking). Beter nog, zorg ervoor dat je vergelijking in lijn is met de theorie. Als een theorie bijvoorbeeld voorspelt dat je groep X hoger zou moeten scoren op een item dan je groep Y, [^reporting-effect-sizes-1] moet je dienovereenkomstig veronderstellen dat groep X een hoger gemiddelde zal hebben dan groep Y op het item, en gemiddelde(Y) aftrekken van gemiddelde(X) (in plaats van andersom) om het gemiddelde verschil te krijgen. Je moet dan verwachten dat je \\(t\\) statistiek positief is, en je \\(d\\) waarde ook. Met andere woorden, vermijd om iets te rapporteren als \\(t\\) = -5,14, \\(d\\) = 0,36, waar de tekens van de statistieken dan niet overeenkomen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rapporteren van Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Reporting-Effect-Sizes.html#nauwkeurigheid",
    "href": "Reporting-Effect-Sizes.html#nauwkeurigheid",
    "title": "3  Rapporteren van Effect Sizes",
    "section": "3.3 Nauwkeurigheid",
    "text": "3.3 Nauwkeurigheid\nEffect sizes kunnen zeer nauwkeurig worden geschat op basis van de beschikbare gegevens, de gebruikte methodologie en de manier waarop de populatie is bemonsterd. Het kan ook worden geschat met weinig vertrouwen in het resulterende getal. Dit kan bijvoorbeeld het geval zijn als de steekproef erg klein is, als de populatie veel variabiliteit vertoont, als er een tussen-groepsdesign is gebruikt in plaats van een gepaarde steekproefdesign en tot slot als er geclusterde steekproeftrekking is gebruikt in plaats van gerandomiseerde steekproeftrekking. Precisie kan worden geschat met behulp van verschillende hulpmiddelen, maar het meest gebruikte hulpmiddel is waarschijnlijk het betrouwbaarheidsinterval. Dit interval heeft een betrouwbaarheidsniveau, vaak 95%.\n\n\n\n\nGelman, Andrew. 2011. “Why It Doesn’t Make Sense in General to Form Confidence Intervals by Inverting Hypothesis Tests | Statistical Modeling, Causal Inference, and Social Science.” https://statmodeling.stat.columbia.edu/2011/08/25/why_it_doesnt_m/.\n\n\nMorey, Richard D., Rink Hoekstra, Jeffrey N. Rouder, Michael D. Lee, and Eric-Jan Wagenmakers. 2016. “The Fallacy of Placing Confidence in Confidence Intervals.” Psychonomic Bulletin & Review 23 (1): 103–23. https://doi.org/10.3758/s13423-015-0947-8.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rapporteren van Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Reporting-Confidence-Intervals.html",
    "href": "Reporting-Confidence-Intervals.html",
    "title": "5  Rapporteren van Betrouwbaarheidsintervallen",
    "section": "",
    "text": "Betrouwbaarheidsintervallen moeten worden berekend en gerapporteerd voor elke effect size die je hebt verkregen en in je manuscript hebt vermeld. Als je een replicatie doet en je doelartikel/studie geen CI’s rapporteerde voor de effect size, moet je CI’s berekenen en rapporteren.\nNormaal gesproken berekenen we 95% betrouwbaarheidsintervallen (d.w.z. 95% van deze intervallen zal naar verwachting de ware parameterwaarde bevatten als we een oneindig aantal identieke studies uitvoeren).\n\n\n\n\n\n\nAlpha niveau\n\n\n\nHet betrouwbaarheidsinterval hangt af van het alfa-niveau, dat wil zeggen het deel van de CI’s bij herhaalde bemonstering dat de ware parameter niet zal bevatten. Als het ware effect nul is (of nul), vertegenwoordigt het alfa-niveau het fout-positieve percentage (d.w.z. het percentage waarbij een significant effect wordt waargenomen terwijl er geen is). De 95% CI is gebaseerd op een alfa-niveau van .05, maar onderzoekers kunnen elke waarde kiezen (tussen 0 en 1), zolang deze maar goed is gemotiveerd (Lakens 2022).\n\n\nDesalniettemin berekenen we voor sommige effectgroottes (bijv. eta-kwadraat, partiële eta-kwadraat, R-kwadraat) 90% betrouwbaarheidsintervallen. Dit komt omdat \\(\\eta^2\\) gekwadrateerd en altijd positief is, en F-tests eenzijdig zijn. Het rapporteren van 95% CI voor eta kwadraat kan leiden tot situaties waarin de CI nul bevat maar de p-waarde onder .05 valt, terwijl het rapporteren van 90% CI een dergelijk probleem voorkomt. Lees voor meer informatie over dit onderwerp Daniel Lakens blog over betrouwbaarheidsintervallen en Steiger (2004).\nBetrouwbaarheidsintervallen moeten direct na een effectgrootte worden gerapporteerd, bijvoorbeeld Cohen’s \\(d\\) = 0,40, 95% CI [0,20, 0,60]. Na de eerste keer dat ze in een manuscript worden gerapporteerd, kan elke volgende CI eenvoudig tussen haakjes worden gezet zonder “95% CI” ervoor.\nTenzij je iets meet dat betekenisvol is in het echte leven (bijv. inkomen, aantal jaren ervaring, bedrag dat iemand bereid is te doneren), zorg er dan voor dat de CI die je hebt berekend een CI is van de effect sizes en niet van andere statistieken, zoals de teststatistieken of het gemiddelde verschil in ruwe eenheden.\nAls je ziet dat de schatting van de effectgrootte niet binnen je CI valt, heb je waarschijnlijk een probleem. Voor gemiddelden en voor verschil in gemiddelden moet de schatting precies het midden van je CI zijn; voor andere statistieken (bijv. correlatie, proportie, frequentie, standaardafwijking) kan de ene arm langer zijn dan de andere, zodat de schatting mogelijk niet het midden is.\nVoor meer informatie over de berekening en rapportage van effectgroottes en betrouwbaarheidsintervallen, zie Steiger (2004) en Lakens (2014).\n\n\n\n\nLakens, Daniël. 2014. “The 20.” http://daniellakens.blogspot.com/2014/06/calculating-confidence-intervals-for.html.\n\n\n———. 2022. “Sample Size Justification.” Collabra: Psychology 8 (1): 33267. https://doi.org/10.1525/collabra.33267.\n\n\nSteiger, James H. 2004. “Beyond the f Test: Effect Size Confidence Intervals and Tests of Close Fit in the Analysis of Variance and Contrast Analysis.” Psychological Methods 9 (2): 164–82. https://doi.org/10.1037/1082-989X.9.2.164."
  },
  {
    "objectID": "Standardized-Mean-Differences.html#reporting-a-t-test-with-effect-size-and-ci",
    "href": "Standardized-Mean-Differences.html#reporting-a-t-test-with-effect-size-and-ci",
    "title": "7  Gemiddelde verschillen",
    "section": "7.1 Reporting a t-test with effect size and CI",
    "text": "7.1 Reporting a t-test with effect size and CI\nWhatever effect size and CI you choose to report, you can report it alongside the t-test statistics (i.e., t-value and the p value). For example,\n\nThe treatment group had a significantly higher mean than the control group (t = 2.76, p = .009, n = 35, d = 0.47 [0.11, 0.81])."
  },
  {
    "objectID": "Standardized-Mean-Differences.html#sec-single-group",
    "href": "Standardized-Mean-Differences.html#sec-single-group",
    "title": "7  Gemiddelde verschillen",
    "section": "7.2 Enkelvoudig Groep Designs",
    "text": "7.2 Enkelvoudig Groep Designs\nVoor een ontwerp met één groep hebben we één groep en willen we het gemiddelde van die groep vergelijken met een constante, \\(C\\) (d.w.z. een doelwaarde). Het gestandaardiseerde gemiddelde verschil voor een enkele groep kan worden berekend met (vergelijking 2.3.3, Cohen 1988),\n\\[\nd_s = \\frac{M-C}{S_1}\n\\]\nEen positieve \\(d_s\\) waarde geeft aan dat het gemiddelde groter is dan de doelwaarde, \\(C\\). Deze formulering gaat ervan uit dat de steekproef getrokken wordt uit een normale verdeling. De standaardisator (d.w.z. de noemer) is de standaardafwijking van de steekproef. De bijbehorende standaardafwijking voor \\(d_s\\) is (zie documentatie voor Caldwell 2022),\n\\[\nSE_{d_s} = \\sqrt{\\frac{1}{n}+\\frac{d_s^2}{2n}}.\n\\]\nIn R kunnen we de functie d.single.t uit het pakket MOTE gebruiken om het gestandaardiseerde gemiddelde verschil voor één groep te berekenen.\n\n# Installeer pakketten als ze al niet geínstalleerd zijn\n# install.packages('MOTE')\n# Cohen's d voor één gropp\n\n# Bijvoorbeeld:\n# Sample Gemiddelde = 30.4, SD = 22.53, N = 96\n# Doelwaarde, C = 15\n\nlibrary(MOTE)\n\nstats &lt;- d.single.t(\n  m = 30.4,\n  u = 15,\n  sd = 22.53,\n  n = 96\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af \ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 0.684 0.460 0.904\n\n\nZoals je kunt zien, laat de uitvoer zien dat de effectgrootte \\(d_s\\) = 0,68, 95% CI [0,46, 0,90]. Merk op dat de apa functie in MOTE een waarde aanneemt en een APA geformatteerde effectgrootte waarde teruggeeft (d.w.z., voorloopnul en drie decimalen).",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#sec-two-ind-group",
    "href": "Standardized-Mean-Differences.html#sec-two-ind-group",
    "title": "7  Gemiddelde verschillen",
    "section": "7.3 Twee Onafhankelijke Groepen Design",
    "text": "7.3 Twee Onafhankelijke Groepen Design\n\n7.3.1 Gestanstaardiseerd met Gepoolde Standaard Deviatie (\\(d_p\\))\nVoor een tweegroepsdesign (d.w.z. between-groups design) willen we de gemiddelden van twee groepen (groep 1 en groep 2) vergelijken. Het gestandaardiseerde gemiddelde verschil tussen twee groepen kan worden berekend met (vergelijking 5.1, Glass, McGaw, and Smith 1981),\n\\[\nd_p = \\frac{M_1-M_2}{S_p}.\n\\]\nEen positieve \\(d_p\\) waarde zou aangeven dat het gemiddelde van groep 1 groter is dan het gemiddelde van groep 2. Het gemiddelde verschil delen door de gepoolde standaardafwijking, \\(S_p\\), is de klassieke formulering van Cohen’s \\(d\\). De gepoolde standaardafwijking, \\(S_p\\), kan worden berekend als de vierkantswortel van de gemiddelde variantie (gewogen door de vrijheidsgraden, \\(df=n-1\\)) van groep 1 en groep 2 (pp. 108, Glass, McGaw, and Smith 1981):\n\\[\nS_p = \\sqrt{\\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}}\n\\]\nMerk op dat de term variantie verwijst naar het kwadraat van de standaardafwijking (\\(S^2\\)). Cohen’s \\(d_p\\) is gerelateerd aan de t-statistiek van een onafhankelijke t-test. In feite kunnen we de \\(d_p\\) waarde uit de \\(t\\)-statistiek berekenen met de volgende formule (vergelijking 5.3, Glass, McGaw, and Smith 1981):\n\\[\nd = t\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}.\n\\]\nDe bijbehorende standaardfout van \\(d_p\\) is,\n\\[\nSE_{d_p} = \\sqrt{\\frac{n_1+n_2}{n_1 n_2}+\\frac{d_p^2}{2(n_1+n_2)}}.\n\\]\nIn R kunnen we de d.ind.t functie uit het MOTE pakket gebruiken om het gestandaardiseerde gemiddelde verschil tussen twee groepen te berekenen. Omdat we het MOTE pakket al hebben geladen, hoeven we dat niet nog een keer te doen.\n\n# Cohen's d voor twee onafhankelijke groepen\n# gegeven gemiddelden en SDs\n\n# Bijvoorbeeld:\n# Groep 1 Gemiddelde = 30.4, SD = 22.53, N = 96\n# Groep 2 Gemiddelde = 21.4, SD = 19.59, N = 96\n\nstats &lt;- d.ind.t(\n  m1 = 30.4,\n  m2 = 21.4,\n  sd1 = 22.53,\n  sd2 = 19.59,\n  n1 = 96,\n  n2 = 96,\n  a = 0.05\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af \ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 0.426 0.140 0.712\n\n\nDe output laat de resultaten zien: \\(d_p\\) = 0.43, 95% CI [0.14, 0.71].\n\n\n7.3.2 Gestandaardiseerd door Controle Groep Standaard Deviatie (\\(d_{\\Delta}\\))\nAls twee groepen aanzienlijk verschillen in hun standaarddeviaties, kunnen we in plaats daarvan standaardiseren met de standaarddeviatie van de controlegroep (\\(S_C\\)), zodat,\n\\[\nd_{\\Delta} = \\frac{M_T-M_C}{S_C}.\n\\]\nWaarbij de subscripts, \\(T\\) en \\(C\\), respectievelijk de behandelgroep en controlegroep aanduiden. Deze formulering wordt gewoonlijk Glass’ \\(Delta\\) genoemd (Glass 1981). De standaardfout voor \\(d_{\\Delta}\\) kan worden gedefinieerd als,\n\\[\nSE_{d_{\\Delta}} = \\sqrt{\\frac{n_T+n_C}{n_T n_C} + \\frac{d_\\Delta^2}{n_C+1} }\n\\]\nMerk op dat als we alleen standaardiseren door de standaardafwijking van de controlegroep (in plaats van poolen), we minder vrijheidsgraden hebben (\\(df=n_C-1\\)) en dus meer steekproeffout dan wanneer we delen door de gepoolde standaardafwijking (\\(df= n_T + n_C - 2\\)). In R kunnen we de functie delta.ind.t.diff uit het pakket MOTE gebruiken om \\(d_Delta\\) te berekenen.\n\n# Cohen's dz voor verschilscores\n# gegeven verschilscore gemiddelden en SDs\n\n# Bijvoorbeeld\n# Controle groep Gemiddelde = 30.4, SD = 22.53, N = 96\n# Behandel groep Gemiddelde = 21.4, SD = 19.59, N = 96\n# correlatie tussen condities: r = .40\n\nstats &lt;- delta.ind.t(\n  m1 = 30.4,\n  m2 = 21.4,\n  sd1 = 22.53,\n  sd2 = 19.59,\n  n1 = 96,\n  n2 = 96,\n  a = 0.05\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af\ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 0.399 0.140 0.712",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#sec-repeated-measures",
    "href": "Standardized-Mean-Differences.html#sec-repeated-measures",
    "title": "7  Gemiddelde verschillen",
    "section": "7.4 Herhaalde Metingen Designs",
    "text": "7.4 Herhaalde Metingen Designs\nIn een ontwerp met herhaalde metingen worden dezelfde proefpersonen (of items, enz.) gemeten op twee of meer afzonderlijke gelegenheden of in meerdere omstandigheden binnen één sessie. Tegelijk willen het gemiddelde verschil weten tussen die gelegenheden of omstandigheden (Baayen, Davidson, and Bates 2008; Barr et al. 2013). Een voorbeeld hiervan is een pre/post-vergelijking waarbij proefpersonen worden getest voor en na het ondergaan van een bepaalde behandeling (zie Figure 7.1 voor een visualisatie). Een gestandaardiseerd gemiddeld verschil in een ontwerp met herhaalde metingen kan een paar verschillende vormen aannemen die we hieronder definiëren.\n\n\n\n\n\n\n\n\nFigure 7.1: Figuur met gesimuleerde data van een herhaalde metingen ontwerp, de x-as toont de conditie (bijv. pre-test en post-test) en de y-as zijn de scores. Lijnen geven de verandering binnen de persoon voor/na aan.\n\n\n\n\n\n\n7.4.1 Verschilscore \\(d\\) (\\(d_z\\))\nIn plaats van de gemiddelden van twee sets scores met elkaar te vergelijken, kunnen we bij een within subject design de scores verkregen in conditie 1 aftrekken van de scores in conditie 2. Deze verschilscores (\\(X_{{diff}}=X_2-X_1\\)) kunnen op dezelfde manier worden gebruikt als bij het single group design (als de doelwaarde nul was, d.w.z. \\(C=0\\)), zodat (vergelijking 2.3.5, Cohen 1988),\n\\[\nd_z = \\frac{M_{\\text{diff}}}{S_{\\text{diff}}}\n\\]\nHet verschil tussen deze formulering en het enkelvoudig groep design is de aard van de scores (verschilscores in plaats van ruwe scores). Het handige van \\(d_z\\) is dat het een direct verband heeft met de \\(t\\)-statistiek, \\(d_z=\\frac{t}{\\sqrt{n}}\\). Dit maakt het erg nuttig voor poweranalyses. Als de standaardafwijking van de verschilscores niet toegankelijk is, kan deze berekend worden met de standaardafwijking van conditie 1 (\\(S_1\\)), de standaardafwijking van conditie 2 (\\(S_2\\)) en de correlatie tussen condities (\\(r\\)) (vergelijking 2.3.6, Cohen 1988):\n\\[\nS_{\\text{diff}}=\\sqrt{S^2_1 + S^2_2 - 2 r S_1 S_2}\n\\]\nHet is belangrijk op te merken dat wanneer de correlatie tussen groepen groot is, de \\(d_z\\) waarde ook groter zal zijn, terwijl een kleine correlatie een kleinere \\(d_z\\) waarde zal opleveren. De standaardafwijking van \\(d_z\\) kan op dezelfde manier worden berekend als bij het ontwerp met één groep, zodat,\n\\[\nSE_{d_z} = \\sqrt{\\frac{1}{n}+\\frac{d_z^2}{2n}}\n\\]\nIn R kunnen we de functie d.ind.t.diff uit het pakket MOTE gebruiken om \\(d_z\\) te berekenen.\n\n# Cohen's dz voor verschilscores\n# gegeven verschilscore gemiddelden en SDs\n\n# Bijvoorbeeld:\n# Verschilscore Gemiddelde = 21.4, SD = 19.59, N = 96\n\nlibrary(MOTE)\n\nstats &lt;- d.dep.t.diff(\n  m = 21.4,\n  sd = 19.59,\n  n = 96,\n  a = 0.05\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af\ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 1.092 0.837 1.344\n\n\nDe uitvoer laat zien dat de effectgrootte \\(d_z\\) = 1,09, 95% CI [0,84, 1,34].\n\n\n7.4.2 Herhaalde Metingen \\(d\\) (\\(d_{rm}\\))\nVoor een binnen-groep design willen we de gemiddelden van scores verkregen uit conditie 1 en conditie 2 vergelijken. Het repeated measures gestandaardiseerde gemiddelde verschil tussen de twee condities kan worden berekend met (vergelijking 9, Lakens 2013),\n\\[\nd_{rm} = \\frac{M_2-M_1}{S_w}.\n\\]\nEen positieve \\(d_{rm}\\) waarde zou aangeven dat het gemiddelde van toestand 2 groter is dan het gemiddelde van toestand 1. Het gaat hier om de standaardafwijking binnen het onderwerp, \\(S_w\\). De standaardafwijking binnen het onderwerp kan als volgt worden gedefinieerd,\n\\[\nS_{w}=\\sqrt{\\frac{S^2_1 + S^2_2 - 2 r S_1 S_2}{2(1-r)}}.\n\\]\nWe kunnen \\(S_w\\) ook uitdrukken in termen van de standaardafwijking van de verschilscores (\\(S_{{diff}}\\)),\n\\[\nS_w = \\frac{S_{\\text{diff}}}{ \\sqrt{2(1-r)} }.\n\\]\nVerder kunnen we \\(d_{rm}\\) zelfs uitdrukken in termen van de verschilscore gestandaardiseerd gemiddeld verschil (\\(d_z\\)),\n\\[\nd_{rm} = d_z \\times \\sqrt{2(1-r)}.\n\\]\nUiteindelijk is \\(d_{rm}\\) meer geschikt als effectgrootteschatting voor gebruik in meta-analyses, terwijl \\(d_z\\) meer geschikt is voor poweranalyse (Lakens 2013). De standaardfout voor \\(d_{rm}\\) kan als volgt worden berekend,\n\\[\nSE_{d_{rm}} = \\sqrt{\\left(\\frac{1}{n} + \\frac{d^2_{rm}}{2n}\\right) \\times 2(1-r)}\n\\]\nIn R kunnen we de d.ind.t.rm functie uit het MOTE pakket gebruiken om het repeated measures standardized mean difference (\\(d_{rm}\\)) te berekenen.\n\n# Cohen's d voor herhaalde metingen\n# gegeven gemiddelden en SDs en correlatie\n\n# Bijvoorbeeld:\n# Conditie 1 Gemiddelde = 30.4, SD = 22.53, N = 96\n# Conditie 2 Gemiddelde = 21.4, SD = 19.59, N = 96\n# correlatie tussen condities: r = .40\n\nstats &lt;- d.dep.t.rm(\n  m1 = 30.4,\n  m2 = 21.4,\n  sd1 = 22.53,\n  sd2 = 19.59,\n  r = .40,\n  n = 96,\n  a = 0.05\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af\ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 0.425 0.215 0.633\n\n\nDe uitvoer laat zien dat de effectgrootte \\(d_{rm}\\) = 0,42, 95% CI [0,21, 0,63] is.\n\n\n7.4.3 Gemiddelde variantie \\(d\\) (\\(d_{av}\\))\nHet probleem met \\(d_{z}\\) en \\(d_{rm}\\) is dat ze de correlatie tussen condities vereisen. In de praktijk worden correlaties tussen condities vaak niet gerapporteerd. Een alternatieve schatter van Cohen’s \\(d\\) bij een ontwerp met herhaalde metingen is om gewoon de klassieke variatie van Cohen’s \\(d\\) te gebruiken (d.w.z. gepoolde standaardafwijking). In een ontwerp met herhaalde metingen verandert de steekproefgrootte niet tussen condities. Daarom is het wegen van de variantie van toestand 1 en toestand 2 met hun respectieve vrijheidsgraden (d.w.z. \\(df=n-1\\)) een onnodige stap. In plaats daarvan kunnen we standaardiseren met de vierkantswortel van het gemiddelde van de varianties van toestand 1 en 2 (zie vergelijking 5, Algina and Keselman 2003):\n\\[\nd_{av} = \\frac{M_2 - M_1}{\\sqrt{\\frac{S_1^2 + S_2^2}{2}}}\n\\]\nDeze formulering is vooral handig als de correlatie niet aanwezig is, maar zonder de correlatie wordt er geen rekening gehouden met de consistentie van verandering tussen condities. De standaardfout van de \\(d_{av}\\) kan worden uitgedrukt als (vergelijking 9, Algina and Keselman 2003),\n\\[\nSE_{d_{av}}= \\sqrt{\\frac{2(S^2_1 + S^2_2 - 2rS_1S_2)}{n(S_1^2+S^2)}}\n\\]\nIn R kunnen we de d.ind.t.rm functie uit het MOTE pakket gebruiken om het herhaalde metingen gestandardiseerde gemiddelde verschil (\\(d_{rm}\\)) te berekenen.\n\n# Cohen's d voor herhaalde metingen (gemiddelde variantie)\n# gegeven gemiddelde en SDs \n\n# Bijvoorbeeld:\n# Conditie 1 Gemiddelde = 30.4, SD = 22.53, N = 96\n# Conditie 2 Gemiddelde = 21.4, SD = 19.59, N = 96\n\nstats &lt;- d.dep.t.avg(\n  m1 = 30.4,\n  m2 = 21.4,\n  sd1 = 22.53,\n  sd2 = 19.59,\n  n = 96,\n  a = 0.05\n)\n\n# druk alleen de d waarde en betrouwbaarheidsintervalel af\ndata.frame(d = apa(stats$d), \n           dlow = apa(stats$dlow), \n           dhigh = apa(stats$dhigh))\n\n      d  dlow dhigh\n1 0.427 0.217 0.635\n\n\nDe uitvoer laat zien dat de effectgrootte \\(d_{av}\\) = 0,43, 95% CI [0,22, 0,64].\n\n\n7.4.4 Becker’s \\(d\\) (\\(d_b\\))\nEen nog eenvoudiger variant van herhaalde metingen \\(d\\)waarde komt van Becker (1988). Becker’s \\(d\\) standaardiseert eenvoudigweg met de standaardafwijking vóór de test als de vergelijking een pre-post design is,\n\\[\nd_b = \\frac{M_{\\text{post}}-M_{\\text{pre}}}{S_{\\text{pre}}}.\n\\]\nDe handige interpretatie van “verandering in basislijnstandaarddeviaties” kan heel nuttig zijn. We kunnen de standaardfout ook verkrijgen met (vergelijking 13, Becker 1988),\n\\[\nSE_{d_b} = \\sqrt{\\frac{2(1-r)}{n}+\\frac{d_b^2}{2n}}\n\\]\nMerk op dat hoewel de formule voor het berekenen van \\(d_b\\) niet de correlatiecoëfficiënt bevatte, de standaardfout dat wel doet.\nIn basis-R kunnen we Becker’s formulering van gestandaardiseerd gemiddelde verschil berekenen met bovenstaande vergelijkingen.\n\n# Installeer het pakket hieronder als je dat al niet gedaan hebt\n# install.packages(escalc)\n# Cohen's d voor herhaalde metingen (becker's d)\n# gegeven gemiddelde, de pre-test SDs en de correlatie\n\n# Bijvoorbeeld:\n# Pre-test Gemiddelde = 21.4, SD = 19.59, N = 96\n# Post-test Gemiddelde = 30.4, N = 96\n# Correlatie tussen condities: r = .40\n\nMpre &lt;- 21.4\nMpost &lt;- 30.4\nSpre &lt;- 19.59\nr &lt;- .40\nn &lt;- 96\na &lt;- 0.05\n\nd &lt;- (Mpost - Mpre) / Spre\n\nSE &lt;- sqrt( 2*(1-r)/n + d^2/(2*n) )\n\n# druk alleen de d waarde en betrouwbaarheidsintervallen af \ndata.frame(d = apa(d), \n           dlow = apa(d - 1.96*SE), \n           dhigh = apa(d + 1.96*SE))\n\n      d  dlow dhigh\n1 0.459 0.231 0.688\n\n\nDe uitvoer laat zien dat de effectgrootte \\(d_{rm}\\) = 0,46, 95% CI [0,23, 0,69].\n\n\n7.4.5 Vergelijken Herhaalde Metingen \\(d\\) waarden\nFigure 7.2 toont herhaalde metingen ontwerpen met een hoge (\\(r=\\) .95) en lage (\\(r=\\) .05) correlatie tussen condities. Laten we de standaarddeviaties en gemiddelden voor beide condities (hoge en lage correlatie) vastzetten en alleen de correlatie variëren. Nu kunnen we de herhaalde-maatregelen-schatters op basis van deze twee condities in Figure 7.2 vergelijken:\n\nHoge correlatie:\n\n\\(d_z=1.24\\)\n\\(d_{rm}=0.39\\)\n\\(d_{av}=0.43\\)\n\\(d_{b}=0.40\\)\n\nLage correlatie:\n\n\\(d_z=0.31\\)\n\\(d_{rm}=0.43\\)\n\\(d_{av}=0.43\\)\n\\(d_{b}=0.40\\)\n\n\nWe merken op dat de correlatie \\(d_z\\) sterker beïnvloedt dan elke andere schatter. De waarde van \\(d_{rm}\\) verandert heel weinig, terwijl \\(d_{av}\\) en \\(d_{b}\\) helemaal geen rekening houden met de correlatie.\n\n\n\n\n\n\n\n\nFigure 7.2: Figuur met gesimuleerde gegevens van een herhaald metingenontwerp, waarbij de x-as de conditie weergeeft (bijv. pre-test en post-test) en de y-as de scores. Het linkerpaneel toont een hoge pre-post correlatie (\\(r\\) = .95) en het rechterpaneel toont een conditie met een lage correlatie (\\(r\\) = .05). Lijnen geven de verandering binnen de persoon voor/na aan.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#sec-ppc",
    "href": "Standardized-Mean-Differences.html#sec-ppc",
    "title": "7  Gemiddelde verschillen",
    "section": "7.5 Pretest-Posttest-Controle Groep Designs",
    "text": "7.5 Pretest-Posttest-Controle Groep Designs\nIn veel onderzoeksgebieden worden zowel tussen als binnen de groep factoren opgenomen. Bij onderzoek waarbij de effecten van een interventie worden onderzocht, wordt een steekproef bijvoorbeeld vaak gerandomiseerd in twee afzonderlijke groepen (interventie en controle) en wordt de uitkomst van belang zowel voor (pretest) als na (posttest) de interventie/controleperiode gemeten. In dit soort 2x2 (groep x tijd) studieontwerpen is het meestal het verschil tussen de gestandaardiseerde gemiddelde verandering voor de interventie/behandeling (\\(T\\)) en de controlegroep (\\(C\\)) dat van belang is. Voor een visualisatie van een pretest-posttest-controlegroepdesign zie Figure 7.3.\nMorris (2008) geeft drie effectgroottes voor deze pretest-posttest-controle (PPC).\n\n\n\n\n\n\n\n\nFigure 7.3: Illustration of a pre-post control design. Left panel shows the pre-post difference in the control group and right panel shows the pre-post difference in the intervention/treatment group. Lines indicate within person pre/post change.\n\n\n\n\n\n\n7.5.1 PPC1 - afzonderlijke pre-test standaard deviaties\nDe afzonderlijke standaarddeviaties van de pre-test (d.w.z. baseline) worden gebruikt om het gemiddelde verschil van de interventiegroep en de controlegroep van voor en na te standaardiseren (zie vergelijking 4, Morris 2008),\n\\[\nd_T = \\frac{M_{T,\\text{post}} - M_{T,\\text{pre}}}{S_{T,\\text{pre}}}\n\\]\n\\[\nd_C = \\frac{M_{C,\\text{post}} - M_{C,\\text{pre}}}{S_{C,\\text{pre}}}\n\\]\nMerk op dat deze effectgroottes identiek zijn aan de \\(d\\) formulering van de SMD van Becker (zie Section 7.4.4). Daarom is de pretest-posttest-controlegroep effectgrootte simpelweg het verschil tussen de interventie en controle pre/post SMD (vergelijking 15, Becker 1988),\n\\[\nd_{PPC1} = d_T - d_C\n\\]\nDe asymptotische standaardafwijking van \\(d_{PPC2}\\) werd voor het eerst afgeleid door Becker (1988) en kan worden uitgedrukt als de vierkantswortel van de som van de steekproefvarianties (vergelijking 16, Becker 1988).\n\\[\nSE_{d_{PPC1}} = \\sqrt{\\left[\\frac{2(1-r_T)}{n_T} + \\frac{d_T}{2n_T}\\right] + \\left[\\frac{2(1-r_C)}{n_C} + \\frac{d_C}{2n_C}\\right]}\n\\]\nWe kunnen \\(d_{PPC1}\\) en zijn betrouwbaarheidsintervallen berekenen met R:\n\n# Voorbeeld:\n\n# Controle Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 6\n## Post-test Gemiddelde = 25, SD = 7\n## Pre/post correlatie = .50\nM_Cpre &lt;- 20\nM_Cpost &lt;- 25\nSD_Cpre &lt;- 6\nSD_Cpost &lt;- 7\nrC &lt;- .50\nnC &lt;- 90\n\n# Interventie Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 5\n## Post-test Gemiddelde = 27, SD = 8\n## Pre/post correlatie = .50\nM_Tpre &lt;- 20\nM_Tpost &lt;- 27\nSD_Tpre &lt;- 5\nSD_Tpost &lt;- 8\nrT &lt;- .50\nnT &lt;- 90\n\n# bereken het geobserveerde gestandaardiseerde gemiddelde verschil\ndT &lt;- (M_Tpost- M_Tpre) / SD_Tpre\ndC &lt;- (M_Cpost - M_Cpre) / SD_Cpre\ndPPC1 &lt;- dT - dC\n\n# bereken de standaard four (SE)\nSE &lt;- sqrt( 2*(1-rT)/nT + dPPC1^2/(2*nT) + 2*(1-rC)/nC + dPPC1^2/(2*nC) )\n\n# druk de d waarde en betrouwbaarheids intervallen af\ndata.frame(d = MOTE::apa(dPPC1),\n           dlow = MOTE::apa(dPPC1 - 1.96*SE),\n           dhigh = MOTE::apa(dPPC1 + 1.96*SE))\n\n      d  dlow dhigh\n1 0.567 0.252 0.881\n\n\nDe output toont een pre-post interventie-effect van \\(d_{PPC1}\\) = 0,57 [0,25, 0,88].\n\n\n7.5.2 PPC2 - gepoolde pre-test standaard deviaties\nDe gepoolde standaarddeviaties vóór de test (d.w.z. bij de uitgangswaarde) kunnen worden gebruikt om het verschil in verandering vóór/na de interventie- en controlegroep te standaardiseren, zodat (vergelijking 8, Morris 2008),\n\\[\nd_{PPC2} = \\frac{(M_{T,\\text{post}} - M_{T,\\text{pre}}) - (M_{C,\\text{post}} - M_{C,\\text{pre}})}{S_{p,\\text{pre}}}\n\\]\nwaarbij\n\\[\nS_{p,\\text{pre}} = \\sqrt{\\frac{(n_T-1)S^2_{T,\\text{pre}} + (n_C - 1)S^2_{C,\\text{pre}}}{n_T + n_C - 2}}.\n\\]\nDe verdeling van \\(d_{PPC2}\\) werd beschreven door Morris (2008) en kan worden uitgedrukt als (aangepast van vergelijking 16, Morris 2008),\n\\[\n\\small{SE_{d_{PPC2}} = \\sqrt{2\\left(1-\\frac{n_T r_T + n_C r_C}{n_T + n_C}\\right)\\left(\\frac{n_T + n_C}{n_T n_C}\\right)\\left[1 + \\frac{d^2_{PPC2}}{2\\left(1-\\frac{n_T r_T + n_C r_C}{n_T + n_C}\\right)\\left(\\frac{n_T + n_C}{n_T n_C}\\right)}\\right] - d^2_{PPC2}}}\n\\]\nMerk op dat de oorspronkelijke vergelijking in het artikel van Morris (2008) de populatie pre-post correlatie \\(rho\\) gebruikt, maar in bovenstaande vergelijking vervangen we \\(rho\\) door het steekproefgrootte gewogen gemiddelde van de Pearson correlatie berekend in de behandelgroep en de controlegroep (d.w.z. \\(rho approx frac{n_ r_T + n_C r_C}{n_T + n_C}\\)).\nWe kunnen R gebruiken om \\(d_{PPC2}\\) en betrouwbaarheidsintervallen te verkrijgen:\n\n# Voorbeeld:\n\n# Controle Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 6\n## Post-test Gemiddelde = 25, SD = 7\n## Pre/post correlatie = .50\nM_Cpre &lt;- 20\nM_Cpost &lt;- 25\nSD_Cpre &lt;- 6\nSD_Cpost &lt;- 7\nrC &lt;- .50\nnC &lt;- 90\n\n# Interventie Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 5\n## Post-test Gemiddelde = 27, SD = 8\n## Pre/post correlatie = .50\nM_Tpre &lt;- 20\nM_Tpost &lt;- 27\nSD_Tpre &lt;- 5\nSD_Tpost &lt;- 8\nrT &lt;- .50\nnT &lt;- 90\n\n# bereken het geobserveerde gestandaardiseerde gemiddelde verschil\ndPPC2 &lt;- ((M_Tpost- M_Tpre) - (M_Cpost - M_Cpre)) / sqrt( ( (nT - 1)*(SD_Tpre^2) + (nC - 1)*(SD_Cpre^2) ) / (nT + nC - 2) )\n\n# bereken de standaard fout (SE)\nSE &lt;-  sqrt(2*(1-( (nT*rT+nC*rC)/(nT + nC))) * ((nT+nC)/(nT*nC)) * (1 + (dPPC2^2 / (2*(1 - ((nT*rT+nC*rC)/(nT+nC))) * ((nT+nC)/(nT*nC)))))) - dPPC2\n\n# druk de d waarde en betrouwbaarheidsintervallen af \ndata.frame(d = MOTE::apa(dPPC2),\n           dlow = MOTE::apa(dPPC2 - 1.96*SE),\n           dhigh = MOTE::apa(dPPC2 + 1.96*SE))\n\n      d  dlow dhigh\n1 0.362 0.304 0.420\n\n\nDe output toont een pre-post interventie-effect van \\(d_{PPC2}\\) = 0,36 [0,30, 0,42].\n\n\n7.5.3 PPC3 - gepoolde pre- en post-test\nDe twee vorige effect sizes gebruiken alleen de pretest standaarddeviatie. Maar als we graag aannemen dat pretest- en posttestvarianties homogeen zijn1, kunnen de gepoolde pre-test- en postteststandaarddeviaties worden gebruikt om het verschil in verandering voor en na de interventie- en controlegroep te standaardiseren, zodat (vergelijking 8, Morris 2008),\n\\[\nd_{PPC3} = \\frac{(M_{T,\\text{post}} - M_{T,\\text{pre}}) - (M_{C,\\text{post}} - M_{C,\\text{pre}})}{S_{p,\\text{pre-post}}},\n\\]\nwaarbij,\n\\[\nS_{p,\\text{pre-post}} = \\sqrt{\\frac{(n_T-1)\\left(S^2_{T,\\text{pre}} + S^2_{T,\\text{post}}\\right) + (n_C - 1)\\left(S^2_{C,\\text{pre}} + S^2_{C,\\text{post}}\\right)}{2(n_T + n_C - 2)}}.\n\\]\nDe standaardfout voor \\(d_{PPC2}\\) is momenteel onbekend. Een optie om deze standaardfout te schatten is het gebruik van een niet-parametrische of parametrische bootstrap door de ruwe gegevens herhaaldelijk te sampelen, of als de ruwe gegevens niet beschikbaar zijn door gesimuleerde gegevens te sampelen. We kunnen dit doen in basis-R door voor/na data te simuleren met de mvrnorm() functie uit het MASS pakket (Venables and Ripley 2002):\n\n# Installeer het pakket als het nog niet is geïnstalleerd\n# install.packages(MASS)\n\n# Bijvoorbeeld:\n\n# Controle Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 6\n## Post-test Gemiddelde = 25, SD = 7\n## Pre/post correlatie = .50\nM_Cpre &lt;- 20\nM_Cpost &lt;- 25\nSD_Cpre &lt;- 6\nSD_Cpost &lt;- 7\nrC &lt;- .50\nnC &lt;- 90\n\n# Interventie Groep (N = 90)\n## Pre-test Gemiddelde = 20, SD = 5\n## Post-test Gemiddelde = 27, SD = 8\n## Pre/post correlatie = .50\nM_Tpre &lt;- 20\nM_Tpost &lt;- 27\nSD_Tpre &lt;- 5\nSD_Tpost &lt;- 8\nrT &lt;- .50\nnT &lt;- 90\n\n# simuleerdata\nset.seed(1) # set seed voor reproduceerbaarheid\nboot_dPPC3 &lt;- c()\nfor(i in 1:1000){\n  # simuleer controle groep pre-post data\n  data_C &lt;- MASS::mvrnorm(n = nC,\n                          # input geobserveerde gemiddelden\n                          mu = c(M_Cpre,M_Cpost),\n                          # input geobserveerde covariantie matrix\n                          Sigma = data.frame(pre = c(SD_Cpre^2, rC*SD_Cpre*SD_Cpost), \n                                             post = c(rC*SD_Cpre*SD_Cpost,SD_Cpost^2)))\n  # simuleer interventie groep pre-post data\n  data_T &lt;- MASS::mvrnorm(n = nT,\n                          # input geobserveerde gemiddelden\n                          mu = c(M_Tpre,M_Tpost),\n                          # input geobserveerde covariantie matrix\n                          Sigma = data.frame(pre = c(SD_Tpre^2, rT*SD_Tpre*SD_Tpost), \n                                             post = c(rT*SD_Tpre*SD_Tpost,SD_Tpost^2)))\n  \n  # bereken het gemiddelde verschil in pre/post verandering (de teller)\n  MeanDiff &lt;- (mean(data_T[,2]) - mean(data_T[,1])) - (mean(data_C[,2]) - mean(data_C[,1]))\n  \n  # bereken de gepoolde pre-post standaard deviatie (de deler)\n  S_Pprepost &lt;-  sqrt( ( (nT - 1)*(sd(data_T[,1])^2+sd(data_T[,2])^2) + (nC - 1)*(sd(data_C[,1])^2+sd(data_C[,2])^2) ) / (nT + nC - 2) )\n  \n  # bereken het gestandaardiseerde gemiddelde verschil voor elke bootstrap iteratie\n  boot_dPPC3[i] &lt;- MeanDiff / S_Pprepost\n}\n\n# bereken gebootstrapte standaard fout\nSE &lt;- sd(boot_dPPC3)\n\n# bereken de geobserveerde gestandaardiseerde gemiddelde verschil\ndPPC3 &lt;- ((M_Tpost- M_Tpre) - (M_Cpost - M_Cpre)) / sqrt( ( (nT - 1)*(SD_Tpre^2+SD_Tpost^2) + (nC - 1)*(SD_Cpre^2+SD_Cpost^2) ) / (nT + nC - 2) )\n\n#druk de d waarde en betrouwbaarheidsintervallen af\ndata.frame(d = MOTE::apa(dPPC3),\n           dlow = MOTE::apa(dPPC3 - 1.96*SE),\n           dhigh = MOTE::apa(dPPC3 + 1.96*SE))\n\n      d  dlow dhigh\n1 0.214 0.002 0.427\n\n\nDe output toont een pre-post interventie-effect van \\(d_{PPC3}\\) = 0,21 [0,002, 0,43].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#small-sample-bias-in-d-values",
    "href": "Standardized-Mean-Differences.html#small-sample-bias-in-d-values",
    "title": "7  Gemiddelde verschillen",
    "section": "7.6 Small Sample Bias in \\(d\\) values",
    "text": "7.6 Small Sample Bias in \\(d\\) values\nAll the estimators of \\(d\\) listed above are biased estimates of the population \\(d\\) value, specifically they all over-estimate the population value in small sample sizes. To adjust for this bias, we can apply a correction factor based on the degrees of freedom. The degrees of freedom will largely depend on the estimator used. The degrees of freedom for each estimator is listed below:\n\nSingle Group design (\\(d_s\\)): \\(df = n-1\\)\nBetween Groups - Pooled Standard Deviation (\\(d_p\\)): \\(df = n_1+n_2-2\\)\nBetween Groups - Control Group Standard Deviation (\\(d_\\Delta\\)): \\(df = n_C-1\\)\nRepeated Measures - all types (\\(d_z\\), \\(d_{rm}\\), \\(d_{av}\\), \\(d_{b}\\)): \\(df = n-1\\)\nPretest-Posttest-Control Separate Standard Deviation (\\(d_{PPC1}\\)): \\(df=n_C−1\\)\nPretest-Posttest-Control Pooled Pretest Standard Deviation (\\(d_{PPC2}\\)): \\(df=n_T+n_C−2\\)\nPretest-Posttest-Control Pooled Pretest and Posttest Standard Deviation (\\(d_{PPC3}\\)): \\(df=2(n_T+n_C−2)\\)\n\nWith the appropriate degrees of freedom, we can use the following correction factor, \\(CF\\), to obtain an unbiased estimate of the population standardized mean difference:\n\\[\nCF = \\frac{\\Gamma\\left(\\frac{df}{2}\\right)}{\\Gamma\\left(\\frac{df-1}{2}\\right)\\sqrt{\\frac{df}{2}}}\n\\]\nWhere \\(\\Gamma(\\cdot)\\) is the gamma function. An approximation of this complex formula given by Hedges (1981) can be written as \\(CF\\approx 1-\\frac{3}{4\\cdot df -1}\\). In R, this can be calculated using,\n\n# Example:\n# Group 1 sample size = 20\n# Group 2 sample size = 18\n\nn1 &lt;- 20\nn2 &lt;- 18\n\ndf &lt;- n1 + n2 - 2\n\nCF &lt;- gamma(df/2) / ( sqrt(df/2) * gamma((df-1)/2) )\n\nCF\n\n[1] 0.9789964\n\n\nThis correction factor can then be applied to any of the estimators mentioned above,\n\\[\nd^* = d\\times CF\n\\]\nThe corrected \\(d\\) value, \\(d^*\\), is commonly referred to as Hedges’ \\(g\\) or just \\(g\\). To avoid notation confusion we will just add an asterisk to \\(d\\) to denote the correction. We also need to correct the standard error for \\(d^*\\)\n\\[\nSE_{d^*} = SE_{d} \\times CF\n\\]\nThese standard errors can then be used to calculate the confidence interval of the corrected \\(d\\) value,\n\\[\nCI_{d*} = d^* \\pm 1.96\\times SE_{d^*}\n\\]\n\n# Example:\n# Cohen's d = .50, SE = .10\n\nd = .50\nSE = .10\n\n# correct d value and CIs small sample bias\nd_corrected &lt;- d * CF\nSE_corrected &lt;- SE * CF\ndlow_corrected &lt;- d_corrected - 1.96*SE_corrected\ndhigh_corrected &lt;- d_corrected + 1.96*SE_corrected\n\n# print just the d value and confidence intervals\ndata.frame(d = apa(d), \n           dlow = apa(dlow_corrected), \n           dhigh = apa(dhigh_corrected))\n\n      d  dlow dhigh\n1 0.500 0.298 0.681\n\n\nThe output shows that the corrected effect size is \\(d^*\\) = 0.50, 95% CI [0.30, 0.68].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#sec-rr",
    "href": "Standardized-Mean-Differences.html#sec-rr",
    "title": "7  Gemiddelde verschillen",
    "section": "7.7 Verhoudingen van gemiddelden",
    "text": "7.7 Verhoudingen van gemiddelden\nEen andere veelgebruikte benadering, met name op het gebied van ecologie en evolutie, is het nemen van de natuurlijke logaritme van de verhouding tussen twee gemiddelden; de zogenaamde responsratio (\\(lnRR\\)). Dit is soms gunstiger omdat, doordat bij de constructie ervan de standaarddeviatie in een of andere vorm als noemer wordt gebruikt, de verschillende versies van gestandaardiseerde gemiddelde verschillen worden beïnvloed door de schatting van deze parameter waarvoor studies vaak minder sterk zijn in vergelijking met gemiddelde grootheden (Yang et al. 2022). Voor de \\(lnRR\\) heeft de standaarddeviatie echter alleen invloed op de variantieschatting en niet op de puntschatting. Een beperking van de lnRR is echter dat deze beperkt is tot gegevens die worden waargenomen op een verhoudingsschaal (d.w.z. een absoluut nulpunt hebben en gevallen daarvan ordinaal en additief gerelateerd zijn, wat betekent dat beide gemiddelden positief zijn).\nHoewel de \\(lnRR\\) strikt genomen geen verschil in gemiddelden in additieve zin is, zoals de bovenstaande gestandaardiseerde effectgroottes voor gemiddelde verschillen, kan het in zekere zin worden beschouwd als een weergave van het verschil in gemiddelden op de multiplicatieve schaal. In feite wordt het na berekening vaak getransformeerd om het procentuele verschil of de verandering tussen de gemiddelden weer te geven: \\(100 maal \\exp(lnRR)-1\\). Dit kan echter een door transformatie geïnduceerde vertekening veroorzaken, omdat een niet-lineaire transformatie van een gemiddelde waarde over het algemeen niet gelijk is aan het gemiddelde van de getransformeerde waarde. In de context van een meta-analyse waarin \\(lnRR\\) geschat over verschillende studies worden gecombineerd, kan een correcte factor worden toegepast: \\(100 maal \\exp(lnRR+0,5 S^2_\\text{total})-1\\), waarbij \\(S^2_\\text{total}\\) de variantie van alle \\(lnRR\\) -waarden is.\nNet als voor de verschillende gestandaardiseerde gemiddelde verschillen, bestaan er verschillende berekeningen voor de lnRR, afhankelijk van de gebruikte studieopzet (zie Senior, Viechtbauer, and Nakagawa 2020).\n\n7.7.1 lnRR voor onafhankelijke groepen (\\(lnRR_{ind}\\))\nDe lnRR kan als volgt worden berekend als groepen onafhankelijk zijn,\n\\[\nlnRR_\\text{ind}=\\ln\\left(\\frac{M_T}{M_C}\\right)+CF\n\\]\nWaarbij \\(M_T\\) en \\(M_C\\) de gemiddelden zijn voor respectievelijk de behandel- en controlegroep en \\(CF\\) de kleine steekproefcorrectiefactor is, berekend als,\n\\[\nCF = \\frac{S^2_T}{2n_TM_T^2} - \\frac{S^2_C}{2n_CM_C^2}\n\\]\nDe standaardfout kan als volgt worden berekend,\n\\[\nSE_{lnRR_\\text{ind}} = \\sqrt{ \\frac{S^2_T}{n_T M_T^2} + \\frac{S^2_C}{n_C M_C^2} +\\frac{S^4_T}{2n^2_T M_T^4} + \\frac{S^4_C}{2n^2_C M_C^4}}\n\\]\nIn R kunnen we deze effectgrootte eenvoudig berekenen met de functie escalc() in het pakket metafor (Viechtbauer 2010):\n\n# lnRR voor twee onafhankelijke gropen \n# ggegeven gemiddelden en SDs\n\n# Bijvoorbeeld:\n# Groep 1 Gemiddelde = 30.4, Standaard deviatie = 22.53, Sample omvang = 96\n# Groep 2 Gemiddelde = 21.4, Standaard deviatie = 19.59, Sample omvang = 96\n\nlibrary(metafor)\n\n\n# data voorbereiden\nM1 &lt;- 30.4\nM2 &lt;- 21.4\nSD1 &lt;- 22.53\nSD2 &lt;- 19.59\nN1 = 96\nN2 = 96\n\n# bereken lnRRind en standaard fout\nlnRRind &lt;- escalc(measure = \"ROM\", \n               m1i = M1,\n               m2i = M2,\n               sd1i = SD1,\n               sd2i = SD2,\n               n1i = N1,\n               n2i = N2)\n\nlnRRind$SE &lt;- sqrt(lnRRind$vi)\n\n# bereken betrouwbaarheisinterval\nlnRRind$CIlow &lt;- lnRRind$yi - 1.96*lnRRind$SE\nlnRRind$CIhigh &lt;-  lnRRind$yi + 1.96*lnRRind$SE\n\n# druk de VR-waarde en betrouwbaarheidsintervallen af\ndata.frame(lnRRind = MOTE::apa(lnRRind$yi),\n           lnRRind_low = MOTE::apa(lnRRind$CIlow),\n           lnRRind_high = MOTE::apa(lnRRind$CIhigh))\n\n  lnRRind lnRRind_low lnRRind_high\n1   0.351       0.115        0.587\n\n\nHet voorbeeld geeft een natuurlijke log-responsratio van \\(lnRR_text{ind}\\) = 0,35 [0,12, 0,59].\n\n\n7.7.2 lnRR voor afhankelijke groepen (\\(lnRR_\\text{dep}\\))\nDe lnRR kan als volgt worden berekend als de groepen afhankelijk zijn (d.w.z. dezelfde proefpersonen in beide condities), bijvoorbeeld een pre-post vergelijking,\n\\[\nlnRR_\\text{dep} = \\ln\\left(\\frac{M_2}{M_1}\\right) + CF\n\\]\nWaarbij \\(CF\\) de kleine steekproefcorrectiefactor is, berekend als,\n\\[\nCF = \\frac{S^2_2}{2nM^2_2} - \\frac{S^2_1}{2nM^2_1}\n\\]\nDe standaardfout kan dan worden berekend als,\n\\[\n\\small{SE_{lnRR_\\text{dep}} = \\sqrt{ \\frac{S^2_1}{n M_1^2} + \\frac{S^2_2}{n M_2^2} + \\frac{S^4_1}{2n^2M^4_1} +  \\frac{S^4_2}{2n^2M^4_2} + \\frac{2rS_1 S_2}{n M_1 M_2} + \\frac{r^2S^2_1 S^2_2 (M_1^4 + M_2^4)}{2n^2 M_1^4 M_2^4}}}\n\\]\nIn R kunnen we deze effectgrootte eenvoudig berekenen met de functie escalc() uit het pakket metafor, en wel als volgt:\n\n# lnRR voor twee afhankelijke groepen\n# gegeven gemiddelden en SDs\n\n\n# Bijvoorbeeld:\n# Gemiddelde 1 = 30.4, Standaard deviatie 1 = 22.53\n# Gemiddelde 2 = 21.4, Standaard deviatie 2 = 19.59\n# Sample omvang = 96\n# Correlatie = 0.4\n\nlibrary(metafor)\n\n\n# data voorbereiden\nM1 &lt;- 30.4\nM2 &lt;- 21.4\nSD1 &lt;- 22.53\nSD2 &lt;- 19.59\nN = 96\nR = 0.4\n\n\n# bereken lnRR en standaard fout\nlnRRdep &lt;- escalc(measure = \"ROMC\", \n               m1i = M1,\n               m2i = M2,\n               sd1i = SD1,\n               sd2i = SD2,\n               ni = N,\n               ri = R)\n\n# standaardfout berekenen uit wortel van steekproefvariantie\nlnRRdep$SE &lt;- sqrt(lnRRdep$vi)\n\n\n# bereken betrouwbaarheidsinterval\nlnRRdep$CIlow &lt;- lnRRdep$yi - 1.96*lnRRdep$SE\nlnRRdep$CIhigh &lt;-  lnRRdep$yi + 1.96*lnRRdep$SE\n\n\n\n\n# druk de VR waarde en betrouwbaarheidsintervallen af\ndata.frame(lnRRdep = MOTE::apa(lnRRdep$yi),\n           lnRRdep_low = MOTE::apa(lnRRdep$CIlow),\n           lnRRdep_high = MOTE::apa(lnRRdep$CIhigh))\n\n  lnRRdep lnRRdep_low lnRRdep_high\n1   0.351       0.167        0.535\n\n\nHet voorbeeld geeft een natuurlijke logreactieverhouding van \\(lnRR_text{dep}\\) = 0,35 [0,17, 0,54].\n\n\n\n\nAlgina, James, and H. J. Keselman. 2003. “Approximate Confidence Intervals for Effect Sizes.” Educational and Psychological Measurement 63 (4): 537–53. https://doi.org/10.1177/0013164403256358.\n\n\nBaayen, R Harald, Douglas J Davidson, and Douglas M Bates. 2008. “Mixed-Effects Modeling with Crossed Random Effects for Subjects and Items.” Journal of Memory and Language 59 (4): 390–412.\n\n\nBarr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. “Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.” Journal of Memory and Language 68 (3): 255–78.\n\n\nBecker, Betsy J. 1988. “Synthesizing Standardized Mean-Change Measures - UConn Library.” British Journal of Mathematical and Statistical Psychology 41 (2): 257278. https://doi.org/https://doi.org/10.1111/j.2044-8317.1988.tb00901.x.\n\n\nCaldwell, Aaron R. 2022. “Exploring Equivalence Testing with the Updated TOSTER r Package.” PsyArXiv. https://doi.org/10.31234/osf.io/ty8de.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Academic Press.\n\n\nGlass, Gene V. 1981. “Meta-Analysis in Social Research.” (No Title). https://cir.nii.ac.jp/crid/1130000795088566912.\n\n\nGlass, Gene V., Barry McGaw, and Mary L. Smith. 1981. “Meta-Analysis in Social Research.” (No Title). https://cir.nii.ac.jp/crid/1130000795088566912.\n\n\nHedges, Larry V. 1981. “Distribution Theory for Glass’s Estimator of Effect Size and Related Estimators.” Journal of Educational Statistics 6 (2): 107–28. https://doi.org/10.3102/10769986006002107.\n\n\nLakens, Daniël. 2013. “Calculating and Reporting Effect Sizes to Facilitate Cumulative Science: A Practical Primer for t-Tests and ANOVAs.” Frontiers in Psychology 4. https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863.\n\n\nMorris, Scott B. 2008. “Estimating Effect Sizes From Pretest-Posttest-Control Group Designs.” Organizational Research Methods 11 (2): 364–86. https://doi.org/10.1177/1094428106291059.\n\n\nSenior, Alistair M., Wolfgang Viechtbauer, and Shinichi Nakagawa. 2020. “Revisiting and Expanding the Meta-Analysis of Variation: The Log Coefficient of Variation Ratio.” Research Synthesis Methods 11 (4): 553–67. https://doi.org/10.1002/jrsm.1423.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics with s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in R with the metafor Package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.\n\n\nYang, Yefeng, Helmut Hillebrand, Malgorzata Lagisz, Ian Cleasby, and Shinichi Nakagawa. 2022. “Low Statistical Power and Overestimated Anthropogenic Impacts, Exacerbated by Publication Bias, Dominate Field Studies in Global Change Biology.” Global Change Biology 28 (3): 969–89. https://doi.org/10.1111/gcb.15972.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#footnotes",
    "href": "Standardized-Mean-Differences.html#footnotes",
    "title": "7  Gemiddelde verschillen",
    "section": "",
    "text": "Let op, dit is mogelijk niet het geval, vooral als er een gemiddelde-variantie relatie is en één (meestal de interventie) groep een hogere posttest gemiddelde score heeft.↩︎",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Non-Parametric-Effect-Sizes.html#wilcoxon-mann-whitney-tests",
    "href": "Non-Parametric-Effect-Sizes.html#wilcoxon-mann-whitney-tests",
    "title": "12  Non-Parametric Tests",
    "section": "12.1 Wilcoxon-Mann-Whitney tests",
    "text": "12.1 Wilcoxon-Mann-Whitney tests\nA non-parametric alternative to the t-test is the Wilcoxon-Mann-Whitney (WMW) group of tests. When comparing two independent samples this is called a Wilcoxon rank-sum test, but sometimes referred to as a Mann-Whitney U Test. When using it on paired samples, or one sample, it is a signed rank test. These are generally referred to as tests of “symmetry” (Divine et al. 2018).\n\n# Paired samples ---- \n\ndata(sleep)\n\n# wilcoxon test\nwilcox.test(extra ~ group,\n            data = sleep,\n            paired = TRUE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  extra by group\nV = 0, p-value = 0.009091\nalternative hypothesis: true location shift is not equal to 0\n\n# Two Sample ------\n# data import from likert\ndata(mass, package = \"likert\")\ndf_mass = mass |&gt;\n  as.data.frame() |&gt;\n  janitor::clean_names() \n\n# function needs input as a numeric\n# ordered factors can be converted to ranks\n# Again, the warning can be ignored\nwilcox.test(rank(math_relates_to_my_life) ~ gender,\n            data = df_mass)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  rank(math_relates_to_my_life) by gender\nW = 23, p-value = 0.1104\nalternative hypothesis: true location shift is not equal to 0",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Non-Parametrische Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Non-Parametric-Effect-Sizes.html#brunner-munzel-tests",
    "href": "Non-Parametric-Effect-Sizes.html#brunner-munzel-tests",
    "title": "12  Non-Parametric Tests",
    "section": "12.2 Brunner-Munzel Tests",
    "text": "12.2 Brunner-Munzel Tests\nBrunner-Munzel’s tests can be used instead of the WMW tests. The primary reason is the interpretation of the test (Munzel and Brunner 2002; Brunner and Munzel 2000; Neubert and Brunner 2007). Recently, Karch (2021) argued that the Mann-Whitney test is not a decent test of equality of medians, distributions or stochastic equality. The Brunner-Munzel test, on the other hand, provides a sensible approach to test for stochastic equality.\nThe Brunner-Munzel tests measure a rank based “relative effect” or “stochastic superiority probability”. The test statistic (\\(\\hat p\\)) is essentially the probability of a value in one condition being greater than other while splitting the ties1. However, Brunner-Munzel tests can not be applied to the single group or one-sample designs.\n\\[\n\\hat{p} = P(X&lt;Y)+ \\frac{1}{2} \\cdot P(X=Y)\n\\]\nThese tests are relatively new so there are very few packages offer Brunner-Munzel. Moreover, Karch (2021) argues that the stochastic superiority effect size (\\(\\hat{p}\\)) offers a nuanced way to interpret group differences by visualizing observations as competitors in a contest. Propounded by scholars like Cliff (1993) and Divine et al. (2018), it views each observation from one group in a duel with every observation from another. If an observation from the first group surpasses its counterpart, it “wins,” and the group garners a point; tied observations yield half a point to each group. This concept can be further elucidated through a bubble plot, where placement above, below, or on the diagonal indicates the dominance of one group’s observation over the other. Other interpretations, like transforming p to the Wilcoxon-Mann-Whitney (WMW) odds or Cliff’s δ offer deeper insights. There are implementations of the Brunner-Munzel test in a few packages in R (i.e. lawstat, rankFD, and brunnermunzel). Karch (2021) recommends the brunnermunzel.permutation.test function from the brunnermunzel package. The TOSTER R package can also provide coverage (Läkens 2017; Caldwell 2022).\n\n# Install package for data cleaning\n# install.packages('janitor')\nlibrary(janitor)\n\n# Paired samples\nlibrary(TOSTER)\ndata(sleep)\n\n# When sample sizes are small\n# a permutation version should be used.\n# When this is done a seed should be set.\nset.seed(2124)\nbrunner_munzel(extra ~ group,\n               data = sleep,\n               paired = TRUE,\n               perm = TRUE)\n\n\n    Paired Brunner-Munzel permutation test\n\ndata:  extra by group\nt = -3.7266, df = 9, p-value = 0.003906\nalternative hypothesis: true relative effect is not equal to 0.5\n95 percent confidence interval:\n 0.1233862 0.3866138\nsample estimates:\np(X&lt;Y) + .5*P(X=Y) \n             0.255 \n\n# Two Sample\n# data import from likert\ndata(mass, package = \"likert\")\ndf_mass = mass |&gt;\n  as.data.frame() |&gt;\n  clean_names() \n\n# function needs input as a numeric\n# ordered factors can be converted to ranks\n# Again, the warning can be ignored\nset.seed(24111)\nTOSTER::brunner_munzel(\n  rank(math_relates_to_my_life) ~ gender,\n  data = df_mass,\n  paired = FALSE,\n  perm = TRUE\n)\n\n\n    two-sample Brunner-Munzel permutation test\n\ndata:  rank(math_relates_to_my_life) by gender\nt = -2.1665, df = 17.953, p-value = 0.0642\nalternative hypothesis: true relative effect is not equal to 0.5\n95 percent confidence interval:\n 0.04761905 0.54961243\nsample estimates:\np(X&lt;Y) + .5*P(X=Y) \n         0.2738095",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Non-Parametrische Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Non-Parametric-Effect-Sizes.html#rank-based-effect-sizes",
    "href": "Non-Parametric-Effect-Sizes.html#rank-based-effect-sizes",
    "title": "12  Non-Parametric Tests",
    "section": "12.3 Rank-Based Effect Sizes",
    "text": "12.3 Rank-Based Effect Sizes\nSince the mean and standard deviation are not estimated for a WMW or Brunner-Munzel test, it would be inappropriate to present a standardized mean difference (e.g., Cohen’s d) to accompany these tests. Instead, a rank based effect size (i.e., based on the ranks of the observed values) can be reported to accompany the non-parametric statistical tests.\n\n12.3.1 Rank-Biserial Correlation\nThe rank-biserial correlation (\\(r_{rb}\\)) is considered a measure of dominance. The correlation represents the difference between the proportion of favorable and unfavorable pairs or signed ranks. Larger values indicate that more of \\(X\\) is larger than more of \\(Y\\), with a value of (−1) indicates that all observations in the second, \\(Y\\), group are larger than the first, \\(X\\), group, and a value of (+1) indicates that all observations in the first group are larger than the second.\n\n12.3.1.1 Dependent Groups\n\nCalculate difference scores between pairs:\n\n\\[\nD = X_2 - X_1\n\\]\n\nCalculate the positive and negative rank sums:\n\n\\[\n\\text{When } D_i&gt;0,\\;\\;  R_{\\oplus} = \\sum_{i=1} -1\\cdot \\text{sign}(D_i) \\cdot \\text{rank}(|D_i|)\n\\]\n\\[\n\\text{When } D_i&lt;0,\\;\\;  R_{\\ominus} = \\sum_{i=1} -1\\cdot \\text{sign}(D_i) \\cdot \\text{rank}(|D_i|)\n\\]\n\nWe can set a constant, \\(H\\), to be -1 when the rank positive rank sum is greater than or equal to the negative rank sum (\\(R_{\\oplus} \\ge R_{\\ominus}\\)) or we can set \\(H\\) to 1 when the rank positive rank sum is less than the negative rank sum (\\(R_{\\oplus} &lt; R_{\\ominus}\\)).\n\n\\[\nH = \\begin{cases} -1 &  R_{\\oplus} \\ge  R_{\\ominus} \\\\ 1 & R_{\\oplus} &lt; R_{\\ominus} \\end{cases}\n\\]\n\nCalculate rank-biserial correlation:\n\n\\[\nr_{rb} = 4H\\times \\left| \\frac{\\min( R_{\\oplus}, R_{\\ominus}) - .5\\times ( R_{\\oplus} +  R_{\\ominus})}{n(n + 1)} \\right|\n\\]\n\nFor paired samples, or one sample, the standard error is calculated as the following:\n\n\\[\nSE_{r_{rb}} = \\sqrt{ \\frac {2(2 n^3 + 3 n^2 + n)} {6(n^2 + n)} }\n\\]\n\nThe confidence intervals can then be calculated by Z-transforming the correlation.\n\n\\[\nZ_{rb} = \\text{arctanh}(r_{rb})\n\\]\n\nCalculate the standard error of the Z-transformed correlation\n\n\\[\nSE_{Z_{rb}} = \\frac{SE_{r_{rb}}}{1-r_{rb}^2}\n\\]\n\nThen the confidence interval can be calculated and then back-transformed.\n\n\\[\nCI_{r_{rb}} = \\text{tanh}(Z_{rb}  \\pm  1.96 \\cdot SE_{Z_{rb}})\n\\] In R, we can use the ses_calc() function in TOSTER package (Läkens 2017). For the following example, we will calculate the rank-biserial correlation in the sleep dataset:\n\n# Dependent groups\n\ndata(sleep)\nlibrary(TOSTER)\n\n# When sample sizes are small\n# a permutation version should be used.\n# When this is done a seed should be set.\nset.seed(2124)\nses_calc(extra ~ group,\n         data = sleep,\n         paired = TRUE)\n\n                           estimate lower.ci  upper.ci conf.level\nRank-Biserial Correlation 0.9818182 0.928369 0.9954785       0.95\n\n\nThe example shows a rank-biserial correlation is \\(r_{rb}\\) = .982 [.938, .995]. This suggests that nearly every individual in the sample showed an increase in condition 2 relative to condition 1. As you can see from the figure below, only one individual showed a decline (individual shown in red).\n\n\n\n\n\n\n\n\n\n\n\n12.3.1.2 Independent Groups\n\nCalculate the ranks for each observation across all observations of in group 1 and 2\n\n\\[\nR = \\text{rank}(X)\n\\]\n\nCalculate the rank sums from each group\n\n\\[\nU_1 = \\left(\\sum_{i=1}^{n_1} R_{1i}\\right) - n_1 \\cdot \\frac{n_1 + 1}{2}\n\\]\n\\[\nU_2 = \\left(\\sum_{i=1}^{n_2} R_{2i}\\right) - n_2 \\cdot \\frac{n_2 + 1}{2}\n\\]\n\nCalculate rank biserial correlation\n\n\\[\nr_{rb} = \\frac{U_1}{n_1 n_2} - \\frac{U_2}{n_1 n_2}\n\\]\n\nFor independent samples, the standard error is calculated as the following:\n\n\\[\nSE_{rb} = \\sqrt{\\frac {n_1 + n_2 + 1} { 3  n_1  n_2}}\n\\]\n\nThe confidence intervals can then be calculated by transforming the estimate.\n\n\\[\nZ_{rb} = \\text{arctanh}(r_{rb})\n\\]\n\nCalculate the standard error of the Z-transformed correlation\n\n\\[\nSE_{Z_{rb}} = \\frac{SE_{r_{rb}}}{1-r_{rb}^2}\n\\]\n\nThen the confidence interval can be calculated and then back-transformed.\n\n\\[\nCI_{r_{rb}} = \\text{tanh}(Z_{rb}  \\pm  1.96 \\cdot SE_{Z_{rb}})\n\\]\nIn R, we can use ses_calc in the TOSTER package can be utilized to calculate \\(r_{rb}\\).\n\n# Two Sample\n# install the janitor package for data cleaning\n# clean and import data from likert\ndata(mass, package = \"likert\")\ndf_mass = mass |&gt;\n  as.data.frame() |&gt;\n  janitor::clean_names() \n\n# function needs input as a numeric\n# ordered factors can be converted to ranks\n# Again, the warning can be ignored\nset.seed(24111)\nses_calc(\n  rank(math_relates_to_my_life) ~ gender,\n  data = df_mass,\n  paired = FALSE\n)\n\n                           estimate   lower.ci   upper.ci conf.level\nRank-Biserial Correlation -0.452381 -0.7831567 0.07794462       0.95\n\n\nThe example shows a rank-biserial correlation is \\(r_{rb}\\) = -.45 [-.78, .08].\n\n\n\n12.3.2 Concordance Probability\nIn the two sample case, concordance probability is the probability that a randomly chosen subject from one group has a response that is larger than that of a randomly chosen subject from the other group. In the two sample case, this is roughly equivalent to the statistic of the Brunner-Munzel test. In the paired sample case, it is the probability that a randomly chosen difference score (\\(D\\)) will have a positive (+) sign plus 0.5 times the probability of a tie (no/zero difference). The concordance probability can go by many names. It is also referred to as the c-index, the non-parametric probability of superiority, or the non-parametric common language effect size (CLES).\nThe calculation of concordance can be derived from the rank-biserial correlation. The concordance probability (\\(p_c\\)) can be converted from the correlation.\n\\[\np_c = \\frac{r_{rb} + 1 }{2}\n\\]\nIn R, we can use the ses_calc() function again along with the sleep data set. For repeated measures experiments, the concordance probability in dependent groups can be calculated utilizing the paired=TRUE argument in the ses_calc() function:\n\n# Dependent Groups\nlibrary(TOSTER)\n\ndata(sleep)\n\nses_calc(extra ~ group,\n         data = sleep,\n         paired = TRUE,\n         ses = \"c\")\n\n             estimate  lower.ci  upper.ci conf.level\nConcordance 0.9909091 0.9641845 0.9977392       0.95\n\n\nFor two independent groups, the concordance probability can be calculated similarly without specifying the paired argument:\n\n# Independent Groups\n# data import from likert\ndata(mass, package = \"likert\")\ndf_mass = mass |&gt;\n  as.data.frame() |&gt;\n  janitor::clean_names()\n\nses_calc(rank(math_relates_to_my_life) ~ gender,\n         data = df_mass,\n         ses = \"c\")\n\n             estimate  lower.ci  upper.ci conf.level\nConcordance 0.2738095 0.1084217 0.5389723       0.95\n\n\n\n\n12.3.3 Wilcoxon-Mann-Whitney Odds\nThe Wilcoxon-Mann-Whitney odds (O’Brien and Castelloe 2006), also known as the “Generalized Odds Ratio”(Agresti 1980), essentially transforms the concordance probability into an odds ratio.\nThe odds can be converted from the concordance by taking the logit of the concordance. This will provide the log odds.\n\\[\nO_{WMW} = \\exp \\left[\\text{logit}(p_c)\\right]\n\\]\nThe exponential value of the log-odds will provide the odds on a more interpretable scale. Taking just the logit of the concordance probability would give us the log odds such that,\n\\[\n\\log(O_{WMW}) = \\text{logit}(p_c)\n\\]\nIn R, we can calculate \\(O_{WMW}\\) by using the ses_calc() function from the TOSTER package:\n\n# Dependent Groups\n\ndata(sleep)\n\nTOSTER::ses_calc(extra ~ group,\n                       data = sleep,\n                       paired = TRUE,\n                 ses = \"odds\")\n\n         estimate lower.ci upper.ci conf.level\nWMW Odds      109 26.92087 441.3305       0.95\n\n\nWe can also calculate \\(O_{WMW}\\) in independent groups using the same function:\n\n# Independent Groups\n\n# data import from likert\ndata(mass, package = \"likert\")\ndf_mass = mass |&gt;\n  as.data.frame() |&gt;\n  janitor::clean_names()\n\nTOSTER::ses_calc(  rank(math_relates_to_my_life) ~ gender,\n  data = df_mass,\n                 ses = \"odds\")\n\n          estimate  lower.ci upper.ci conf.level\nWMW Odds 0.3770492 0.1216064 1.169067       0.95\n\n\n\n\n\n\nAgresti, Alan. 1980. “Generalized Odds Ratios for Ordinal Data.” Biometrics, 59–67.\n\n\nBrunner, Edgar, and Ullrich Munzel. 2000. “The Nonparametric Behrens-Fisher Problem: Asymptotic Theory and a Small-Sample Approximation.” Biometrical Journal 42 (1): 17–25. https://doi.org/10.1002/(SICI)1521-4036(200001)42:1&lt;17::AID-BIMJ17&gt;3.0.CO;2-U.\n\n\nCaldwell, Aaron R. 2022. “Exploring Equivalence Testing with the Updated TOSTER r Package.” PsyArXiv. https://doi.org/10.31234/osf.io/ty8de.\n\n\nCliff, Norman. 1993. “Dominance Statistics: Ordinal Analyses to Answer Ordinal Questions.” Psychological Bulletin 114 (3): 494.\n\n\nDivine, George W, H James Norton, Anna E Barón, and Elizabeth Juarez-Colunga. 2018. “The Wilcoxon–Mann–Whitney Procedure Fails as a Test of Medians.” The American Statistician 72 (3): 278–86.\n\n\nKarch, Julian D. 2021. “Psychologists Should Use Brunner-Munzel’s Instead of Mann-Whitney’s u Test as the Default Nonparametric Procedure.” Advances in Methods and Practices in Psychological Science 4 (2): 2515245921999602.\n\n\nLäkens, Daniel. 2017. “Equivalence Tests: A Practical Primer for t-Tests, Correlations, and Meta-Analyses.” Social Psychological and Personality Science 1: 1–8. https://doi.org/10.1177/1948550617697177.\n\n\nLiddell, Torrin M., and John K. Kruschke. 2018. “Analyzing Ordinal Data with Metric Models: What Could Possibly Go Wrong?” Journal of Experimental Social Psychology 79 (November): 328–48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nMunzel, Ullrich, and Edgar Brunner. 2002. “An Exact Paired Rank Test.” Biometrical Journal 44 (5): 584–93. https://doi.org/10.1002/1521-4036(200207)44:5&lt;584::AID-BIMJ584&gt;3.0.CO;2-9.\n\n\nNeubert, Karin, and Edgar Brunner. 2007. “A Studentized Permutation Test for the Non-Parametric Behrensfisher Problem.” Computational Statistics & Data Analysis 51 (10): 5192–5204. https://doi.org/10.1016/j.csda.2006.05.024.\n\n\nO’Brien, Ralph G, and John Castelloe. 2006. “Exploiting the Link Between the Wilcoxon-Mann-Whitney Test and a Simple Odds Statistic.” In Proceedings of the Thirty-First Annual SAS Users Group International Conference, 209–31. Citeseer.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Non-Parametrische Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Non-Parametric-Effect-Sizes.html#footnotes",
    "href": "Non-Parametric-Effect-Sizes.html#footnotes",
    "title": "12  Non-Parametric Tests",
    "section": "",
    "text": "Note, for paired samples, this does not refer to the probability of an increase/decrease in paired sample but rather the probability that a randomly sampled value of X will be greater/less than Y. This is also referred to as the “relative” effect in the literature. Therefore, the results will differ from the concordance probability.↩︎",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Non-Parametrische Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Regression.html#regression-overview",
    "href": "Regression.html#regression-overview",
    "title": "13  Regression",
    "section": "13.1 Regression Overview",
    "text": "13.1 Regression Overview\nIn a simple linear regression there is only one predictor (\\(x\\)) and one outcome (\\(y\\)) in the regression model,\n\\[\ny = b_0 + b_1 x + e\n\\]\nWe can visualize this model by showing data from the palmer penguins data package:\n\n\n\n\n\nwhere \\(b_0\\) is the intercept coefficient, \\(b_1\\) is the slope coefficient, and \\(e\\) is the error term that is normally distributed with a mean of zero and a variance of \\(\\sigma^2\\). For a simple linear regression we can obtain an unstandardized regression coefficient by finding the optimal value of \\(b_0\\) and \\(b_1\\) that minimizes the variance in \\(e\\), namely, \\(\\sigma^2\\). In a multiple regression we can model \\(y\\) as a function of multiple predictor variables such that,\n\\[\ny = b_0 + b_1 x_{1} + b_2 x_{2} +... + e\n\\] Where the coefficients are all optimized jointly to minimize the error variance. The line produced by the regression equation is our predicted values of \\(y_i\\), however it can also be interpreted as the mean of \\(y\\) given some value of \\(x\\). In a regression equation we can construct more complex models that include non-linear terms such as interactions or polynomials (or any sort of function of \\(x\\)). For example, we can create a model where we include a main effect, \\(x_1\\), a quadratic polynomial term, \\(x^2_1\\) and an interaction term, \\(x_1 x_2\\),\n\\[\ny_i = b_0 + b_1 x_{1} + b_2 x^2_{2}  + b_2 x_{1} x_{2} + e_i\n\\]"
  },
  {
    "objectID": "Regression.html#effect-sizes-for-a-linear-regression",
    "href": "Regression.html#effect-sizes-for-a-linear-regression",
    "title": "13  Regression",
    "section": "13.2 Effect Sizes for a Linear Regression",
    "text": "13.2 Effect Sizes for a Linear Regression\nIf we want to calculate the variance explained in the outcome by all the predictor variables, we can compute an \\(R^2\\) value. The \\(R^2\\) value can be interpreted one of two ways:\n\nthe variance in \\(y\\) explained by the predictor variables\nthe square of the correlation between predicted \\(y\\) values and observed (actual) \\(y\\) values\n\nLikewise we can also take the square root of \\(R^2\\) to get the correlation between predicted and observed \\(y\\) values. We can construct an linear regression model quite easily in base R using the lm() function. We will use the palmerpenguins dataset for our example.\n\nlibrary(palmerpenguins)\n\n\nmdl &lt;- lm(bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n          data = penguins)\n\nsummary(mdl)\n\n\nCall:\nlm(formula = bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n    data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.8831  -2.7734  -0.3268   2.3128  19.7630 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -28.14701    5.51435  -5.104 5.54e-07 ***\nflipper_length_mm   0.30569    0.01902  16.073  &lt; 2e-16 ***\nbill_depth_mm       0.62103    0.13543   4.586 6.38e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.009 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4638,    Adjusted R-squared:  0.4607 \nF-statistic: 146.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nWe will notice that the linear regression summary returns two \\(R^2\\) values. The first one is the traditional \\(R^2\\) and the other is the adjusted \\(R^2\\). The adjusted \\(R^2_\\text{adj}\\) applies a correction factor since \\(R^2\\) it is often bias when there are more predictor variables and a smaller sample size. If we want to know the contribution for each term in the regression model, we can also use semi-partial \\(sr^2\\) values that are similar to partial eta-squared in the ANOVA section of this book. In R, we can calculate \\(sr^2\\) with the r2_semipartial() function in the effectsize package (Ben-Shachar, Lüdecke, and Makowski 2020):\n\nlibrary(effectsize)\n\nr2_semipartial(mdl,alternative = \"two.sided\")\n\nTerm              |  sr2 |       95% CI\n---------------------------------------\nflipper_length_mm | 0.41 | [0.33, 0.49]\nbill_depth_mm     | 0.03 | [0.01, 0.06]\n\n\nA standardized effect size for each term could also be calculated from standardizing the regression coefficients. Standardized regression coefficients are calculated by re-scaling the predictor and outcome variables to be z-scores (i.e., setting the mean and variance to be zero and one, respectively).\n\nstand_mdl &lt;- lm(scale(bill_length_mm) ~ scale(flipper_length_mm) + scale(bill_depth_mm), \n                data = penguins)\n\nsummary(stand_mdl)\n\n\nCall:\nlm(formula = scale(bill_length_mm) ~ scale(flipper_length_mm) + \n    scale(bill_depth_mm), data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9934 -0.5080 -0.0599  0.4236  3.6199 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              2.898e-16  3.971e-02   0.000        1    \nscale(flipper_length_mm) 7.873e-01  4.899e-02  16.073  &lt; 2e-16 ***\nscale(bill_depth_mm)     2.246e-01  4.899e-02   4.586 6.38e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7344 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4638,    Adjusted R-squared:  0.4607 \nF-statistic: 146.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nAlternatively, we can use the standardise function in the effectsize package:\n\nstandardise(mdl)\n\n\nCall:\nlm(formula = bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n    data = data_std)\n\nCoefficients:\n      (Intercept)  flipper_length_mm      bill_depth_mm  \n        2.898e-16          7.873e-01          2.246e-01",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Regression.html#pearson-correlation-vs-regression-coefficients-in-simple-linear-regressions",
    "href": "Regression.html#pearson-correlation-vs-regression-coefficients-in-simple-linear-regressions",
    "title": "13  Regression",
    "section": "13.3 Pearson correlation vs regression coefficients in simple linear regressions",
    "text": "13.3 Pearson correlation vs regression coefficients in simple linear regressions\nA slope coefficient in a simple linear regression model can be defined as the covariance between predictor \\(x\\) and outcome \\(y\\) divided by the variance in \\(x\\),\n\\[\nb_1 = \\frac{\\text{Cov}(x,y)}{S_x^2}\n\\]\nWhere \\(S_x\\) is the standard deviation of \\(x\\) (the square of the standard deviation is the variance). A Pearson correlation is defined as,\n\\[\nr = \\frac{\\text{Cov}(x,y)}{S_xS_y}\n\\]\nWe can see that these formulas are quite similar, in fact we can express \\(r\\) as a function of \\(b_1\\) such that,\n\\[\nr = b_1 \\frac{S_x}{S_y}\n\\]\nWhich means that if \\(S_x=S_y\\) then \\(r = b_1\\). Furthermore, if the regression coefficient is standardized this would make the outcome and predictor variable to both have a variance of 1, thus making \\(S_x=S_y = 1\\). Therefore a standardized regression coefficient is equal to a pearson correlation.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Regression.html#multi-level-regression-models",
    "href": "Regression.html#multi-level-regression-models",
    "title": "13  Regression",
    "section": "13.4 Multi-Level Regression models",
    "text": "13.4 Multi-Level Regression models\nWe can allow the regression coefficients such as the intercept and slope to vary randomly with respect to some grouping variable. For example, lets say we think that the intercept will vary between the different species of penguins when we look at the relationship between body mass and bill length. Using the lme4 package in R, we can construct a model that allows the intercept coefficient to vary between species.\n\nlibrary(palmerpenguins)\nlibrary(lme4)\n\n\nml_mdl &lt;- lmer(bill_length_mm ~ 1 + flipper_length_mm + (1 | species),\n            data = penguins)\nsummary(ml_mdl)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: bill_length_mm ~ 1 + flipper_length_mm + (1 | species)\n   Data: penguins\n\nREML criterion at convergence: 1640.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5568 -0.6666  0.0109  0.7020  4.7678 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n species  (Intercept) 20.06    4.479   \n Residual              6.74    2.596   \nNumber of obs: 342, groups:  species, 3\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)        1.81165    4.97514   0.364\nflipper_length_mm  0.21507    0.02113  10.177\n\nCorrelation of Fixed Effects:\n            (Intr)\nflppr_lngt_ -0.854\n\n\nNote in the table that we have random effects and fixed effects. The random effects shows the grouping (categorical) variable that the parameter is allowed to vary on and then it shows the parameter that is varying, which in our case is the intercept coefficient. It also includes the variance of the intercept, which is the extent to which the intercept varies between species. For the fixed effect terms, we see the intercept displayed as well as the slope, this shows the mean of the intercept across species and, since the slope is equal across species, the slope is just a single value. Let’s visualize how this model looks:\n\n\n\n\n\n\n\n\n\nNotice that in the plot above the slopes are fixed and equal between each species and only the intercepts (i.e., the vertical height of each line) differs. We can also allow the slope to vary if we may choose by editing the formula:\n\nlibrary(palmerpenguins)\nlibrary(lme4)\n\n\nml_mdl &lt;- lmer(bill_length_mm ~ 1 + flipper_length_mm + (1 + flipper_length_mm | species),\n            data = penguins)\nsummary(ml_mdl)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: bill_length_mm ~ 1 + flipper_length_mm + (1 + flipper_length_mm |  \n    species)\n   Data: penguins\n\nREML criterion at convergence: 1638.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6326 -0.6657  0.0083  0.6843  4.9531 \n\nRandom effects:\n Groups   Name              Variance  Std.Dev. Corr \n species  (Intercept)       3.0062118 1.73384       \n          flipper_length_mm 0.0007402 0.02721  -0.61\n Residual                   6.6886861 2.58625       \nNumber of obs: 342, groups:  species, 3\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)        1.56035    4.32870   0.360\nflipper_length_mm  0.21609    0.02623   8.237\n\nCorrelation of Fixed Effects:\n            (Intr)\nflppr_lngt_ -0.863\noptimizer (nloptwrap) convergence code: 0 (OK)\nunable to evaluate scaled gradient\nModel failed to converge: degenerate  Hessian with 1 negative eigenvalues\n\n\nVarying the slope will include flipper_length_mm in the random effects terms. Also note that the summary returns the correlation between random effect terms, which may be useful to know if there is a strong relationship between the intercept and slope across species. Now we see that the random effects terms now include the slope coefficient corresponding to the flipper_length_mm predictor variable. Let’s visualize\n\n\n\n\n\n\n\n\n\nThe plot above shows slight variation in the slope between the three species, however the slope does not vary all that much. For multi-level models we can compute a conditional \\(R^2\\) and a marginal \\(R^2\\) which are each described below\n\nMarginal \\(R^2\\): the variance explained solely by the fixed effects\nConditional \\(R^2\\): the variance explained in the whole model, including both the fixed effects and random effects terms.\n\nIn R, we can use the MuMIn package (Bartoń 2023) to compute both the marginal and conditional \\(R^2\\):\n\nlibrary(MuMIn)\n\nr.squaredGLMM(ml_mdl)\n\n           R2m       R2c\n[1,] 0.2470201 0.8210591\n\n\n\n\n\n\nBartoń, Kamil. 2023. MuMIn: Multi-Model Inference. https://CRAN.R-project.org/package=MuMIn.\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Artifacts-and-Bias.html#resources",
    "href": "Artifacts-and-Bias.html#resources",
    "title": "14  Artifacts and Bias in Effect Sizes",
    "section": "14.1 Resources",
    "text": "14.1 Resources\nEffect size estimates such as correlation coefficients and Cohen’s \\(d\\) values can be severely biased due to various statistical artifacts such as measurement error and selection effects (e.g., range restriction). Methods have been developed to correct for the bias in effect sizes and thus these corrections are called “artifact corrections”. Artifact correction formulas can be complex and therefore readers are referred to other resources listed below:\n\nJané (2023) : An open-access textbook that contains equations and R code for various types of artifact corrections. Not yet released.\nHunter and Schmidt (1990) : Classic textbook on the topic of artifact corrections. Hunter and Schmidt pioneered the methodology for artifact correction style meta-analyses.\nWiernik and Dahlke (2020) : A paper that serves as a condensed version of Hunter and Schmidt’s book. It contains most of the equations necessary to correct effect sizes.\nDahlke and Wiernik (2019) : An R package for conducting artifact correction meta-analyses. Contains all the functions one would need to correct effect sizes for artifacts in R."
  },
  {
    "objectID": "Artifacts-and-Bias.html#correcting-for-measurement-error",
    "href": "Artifacts-and-Bias.html#correcting-for-measurement-error",
    "title": "14  Artifacts and Bias in Effect Sizes",
    "section": "14.2 Correcting for Measurement Error",
    "text": "14.2 Correcting for Measurement Error\nIf we have reliability estimates of the variables of interest, we can correct a Pearson correlation or a standardized mean difference (Cohen’s \\(d\\)) for measurement error. Non-differential measurement error attenuates Pearson correlations and Cohen’s \\(d\\) therefore we can apply correction factors to adjust for this bias. For a pearson correlation, we can use the correction for attenuation first developed by Spearman (1904),\n\\[\nr_c  = \\frac{r_\\text{obs}}{\\sqrt{r_{xx'}r_{yy'}}}\n\\tag{14.1}\\] where \\(r_c\\) is the corrected correlation, \\(r_\\text{obs}\\) is the observed correlation, \\(r_{xx'}\\) is the reliability of \\(x\\), and \\(r_{yy'}\\) is the reliability of \\(y\\). reliability coefficients can be estimated a number of different ways however the two of the most common estimators is Cronbach Alpha and Test-retest reliability. Alpha measures the internal consistency of a set of sub-component measurements (e.g., question responses on a questionnaire) while test-retest reliability measures the stability over time.\nA Cohen’s \\(d\\) can be corrected similarly to a correlation coefficient, however since it only has one continuous variable we can just correct for reliability in the continuous variable\n\\[\nd_c  = \\frac{d_\\text{obs}}{\\sqrt{r_{yy'}}}\n\\] However in the case of a Cohen’s d, it is important that \\(r_{yy'}\\) is the pooled within-group reliability (calculate pooled reliability the same way you calculate the pooled standard deviation for denominator of Cohen’s \\(d\\)). If all you have is the total sample reliability (more commonly reported) you can follow this three step process (Wiernik and Dahlke 2020),\n\nConvert the d value to a point-biserial correlation (see section on conversions)\nCorrect the point-biserial correlation using Equation 14.1 (setting \\(r_{xx'}=1\\))\nConvert it back to a Cohen’s \\(d\\)\n\nNote that confidence intervals for \\(r_c\\) and \\(d_c\\) must also be corrected. For example, a pearson correlation would need to be corrected such that, \\[\nCI_{r_c} = \\left[\\frac{r_\\text{lower-bound}}{\\sqrt{r_{xx'}r_{yy'}}},\\frac{r_\\text{upper-bound}}{\\sqrt{r_{xx'}r_{yy'}}}\\right]\n\\]"
  },
  {
    "objectID": "Artifacts-and-Bias.html#correcting-for-range-restriction",
    "href": "Artifacts-and-Bias.html#correcting-for-range-restriction",
    "title": "14  Artifacts and Bias in Effect Sizes",
    "section": "14.3 Correcting for Range Restriction",
    "text": "14.3 Correcting for Range Restriction\nRange restriction corrections can be quite complex depending on the selection process. The process for correcting Pearson correlations and Cohen’s \\(d\\) for range restriction is laid out in table 3 of Wiernik and Dahlke (2020).\n\n\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “psychmeta: An r Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nHunter, John E., and Frank L. Schmidt. 1990. Methods of meta-analysis: correcting error and bias in research findings. Newbury Park: Sage Publications.\n\n\nJané, Matthew B. 2023. Artifact Corrections for Effect Sizes: Implementation in r and Application to Meta-Analysis. (n.p.). https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/.\n\n\nSpearman, C. 1904. “The Proof and Measurement of Association Between Two Things.” International Journal of Epidemiology 39 (5): 1137–50. https://doi.org/10.1093/ije/dyq191.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.” Advances in Methods and Practices in Psychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611."
  },
  {
    "objectID": "Converting-to-Cohens-d.html#from-independent-samples-t-statistic",
    "href": "Converting-to-Cohens-d.html#from-independent-samples-t-statistic",
    "title": "15  Converting to Cohen’s \\(d\\)",
    "section": "15.1 From Independent Samples \\(t\\)-statistic",
    "text": "15.1 From Independent Samples \\(t\\)-statistic\nTo calculate a between subject standardized mean difference (\\(d_p\\), i.e., pooled standard deviation standardizer), we can use the sample size in each group (\\(n_1\\) and \\(n_2\\)) as well as the \\(t\\)-statistic from an independent sample t-test and plug it into the following formula:\n\\[\nd_{p} = t\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2} }\n\\]\nUsing the t_to_d function in the effectsize package we can convert \\(t\\) to \\(d_p\\).\n\n# Example:\n# unpaired t-statistic = 3.25\n# n1 = 50, n2 = 40\n\nlibrary(effectsize)\n\nt &lt;- 3.25\nn1 &lt;- 50\nn2 &lt;- 40\n\nt_to_d(t, df_error = n1+n2-2, paired = FALSE)\n\nd    |       95% CI\n-------------------\n0.69 | [0.26, 1.12]"
  },
  {
    "objectID": "Converting-to-Cohens-d.html#from-paired-sample-t-statistic",
    "href": "Converting-to-Cohens-d.html#from-paired-sample-t-statistic",
    "title": "15  Converting to Cohen’s \\(d\\)",
    "section": "15.2 From Paired Sample \\(t\\)-statistic",
    "text": "15.2 From Paired Sample \\(t\\)-statistic\nTo calculate a within-subject standardized mean difference (\\(d_z\\), i.e., difference score standardizer), we can use the sample size in each group (\\(n_1\\) and \\(n_2\\)) as well as the \\(t\\)-statistic from an paired sample t-test and plug it into the following formula:\n\\[\nd_{z} = \\frac{t}{\\sqrt{n}}\n\\]\nUsing the t_to_d function in the effectsize package we can convert \\(t\\) to \\(d_z\\).\n\n# Example:\n# paired t-statistic = 3.25\n# n = 50\n\nt &lt;- 3.25\nn &lt;- 50\n\nt_to_d(t, df_error = n-1, paired = TRUE)\n\nd    |       95% CI\n-------------------\n0.46 | [0.17, 0.76]"
  },
  {
    "objectID": "Converting-to-Cohens-d.html#from-pearson-correlation",
    "href": "Converting-to-Cohens-d.html#from-pearson-correlation",
    "title": "15  Converting to Cohen’s \\(d\\)",
    "section": "15.3 From Pearson Correlation",
    "text": "15.3 From Pearson Correlation\nIf a Pearson correlation is calculated between a continuous score and a dichotomous score, this is considered a point-biserial correlation. The point-biserial correlation can be converted into a \\(d_p\\) value using the following formula:\n\\[\nd_p = \\frac{r}{\\sqrt{1-r^2}} \\sqrt{\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}\n\\] Or if sample sizes within each group are unknown (or equal), the equation simplifies to be approximately,\n\\[\nd_p \\approx \\frac{r\\sqrt{4}}{\\sqrt{1-r^2}}\n\\]\nUsing the r_to_d function in the effectsize package we can convert \\(r\\) to \\(d_p\\).\n\n# Example:\n# r = 3.25\n# n1 = 50, n2 = 40\n\nr &lt;- .50\nn1 &lt;- 50\nn2 &lt;- 40\n\nr_to_d(r = r, n1 = n1, n2 = n2)\n\n[1] 1.148913"
  },
  {
    "objectID": "Converting-to-Cohens-d.html#from-odds-ratio",
    "href": "Converting-to-Cohens-d.html#from-odds-ratio",
    "title": "15  Converting to Cohen’s \\(d\\)",
    "section": "15.4 From Odds-Ratio",
    "text": "15.4 From Odds-Ratio\nAn odds-ratio from a contingency table can also be converted to a \\(d_p\\). Note that this formula is an approximation:\n\\[\nd_{p} = \\frac{\\log(OR)\\sqrt{3}}{\\pi}\n\\]\nUsing the oddsratio_to_d function in the effectsize package we can convert \\(OR\\) to \\(d_p\\).\n\n# Example:\n# OR = 1.62\n\nOR &lt;- 1.46\n\noddsratio_to_d(OR = OR)\n\n[1] 0.2086429"
  },
  {
    "objectID": "Converting-to-Correlation.html#from-t-statistic",
    "href": "Converting-to-Correlation.html#from-t-statistic",
    "title": "16  Converting to Pearson Correlation",
    "section": "16.1 From \\(t\\)-statistic",
    "text": "16.1 From \\(t\\)-statistic\nFrom a \\(t\\) statistic calculated from a correlational test, we can calculate the correlation coefficient using the following formula:\n\\[\nr = \\sqrt{\\frac{t^2}{t^2 + n-2}}\n\\]\nUsing the t_to_r function in the effectsize package we can convert \\(t\\) to \\(r\\).\n\n# Example:\n# t = 4.14, n = 50\n\nlibrary(effectsize)\n\nt &lt;- 4.14\nn &lt;- 50\n\nt_to_r(t = t, df = n-2)\n\nr    |       95% CI\n-------------------\n0.51 | [0.28, 0.67]"
  },
  {
    "objectID": "Converting-to-Correlation.html#from-cohens-d",
    "href": "Converting-to-Correlation.html#from-cohens-d",
    "title": "16  Converting to Pearson Correlation",
    "section": "16.2 From Cohen’s \\(d\\)",
    "text": "16.2 From Cohen’s \\(d\\)\nFrom a between groups Cohen’s \\(d\\) value (\\(d_p\\)), we can calculate the correlation coefficient from the following formula:\n\\[\nr = \\frac{d_p}{\\sqrt{d_p^2+\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}\n\\]\nUsing the d_to_r function in the effectsize package we can convert \\(d_p\\) to \\(r\\).\n\n# Example:\n# d = 0.60, n1 = 50, n2 = 70\n\nd &lt;- 0.60\nn1 &lt;- 50\nn2 &lt;- 70\n\nd_to_r(d = d, n1 = n1, n2 = n2)\n\n[1] 0.2858532",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Omrekenen naar Correlaties</span>"
    ]
  },
  {
    "objectID": "Converting-to-Correlation.html#from-odds-ratio",
    "href": "Converting-to-Correlation.html#from-odds-ratio",
    "title": "16  Converting to Pearson Correlation",
    "section": "16.3 From Odds-Ratio",
    "text": "16.3 From Odds-Ratio\nThe correlation coefficient from an odds ratio can be calculated with the following formula:\n\\[\nr = \\frac{\\log(OR)\\times\\sqrt{3}}{\\pi\\sqrt{\\frac{3\\log(OR)^2}{\\pi^2}+\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}\n\\]\nUsing the oddsratio_to_r function in the effectsize package we can convert \\(OR\\) to \\(r\\).\n\n# Example:\n# OR = 2.21, n1 = 50, n2 = 70\n\nOR &lt;- 2.21\nn1 &lt;- 50\nn2 &lt;- 70\n\noddsratio_to_r(OR=OR, n1 = n1, n2 = n2)\n\n[1] 0.2124017",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Omrekenen naar Correlaties</span>"
    ]
  },
  {
    "objectID": "Converting-to-Odds-Ratio.html#from-cohens-d",
    "href": "Converting-to-Odds-Ratio.html#from-cohens-d",
    "title": "17  Converting to Odds Ratio",
    "section": "17.1 From Cohen’s \\(d\\)",
    "text": "17.1 From Cohen’s \\(d\\)\nWe can calculate an odds-ratio from a between groups cohen’s \\(d\\) (\\(d_p\\)):\n\\[\nOR = \\exp\\left(\\frac{d_p \\pi}{\\sqrt{3}}\\right)\n\\]\nWhere \\(\\exp(\\cdot)\\) is an exponential transformation (this inverses the logarithm). Using the d_to_oddsratio function in the effectsize package we can convert \\(d\\) to \\(OR\\).\n\n# Example:\n# d = 0.60, n1 = 50, n2 = 70\n\nlibrary(effectsize)\n\nd &lt;- 0.60\nn1 &lt;- 50\nn2 &lt;- 70\n\nd_to_oddsratio(d = d, n1 = n1, n2 = n2)\n\n[1] 2.969162"
  },
  {
    "objectID": "Converting-to-Odds-Ratio.html#from-a-pearson-correlation",
    "href": "Converting-to-Odds-Ratio.html#from-a-pearson-correlation",
    "title": "17  Converting to Odds Ratio",
    "section": "17.2 From a Pearson Correlation",
    "text": "17.2 From a Pearson Correlation\nWe can calculate an odds ratio from a Pearson correlation using the following formula:\n\\[\nOR = \\exp\\left(\\frac{r\\pi \\sqrt{\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}{\\sqrt{3(1-r^2)}}\\right)\n\\]\nWhen sample sizes are equal, this equation can be simplified to be approximately,\n\\[\nOR = \\exp\\left(\\frac{r\\pi \\sqrt{4}}{\\sqrt{3(1-r^2)}}\\right)\n\\]\nUsing the r_to_oddsratio function in the effectsize package we can convert \\(d\\) to \\(OR\\).\n\n# Example:\n# r = .50, n1 = 50, n2 = 70\n\nr &lt;- .40\nn1 &lt;- 50\nn2 &lt;- 70\n\nr_to_oddsratio(r = r, n1 = n1, n2 = n2)\n\n[1] 4.870584",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Omrekenen naar Odds Ratios</span>"
    ]
  },
  {
    "objectID": "Conclusion.html#limitations-and-future-directions",
    "href": "Conclusion.html#limitations-and-future-directions",
    "title": "18  Conclusion",
    "section": "18.1 Limitations and Future Directions",
    "text": "18.1 Limitations and Future Directions\nWhile this guide covers a wide range of effect size and confidence interval methods, there are some limitations to note. First, our instructions focus specifically on applications in behavioral, cognitive, and social science research. The techniques may need to be adapted for other scientific domains. Second, we only cover free and open source options, so proprietary software packages are not discussed. Finally, as new methods and R packages arise, the guide will need to be continually updated, perhaps in a similar manner as Parsons et al. (2022) Open Scholarship terms after publication.\nIn the future, we aim to expand the guide by collaborating with experts in other fields to include discipline-specific recommendations. We also plan to incorporate new R packages and techniques as they emerge. Readers are encouraged to consult the cited packages’ documentation and peer-reviewed sources to further explore limitations and assumptions of the covered techniques."
  },
  {
    "objectID": "Conclusion.html#conclusion",
    "href": "Conclusion.html#conclusion",
    "title": "18  Conclusion",
    "section": "18.2 Conclusion",
    "text": "18.2 Conclusion\nRobust quantification of study results is a central pillar of open and reproducible science. With this collaborative collection of applied instructions, our guide aims to make calculating effect sizes and confidence intervals more accessible. We hope these resources empower both young researchers and experienced scholars across a variety of disciplines to incorporate these crucial statistical practices into their workflows. In our view, more widespread and thoughtful adoption of these methods will greatly strengthen the collective rigor, transparency, and impact of scientific research.",
    "crumbs": [
      "**Conclusie**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Conclusie</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Agresti, Alan. 1980. “Generalized Odds Ratios for Ordinal\nData.” Biometrics, 59–67.\n\n\nAlgina, James, and H. J. Keselman. 2003. “Approximate Confidence\nIntervals for Effect Sizes.” Educational and Psychological\nMeasurement 63 (4): 537–53. https://doi.org/10.1177/0013164403256358.\n\n\nAnvari, Farid, and Daniël Lakens. 2021. “Using Anchor-Based\nMethods to Determine the Smallest Effect Size of Interest.”\nJournal of Experimental Social Psychology 96: 104159.\n\n\nAPA. 2010. Publication Manual of the American Psychological\nAssociation. American Psychological Association. https://thuvienso.hoasen.edu.vn/handle/123456789/8327.\n\n\nBaayen, R Harald, Douglas J Davidson, and Douglas M Bates. 2008.\n“Mixed-Effects Modeling with Crossed Random Effects for Subjects\nand Items.” Journal of Memory and Language 59 (4):\n390–412.\n\n\nBarr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013.\n“Random Effects Structure for Confirmatory Hypothesis Testing:\nKeep It Maximal.” Journal of Memory and Language 68 (3):\n255–78.\n\n\nBartoń, Kamil. 2023. MuMIn: Multi-Model Inference. https://CRAN.R-project.org/package=MuMIn.\n\n\nBeck, Edward C., Anirudh K. Gowd, Joseph N. Liu, Brian R. Waterman,\nKristen F. Nicholson, Brian Forsythe, Adam B. Yanke, Brian J. Cole, and\nNikhil N. Verma. 2020. “How Is Maximum Outcome Improvement Defined\nin Patients Undergoing Shoulder Arthroscopy for Rotator Cuff Repair? A\n1-Year Follow-up Study.” Arthroscopy: The Journal of\nArthroscopic & Related Surgery 36 (7): 1805–10. https://doi.org/10.1016/j.arthro.2020.02.047.\n\n\nBecker, Betsy J. 1988. “Synthesizing Standardized Mean-Change\nMeasures - UConn Library.” British Journal of Mathematical\nand Statistical Psychology 41 (2): 257278. https://doi.org/https://doi.org/10.1111/j.2044-8317.1988.tb00901.x.\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020.\n“effectsize: Estimation of Effect Size\nIndices and Standardized Parameters.” Journal of Open Source\nSoftware 5 (56): 2815. https://doi.org/10.21105/joss.02815.\n\n\nBen-Shachar, Mattan S., Indrajeet Patil, Rémi Thériault, Brenton M.\nWiernik, and Daniel Lüdecke. 2023. “Phi, Fei, Fo, Fum: Effect\nSizes for Categorical Data That Use the Chi-Squared Statistic.”\nMathematics 11 (9): 1982. https://doi.org/10.3390/math11091982.\n\n\nBlair, Graeme, Jasper Cooper, Alexander Coppock, and Macartan Humphreys.\n2019. “Declaring and Diagnosing Research Designs.”\nAmerican Political Science Review 113: 838–59. https://declaredesign.org/paper.pdf.\n\n\nBonini, Matteo, Marcello Di Paolo, Diego Bagnasco, Ilaria Baiardini,\nFulvio Braido, Marco Caminati, Elisiana Carpagnano, et al. 2020.\n“Minimal Clinically Important Difference for Asthma Endpoints: An\nExpert Consensus Report.” European Respiratory Review 29\n(156).\n\n\nBosco, Frank A., Herman Aguinis, Kulraj Singh, James G. Field, and\nCharles A. Pierce. 2015. “Correlational Effect Size\nBenchmarks.” Journal of Applied Psychology 100 (2):\n431–49. https://doi.org/10.1037/a0038047.\n\n\nBrunner, Edgar, and Ullrich Munzel. 2000. “The Nonparametric\nBehrens-Fisher Problem: Asymptotic Theory and a Small-Sample\nApproximation.” Biometrical Journal 42 (1): 17–25. https://doi.org/10.1002/(SICI)1521-4036(200001)42:1&lt;17::AID-BIMJ17&gt;3.0.CO;2-U.\n\n\nBuchanan, Erin M., Amber Gillenwaters, John E. Scofield, and K. D.\nValentine. 2019. MOTE: Measure of the\nEffect: Package to Assist in Effect Size Calculations and Their\nConfidence Intervals. http://github.com/doomlab/MOTE.\n\n\nCaldwell, Aaron R. 2022. “Exploring Equivalence Testing with the\nUpdated TOSTER r Package.” PsyArXiv. https://doi.org/10.31234/osf.io/ty8de.\n\n\nCliff, Norman. 1993. “Dominance Statistics: Ordinal Analyses to\nAnswer Ordinal Questions.” Psychological Bulletin 114\n(3): 494.\n\n\nCoe, R. 2012. “It’s the Effect Size, Stupid What Effect Size Is\nand Why It Is Important.” In. https://www.semanticscholar.org/paper/It%27s-the-Effect-Size%2C-Stupid-What-effect-size-is-it-Coe/c5ac87df5d6e0e6b6de2f745284835c2a368b0f7.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. Academic Press.\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “psychmeta: An r Package for Psychometric\nMeta-Analysis.” Applied Psychological Measurement 43\n(5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nDaste, Camille, Hendy Abdoul, Frantz Foissac, Marie-Martine\nLefèvre-Colau, Serge Poiraudeau, François Rannou, and Christelle Nguyen.\n2022. “Patient Acceptable Symptom State for Patient-Reported\nOutcomes in People with Non-Specific Chronic Low Back Pain.”\nAnnals of Physical and Rehabilitation Medicine 65 (1): 101451.\nhttps://doi.org/10.1016/j.rehab.2020.10.005.\n\n\nDivine, George W, H James Norton, Anna E Barón, and Elizabeth\nJuarez-Colunga. 2018. “The Wilcoxon–Mann–Whitney Procedure Fails\nas a Test of Medians.” The American Statistician 72 (3):\n278–86.\n\n\nFaul, Franz, Edgar Erdfelder, Axel Buchner, and Albert-Georg Lang. 2009.\n“Statistical Power Analyses Using G*Power 3.1: Tests for\nCorrelation and Regression Analyses.” Behavior Research\nMethods 41 (4): 1149–60. https://doi.org/10.3758/BRM.41.4.1149.\n\n\nFritz, Catherine O., Peter E. Morris, and Jennifer J. Richler. 2012.\n“Effect Size Estimates: Current Use, Calculations, and\nInterpretation.” Journal of Experimental Psychology:\nGeneral 141 (1): 2–18. https://doi.org/10.1037/a0024338.\n\n\nFunder, David C., and Daniel J. Ozer. 2019. “Evaluating Effect\nSize in Psychological Research: Sense and Nonsense.” Advances\nin Methods and Practices in Psychological Science 2 (2): 156–68. https://doi.org/10.1177/2515245919847202.\n\n\nGelman, Andrew. 2011. “Why It Doesn’t Make Sense in\nGeneral to Form Confidence Intervals by Inverting Hypothesis Tests |\nStatistical Modeling, Causal Inference, and Social Science.” https://statmodeling.stat.columbia.edu/2011/08/25/why_it_doesnt_m/.\n\n\nGignac, Gilles E., and Eva T. Szodorai. 2016. “Effect Size\nGuidelines for Individual Differences Researchers.”\nPersonality and Individual Differences 102 (November): 74–78.\nhttps://doi.org/10.1016/j.paid.2016.06.069.\n\n\nGlass, Gene V. 1981. “Meta-Analysis in Social Research.”\n(No Title). https://cir.nii.ac.jp/crid/1130000795088566912.\n\n\nGlass, Gene V., Barry McGaw, and Mary L. Smith. 1981.\n“Meta-Analysis in Social Research.” (No Title). https://cir.nii.ac.jp/crid/1130000795088566912.\n\n\nGuilford, J. P. 1965. “The Minimal Phi Coefficient and the Maximal\nPhi.” Educational and Psychological Measurement 25 (1):\n3–8. https://doi.org/10.1177/001316446502500101.\n\n\nHarrell, Frank. 2020. “Author Checklist - Data Analysis.”\nhttps://discourse.datamethods.org/t/author-checklist/3407.\n\n\nHedges, Larry V. 1981. “Distribution Theory for Glass’s Estimator\nof Effect Size and Related Estimators.” Journal of\nEducational Statistics 6 (2): 107–28. https://doi.org/10.3102/10769986006002107.\n\n\nHEIJDE, DÉSIRÉE van der, MARISSA Lassere, JOHN Edmonds, JOHN Kirwan,\nVIBEKE Strand, and Maarten Boers. 2001. “Minimal Clinically\nImportant Difference in Plain Films in RA: Group Discussions,\nConclusions, and Recommendations. OMERACT Imaging Task Force.”\nThe Journal of Rheumatology 28 (4): 914–17.\n\n\nHoekstra, Rink, Richard D. Morey, Jeffrey N. Rouder, and Eric-Jan\nWagenmakers. 2014. “Robust Misinterpretation of Confidence\nIntervals.” Psychonomic Bulletin & Review 21 (5):\n1157–64. https://doi.org/10.3758/s13423-013-0572-3.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://doi.org/10.5281/zenodo.3960218.\n\n\nHunter, John E., and Frank L. Schmidt. 1990. Methods of\nmeta-analysis: correcting error and bias in research findings.\nNewbury Park: Sage Publications.\n\n\nJané, Matthew B. 2023. Artifact Corrections for Effect Sizes:\nImplementation in r and Application to Meta-Analysis. (n.p.). https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/.\n\n\nKarch, Julian D. 2021. “Psychologists Should Use Brunner-Munzel’s\nInstead of Mann-Whitney’s u Test as the Default Nonparametric\nProcedure.” Advances in Methods and Practices in\nPsychological Science 4 (2): 2515245921999602.\n\n\nKassambara, Alboukadel. 2019. Datarium: Data Bank for Statistical\nAnalysis and Visualization. https://CRAN.R-project.org/package=datarium.\n\n\nKelley, Ken. 2022. MBESS: The MBESS r Package. https://CRAN.R-project.org/package=MBESS.\n\n\nKelley, Ken, and Kristopher J. Preacher. 2012. “On Effect\nSize.” Psychological Methods 17 (2): 137–52. https://doi.org/10.1037/a0028086.\n\n\nKirby, Kris N, and Daniel Gerlanc. 2013. “BootES: An r Package for\nBootstrap Confidence Intervals on Effect Sizes.” Behavior\nResearch Methods 45: 905–27.\n\n\nLakens, Daniël. 2013. “Calculating and Reporting Effect Sizes to\nFacilitate Cumulative Science: A Practical Primer for t-Tests and\nANOVAs.” Frontiers in Psychology 4. https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00863.\n\n\n———. 2014. “The 20.” http://daniellakens.blogspot.com/2014/06/calculating-confidence-intervals-for.html.\n\n\n———. 2022. “Sample Size Justification.” Collabra:\nPsychology 8 (1): 33267. https://doi.org/10.1525/collabra.33267.\n\n\nLakens, Daniël, Anne M Scheel, and Peder M Isager. 2018.\n“Equivalence Testing for Psychological Research: A\nTutorial.” Advances in Methods and Practices in Psychological\nScience 1 (2): 259–69.\n\n\nLäkens, Daniel. 2017. “Equivalence Tests: A Practical Primer for\nt-Tests, Correlations, and Meta-Analyses.” Social\nPsychological and Personality Science 1: 1–8. https://doi.org/10.1177/1948550617697177.\n\n\nLiddell, Torrin M., and John K. Kruschke. 2018. “Analyzing Ordinal\nData with Metric Models: What Could Possibly Go Wrong?”\nJournal of Experimental Social Psychology 79 (November):\n328–48. https://doi.org/10.1016/j.jesp.2018.08.009.\n\n\nLovakov, Andrey, and Elena R. Agadullina. 2021. “Empirically\nDerived Guidelines for Effect Size Interpretation in Social\nPsychology.” European Journal of Social Psychology 51\n(3): 485–504. https://doi.org/10.1002/ejsp.2752.\n\n\nLüdecke, Daniel. 2019. Esc: Effect Size Computation for Meta\nAnalysis (Version 0.5.1). https://doi.org/10.5281/zenodo.1249218.\n\n\nMagnusson, Kristoffer. 2023. “A Causal Inference Perspective on\nTherapist Effects.”\n\n\nMcGlothlin, Anna E., and Roger J. Lewis. 2014. “Minimal Clinically\nImportant Difference: Defining What Really Matters to Patients.”\nJAMA 312 (13): 1342–43. https://doi.org/10.1001/jama.2014.13128.\n\n\nMeehl, Paul E. 1984. “Radical Behaviorism and Mental Events: Four\nMethodological Queries.” Behavioral and Brain Sciences 7\n(4): 563–64. https://doi.org/10.1017/S0140525X00027308.\n\n\nMorey, Richard D., Rink Hoekstra, Jeffrey N. Rouder, Michael D. Lee, and\nEric-Jan Wagenmakers. 2016. “The Fallacy of Placing Confidence in\nConfidence Intervals.” Psychonomic Bulletin & Review\n23 (1): 103–23. https://doi.org/10.3758/s13423-015-0947-8.\n\n\nMorris, Scott B. 2008. “Estimating Effect Sizes From\nPretest-Posttest-Control Group Designs.” Organizational\nResearch Methods 11 (2): 364–86. https://doi.org/10.1177/1094428106291059.\n\n\nMorse, David. 2018. “How to Calculate Degrees of Freedom When\nUsing Two Way ANOVA with Unequal Sample Size?”\n\n\nMunzel, Ullrich, and Edgar Brunner. 2002. “An Exact Paired Rank\nTest.” Biometrical Journal 44 (5): 584–93. https://doi.org/10.1002/1521-4036(200207)44:5&lt;584::AID-BIMJ584&gt;3.0.CO;2-9.\n\n\nNeubert, Karin, and Edgar Brunner. 2007. “A Studentized\nPermutation Test for the Non-Parametric Behrensfisher\nProblem.” Computational Statistics & Data Analysis\n51 (10): 5192–5204. https://doi.org/10.1016/j.csda.2006.05.024.\n\n\nO’Brien, Ralph G, and John Castelloe. 2006. “Exploiting the Link\nBetween the Wilcoxon-Mann-Whitney Test and a Simple Odds\nStatistic.” In Proceedings of the Thirty-First Annual SAS\nUsers Group International Conference, 209–31. Citeseer.\n\n\nOlkin, Ingram, and Jeremy D. Finn. 1995. “Correlations\nRedux.” Psychological Bulletin 118 (1): 155–64. https://doi.org/10.1037/0033-2909.118.1.155.\n\n\nOrben, Amy, and Daniël Lakens. 2020. “Crud (Re)Defined.”\nAdvances in Methods and Practices in Psychological Science 3\n(2): 238–47. https://doi.org/10.1177/2515245920917961.\n\n\nOtgaar, Henry, Paul Riesthuis, Tess Neal, Jason Chin, Irena Boskovic,\nand Eric Rassin. 2023. “If Generalization Is the Grail, Practical\nRelevance Is the Nirvana: Considerations from the Contribution of\nPsychological Science of Memory to Law.” Henry Otgaar, Paul\nRiesthuis, Tess MS Neal, Jason M. Chin, Irena Boskovic & Eric\nRassin,“If Generalization Is the Grail, Practical Relevance Is the\nNirvana: Considerations from the Contribution of Psychological Science\nof Memory to Law”(accepted 2023) Journal of Applied Research in\nMemory and Co.\n\n\nOtgaar, Henry, Paul Riesthuis, Johannes G Ramaekers, Maryanne Garry, and\nLilian Kloft. 2022. “The Importance of the Smallest Effect Size of\nInterest in Expert Witness Testimony on Alcohol and Memory.”\nFrontiers in Psychology 13: 980533.\n\n\nPanzarella, Emily, Nataly Beribisky, and Robert A Cribbie. 2021.\n“Denouncing the Use of Field-Specific Effect Size Distributions to\nInform Magnitude.” PeerJ 9: e11383.\n\n\nPaterson, Ted A., P. D. Harms, Piers Steel, and Marcus Credé. 2016.\n“An Assessment of the Magnitude of Effect Sizes: Evidence From 30\nYears of Meta-Analysis in Management.” Journal of Leadership\n& Organizational Studies 23 (1): 66–81. https://doi.org/10.1177/1548051815614321.\n\n\nPeters, Gjalt-Jorn Ygram, and Stefan Gruijters. 2023. Ufs: A\nCollection of Utilities. https://ufs.opens.science.\n\n\nPogrow, Stanley. 2019. “How Effect Size (Practical Significance)\nMisleads Clinical Practice: The Case for Switching to Practical Benefit\nto Assess Applied Research Findings.” The American\nStatistician 73 (sup1): 223–34. https://doi.org/10.1080/00031305.2018.1549101.\n\n\nRichard, F. D., Charles F. Bond Jr., and Juli J. Stokes-Zoota. 2003.\n“One Hundred Years of Social Psychology Quantitatively\nDescribed.” Review of General Psychology 7 (4): 331–63.\nhttps://doi.org/10.1037/1089-2680.7.4.331.\n\n\nRiesthuis, Paul, Ivan Mangiulli, Nick Broers, and Henry Otgaar. 2022.\n“Expert Opinions on the Smallest Effect Size of Interest in False\nMemory Research.” Applied Cognitive Psychology 36 (1):\n203–15.\n\n\nSawilowsky, Shlomo. 2009. “New Effect Size Rules of Thumb.”\nJournal of Modern Applied Statistical Methods 8 (2). https://doi.org/10.22237/jmasm/1257035100.\n\n\nSchäfer, Thomas, and Marcus A. Schwarz. 2019. “The Meaningfulness\nof Effect Sizes in Psychological Research: Differences Between\nSub-Disciplines and the Impact of Potential Biases.”\nFrontiers in Psychology 10. https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00813.\n\n\nSenior, Alistair M., Wolfgang Viechtbauer, and Shinichi Nakagawa. 2020.\n“Revisiting and Expanding the Meta-Analysis of Variation: The Log\nCoefficient of Variation Ratio.” Research Synthesis\nMethods 11 (4): 553–67. https://doi.org/10.1002/jrsm.1423.\n\n\nSpearman, C. 1904. “The Proof and Measurement of Association\nBetween Two Things.” International Journal of\nEpidemiology 39 (5): 1137–50. https://doi.org/10.1093/ije/dyq191.\n\n\nSteiger, James H. 2004. “Beyond the f Test: Effect Size Confidence\nIntervals and Tests of Close Fit in the Analysis of Variance and\nContrast Analysis.” Psychological Methods 9 (2): 164–82.\nhttps://doi.org/10.1037/1082-989X.9.2.164.\n\n\nTorchiano, Marco. 2020. Effsize: Efficient Effect Size\nComputation. https://doi.org/10.5281/zenodo.1480624.\n\n\nVenables, W. N., and B. D. Ripley. 2002. Modern Applied Statistics\nwith s. Fourth. New York: Springer. https://www.stats.ox.ac.uk/pub/MASS4/.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in\nR with the metafor\nPackage.” Journal of Statistical Software 36 (3): 1–48.\nhttps://doi.org/10.18637/jss.v036.i03.\n\n\nVos, Paul, and Don Holbert. 2022. “Frequentist Statistical\nInference Without Repeated Sampling.” Synthese 200 (2):\n89. https://doi.org/10.1007/s11229-022-03560-x.\n\n\nW. T. Hoyt, A. C. Del Re &. 2014. MAd: Meta-Analysis with Mean\nDifferences. R Package. https://CRAN.R-project.org/package=MAd.\n\n\nWellington, Ian J., Annabelle P. Davey, Mark P. Cote, Benjamin C.\nHawthorne, Caitlin G. Dorsey, Patrick M. Garvin, James C. Messina, Cory\nR. Hewitt, and Augustus D. Mazzocca. 2023. “Substantial Clinical\nBenefit Values Demonstrate a High Degree of Variability When Stratified\nby Time and Geographic Region.” JSES International 7\n(1): 153–57. https://doi.org/10.1016/j.jseint.2022.10.003.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining\nUnbiased Results in Meta-Analysis: The Importance of Correcting for\nStatistical Artifacts.” Advances in Methods and Practices in\nPsychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.\n\n\nWilliam Revelle. 2023. Psych: Procedures for Psychological,\nPsychometric, and Personality Research. Evanston, Illinois:\nNorthwestern University. https://CRAN.R-project.org/package=psych.\n\n\nYang, Yefeng, Helmut Hillebrand, Malgorzata Lagisz, Ian Cleasby, and\nShinichi Nakagawa. 2022. “Low Statistical Power and Overestimated\nAnthropogenic Impacts, Exacerbated by Publication Bias, Dominate Field\nStudies in Global Change Biology.” Global Change Biology\n28 (3): 969–89. https://doi.org/10.1111/gcb.15972."
  },
  {
    "objectID": "Correlations.html",
    "href": "Correlations.html",
    "title": "8  Correlatie tussen Twee Continuë Variabelen",
    "section": "",
    "text": "Om de relatie tussen twee continue variabelen te kwantificeren, is de meest gebruikelijke methode het gebruik van een Pearson correlatiecoëfficiënt (aangeduid met de letter \\(r\\)). De Pearson correlatie neemt de covariantie tussen een continue onafhankelijke (\\(X\\)) en afhankelijke (\\(Y\\)) variabele en standaardiseert deze door de standaarddeviaties van \\(X\\) en \\(Y\\),\n\\[\nr = \\frac{\\text{Cov}(X,Y)}{S_{X} S_{Y}}.\n\\]\nWe kunnen visualiseren hoe een correlatie tussen twee variabelen eruitziet met scatterplots. ?fig-cor-voorbeeld toont diagrammen met verschillende niveaus van correlatie.\n\n\n\n\n\n\n\n\nFigure 8.1: Gesimuleerde data van een bivariate normale verdeling met 6 verschillende correlaties, r = 0, .20, .40, .60, .80, and 1.00.\n\n\n\n\n\nDe standaardfout van de Pearson correlatiecoëfficiënt is,\n\\[\nSE_r = \\sqrt{\\frac{\\left(1-r^2\\right)^2}{n-1}}\n\\]\nIn tegenstelling tot Cohen’s \\(d\\) en andere maatstaven voor de effectgrootte, wordt de correlatiecoëfficiënt begrensd door -1 en positief 1, waarbij positief 1 een perfect positieve correlatie is, -1 een perfect negatieve correlatie is en nul aangeeft dat er geen correlatie is tussen de twee variabelen. De begrenzing heeft tot gevolg dat het betrouwbaarheidsinterval asymmetrisch is rond \\(r\\) (als de correlatie bijvoorbeeld positief is, ligt de ondergrens verder weg van \\(r\\) dan de bovengrens). Het is belangrijk op te merken dat bij een correlatie van nul het betrouwbaarheidsinterval symmetrisch en ongeveer normaal is. Om de betrouwbaarheidsintervallen van \\(r\\) te verkrijgen, moeten we eerst een Fisher’s Z-transformatie toepassen. Een Fisher’s Z transformatie is een hyperbolische arctangens transformatie van een Pearson correlatiecoëfficiënt en kan als volgt berekend worden,\n\\[\nZ_r = \\text{arctanh}(r)\n\\]\nDe Fisher Z-transformatie zorgt ervoor dat \\(Z_r\\) een symmetrische en ongeveer normale steekproefverdeling heeft. Hierdoor kunnen we het betrouwbaarheidsinterval berekenen uit de standaardfout van \\(Z_r\\) (\\(SE_{Z_r} = \\frac{1}{\\sqrt{n-3}}\\)). We kunnen het betrouwbaarheidsinterval ook terugtransformeren naar een Pearson correlatieschaal,\n\\[\nCI_{r} = \\text{tanh}(Z_r \\pm 1.96\\times SE_{Z_r})\n\\]\nWe kunnen dan de boven- en ondergrens terugtransformeren naar de boven- en ondergrens van \\(r\\) door de hyperbolische tangens te nemen (het omgekeerde van de arctangens).\nIn R kan het volledige proces voor het verkrijgen van betrouwbaarheidsintervallen vrij eenvoudig worden uitgevoerd. Als je ruwe gegevens hebt voor \\(X\\) en \\(Y\\), dan kun je de correlatie berekenen met basis-R, cor(X,Y).\n\n# example: r = .50, n = 50\nr &lt;- .50\nn &lt;- 50\n\n# compute Zr\nZr &lt;- atanh(r)\n\n# calculate standard error of Zr\nSE_Zr &lt;- 1/sqrt(n-3)\n\n# compute confidence interval of Zr\nZlow &lt;- Zr - 1.96 * SE_Zr\nZhigh &lt;- Zr + 1.96 * SE_Zr\n\n# backtransform CI of Z to CI of Pearson correlation\nrlow &lt;- tanh(Zlow) \nrhigh &lt;- tanh(Zhigh)\n\n# print pearson correlation and confidence intervals\ndata.frame(r = MOTE::apa(r), \n           rlow = MOTE::apa(rlow), \n           rhigh = MOTE::apa(rhigh))\n\n      r  rlow rhigh\n1 0.500 0.257 0.683\n\n\nDe uitvoer laat zien dat de correlatie en de betrouwbaarheidsintervallen \\(r\\) = 0,50, 95% CI [0,26, 0,68].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Correlaties</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#een-t-test-met-effectgrootte-en-ci-rapporteren",
    "href": "Standardized-Mean-Differences.html#een-t-test-met-effectgrootte-en-ci-rapporteren",
    "title": "7  Gemiddelde verschillen",
    "section": "7.1 Een t-test met effectgrootte en CI rapporteren",
    "text": "7.1 Een t-test met effectgrootte en CI rapporteren\nWelke effectgrootte en CI je ook wilt rapporteren, je kunt deze rapporteren naast de t-teststatistieken (d.w.z. de t-waarde en de p-waarde). Bijvoorbeeld,\n\nDe behandelgroep had een significant hoger gemiddelde dan de controlegroep (t = 2,76, p = .009, n = 35, d = 0,47 [0,11, 0,81]).",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Categorical-Proportional-Data.html#one-sample-proportion-test",
    "href": "Categorical-Proportional-Data.html#one-sample-proportion-test",
    "title": "9  Effect Sizes voor Categoriale Variabelen",
    "section": "9.1 One Sample Proportion Test",
    "text": "9.1 One Sample Proportion Test\nIf we have a single sample and we want to assess the difference between a proportion and some proportion of interest. We can first calculate the test statistic by comparing the observed proportion (\\(p\\)) vs the proportion of interest (\\(p_0\\)):\n\\[\nz = \\frac{p-p_0}{\\sqrt{\\frac{p(1-p)}{n}}},\n\\] where \\(n\\) is the sample size. Note that this is only valid if the proportion of interest is chance (\\(p_0=.50\\)) because the sampling distribution with a proportion of .50 is normal. However if the proportion of interest is not .50, then we should instead compute Cohen’s \\(h\\) (see Section 9.2.3 for details), which transforms the scale so that the distributions are normal regardless of the proportion. The test-statistic with Cohen’s \\(h\\),\n\\[\nz = h\\sqrt{n}\n\\]\nLet’s try testing the proportion against chance (\\(p_0=.50\\)) in R. We can then calculate the p-value in base R by using the pnorm() function:\n\n# Example:\np &lt;- .7 # observed proportion\np0 &lt;- .5 # proportion of interest\nn &lt;- 50 # sample size\n\nz &lt;- (p-p0) / sqrt(p*(1-p)/n)\n\npval &lt;- 2*(1-pnorm(z)) # two tailed test\n\ndata.frame(z,pval)\n\n         z        pval\n1 3.086067 0.002028231\n\n\nResults show a significant difference from chance with \\(z\\) = 3.09 and p-val = .002",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Categoriale/Proportionele Data</span>"
    ]
  },
  {
    "objectID": "Categorical-Proportional-Data.html#effect-sizes",
    "href": "Categorical-Proportional-Data.html#effect-sizes",
    "title": "9  Effect Sizes voor Categoriale Variabelen",
    "section": "9.2 Effect Sizes",
    "text": "9.2 Effect Sizes\n\n9.2.1 Phi Coëfficient (\\(\\phi\\))\nDe Phi-coëfficiënt (\\(\\phi\\)) is een maat voor de associatie tussen twee binaire variabelen (daarom is hij ALLEEN van toepassing op 2 bij 2 contingentietabellen, d.w.z. dat elke variabele slechts twee niveaus heeft). Het is een speciaal geval van de Pearson correlatiecoëfficiënt en een \\(r\\) voor twee binaire variabelen is gelijk aan phi. Merk op dat in tegenstelling tot \\(r\\) die van -1 tot 1 gaat, phi van 0 tot 1 gaat. Ook geeft het teken van \\(r\\) de richting van de associatie aan, terwijl we naar de tabel zelf moeten kijken om de richting van een associatie te bepalen op basis van een 2 bij 2 contingentietabel; phi geeft alleen een maat voor de sterkte. De 2 bij 2 contingentietabel wordt geïllustreerd door Table 9.1.\n\n\n\nTable 9.1: Contingentietabel tussen twee binaire variabelen\n\n\n\n\n\n\n\\(X=0\\)\n\\(X=1\\)\n\n\n\n\n\\(Y=0\\)\n\\(n_{00}\\)\n\\(n_{10}\\)\n\n\n\\(Y=1\\)\n\\(n_{01}\\)\n\\(n_{11}\\)\n\n\n\n\n\n\nDe steekproefgrootten binnen elke cel geven ons de nodige informatie om het verband tussen de twee variabelen te schatten. Een grote phi-coëfficiënt zou naar verwachting relatief grote steekproefgrootten hebben in de diagonale cellen (\\(n_{00}\\) en \\(n_{11}\\)) en relatief kleine steekproefgrootten in de off-diagonale cellen (\\(n_{01}\\) en \\(n_{10}\\)). Om phi te berekenen, kan het rechtstreeks worden berekend uit de cellen van de contingentietabel (aangepast van vergelijking 1, Guilford 1965),\n\\[\n\\phi = \\frac{n_{11}n_{00} -n_{10}n_{01}}{\\sqrt{(n_{00} + n_{01})(n_{10} + n_{11})(n_{00} + n_{10})(n_{01} + n_{11})}}\n\\]\nof handiger, van de \\(\\chi^2\\)-statistiek (vergelijking 7.2.5, Cohen 1988),\n\\[\n\\phi = \\sqrt{\\frac{\\chi^2}{n}}\n\\]\nWaar \\(n\\) de totale steekproefgrootte is (d.w.z. de som van alle cellen). Met behulp van het pakket effectsize in R kunnen we de phi-coëfficiënt berekenen met de functie phi, rechtstreeks uit de contingentietabel:\n\n# Voorbeeld contingentietabel:\n#  40  17\n#  11  45\n\nlibrary(effectsize)\n\ncontingency_table &lt;- matrix(c(40, 11,\n                              17, 45),ncol = 2)\n\nphi_coefficient &lt;- phi(contingency_table, alternative = \"two.sided\")\n\nphi_coefficient\n\nPhi (adj.) |       95% CI\n-------------------------\n0.50       | [0.31, 0.69]\n\n\nIn ons voorbeeld hebben we een phi-coëfficiënt van \\(\\phi\\) = .50 [0.31, 0.69].\n\n\n9.2.2 Cramer’s \\(V\\)\nCramer’s V, soms ook Cramer’s phi (\\(\\phi\\)) genoemd, is een algemene maat voor de effectgrootte van de associatie tussen twee nominale variabelen. Het is van toepassing op contingentietabellen van elke grootte (\\(2\\times 2\\), \\(3\\times 3\\), \\(3\\times 4\\), \\(5\\times 3\\), etc.). Cramer’s \\(V\\) op een controletabel van \\(2\\times 2\\) is gelijk aan de phi-coëfficiënt. Ter illustratie van een hogere orde contingentietabel staat Table 9.2 voor een \\(3\\times 4\\) contingentietabel van twee variabelen. Table 9.2 representeert een \\(3\\times 4\\) contingentie tabel van twee variabelen.\n\n\n\nTable 9.2: Contingentietabel tussen twee categoriale variabelen\n\n\n\n\n\n\n\\(X=0\\)\n\\(X=1\\)\n\\(X=2\\)\n\\(X=3\\)\n\n\n\n\n\\(Y=0\\)\n\\(n_{00}\\)\n\\(n_{10}\\)\n\\(n_{21}\\)\n\\(n_{31}\\)\n\n\n\\(Y=1\\)\n\\(n_{01}\\)\n\\(n_{11}\\)\n\\(n_{21}\\)\n\\(n_{31}\\)\n\n\n\\(Y=2\\)\n\\(n_{02}\\)\n\\(n_{12}\\)\n\\(n_{22}\\)\n\\(n_{32}\\)\n\n\n\n\n\n\nNet als de phi-coëfficiënt varieert de waarde van Cramer’s \\(V\\) van 0 tot 1 en kan op dezelfde manier geïnterpreteerd worden als een phi-coëfficiënt. Ook hier kunnen we de statistiek van \\(\\chi^2\\) gebruiken om de waarde te berekenen, maar omdat er meer dan 2 niveaus voor elke variabele kunnen zijn, moeten we ook rekening houden met het aantal niveaus, \\(k\\), van de variabele met het minste aantal niveaus (bijvoorbeeld bij een contingentietabel van \\(3 maal 4\\) zou \\(k\\) gelijk zijn aan 3). Cramer’s \\(V\\) wordt gedefinieerd als (vergelijking 7.2.6, Cohen 1988),\n\\[\nV = \\sqrt{\\frac{\\chi^2}{n(k-1)}}\n\\]\nDe standaardfout van een Cramer’s \\(V\\) is vergelijkbaar met die van een Pearson correlatie en een \\(\\phi\\) coëfficiënt.\n\\[\nSE_V = \\sqrt{\\frac{\\left(1-V^2\\right)^2}{n-1}}\n\\]\nWaar \\(n\\) de totale steekproefgrootte is (d.w.z. de som van alle cellen). Net als bij de Pearson correlatie kunnen we het betrouwbaarheidsinterval niet rechtstreeks uit de standaardfout berekenen, maar moeten we \\(V\\) omrekenen naar een Z-statistiek van Fisher, \\(Z_V = \\text{arctanh}(V)\\). We kunnen dan het 95%-betrouwbaarheidsinterval voor \\(V\\) berekenen door het betrouwbaarheidsinterval voor \\(Z_V\\) terug te rekenen:\n\\[\nSE_{Z_V} = \\frac{1}{\\sqrt{n-3}}\n\\]\n\\[\nCI_{V} = \\tanh(Z_V \\pm 1.96\\times SE_{Z_V})\n\\]\nMet behulp van het ufs pakket (Peters and Gruijters 2023) kunnen we Cramer’s \\(V\\) en zijn 95% betrouwbaarheidsinterval berekenen met behulp van de Fisher’s Z-methode zoals hierboven beschreven. Voor het voorbeeld kunnen we gegevens uit een 3 \\(times\\) 3 contingentietabel gebruiken.\n\n# Voorbeeld contingentie tabel:\n#  40  14  12\n#  11  27   9\n#   5  10  34\n\nlibrary(ufs)\n\ncontingency_table &lt;- matrix(c(40, 11,  5,\n                              14, 27, 10,\n                              12,  9, 34),ncol = 3)\n\n\nV &lt;- cramersV(contingency_table)\nCI &lt;- confIntV(contingency_table)\n\n# print pearson correlation and confidence intervals\ndata.frame(V = MOTE::apa(V$output$cramersV), \n           Vlow = MOTE::apa(CI$output$confIntV.fisher[1]), \n           Vhigh = MOTE::apa(CI$output$confIntV.fisher[2]))\n\n      V  Vlow Vhigh\n1 0.442 0.309 0.558\n\n\nIn ons voorbeeld hebben we een Cramer’s \\(V\\) of \\(V\\) = .44 [.31, .56].\n\n\n9.2.3 Cohen’s \\(h\\)\nCohen’s \\(h\\) is een maat voor de afstand tussen twee verhoudingen of waarschijnlijkheden. Het wordt soms ook het “verschil tussen arcsijnen” genoemd. Voor een gegeven proportie \\(p\\) wordt de transformatie van de arcsinus gegeven door (vergelijking 6.2.1, Cohen 1988):\n\\[\n\\psi = 2\\cdot \\text{arcsin}(\\sqrt{p}).\n\\]\nCohen’s \\(h\\) is het verschil tussen de arcsinus transformaties van twee verhoudingen (vergelijking 6.2.2, Cohen 1988):\n\\[\nh = \\psi_1 - \\psi_2\n\\]\nCohen’s \\(h\\) wordt vaak gebruikt voor de poweranalyse van proportietests. Het is zelfs de vereiste effectgrootte in het programma G Power (Faul et al. 2009). We kunnen de standaardfout van Cohen’s \\(h\\) berekenen,\n\\[\nSE_h = \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\nOmdat de steekproefverdeling van \\(h\\) symmetrisch is, kunnen we de betrouwbaarheidsintervallen berekenen uit de standaardfout,\n\\[\nCI_h = h \\pm1.96\\times SE_h\n\\]\nOm Cohen’s \\(h\\) te berekenen, kunnen we de cohens_h functie in het effectsize pakket in R gebruiken.\n\n# installeer pakket als je dat al niet hebt gedaan\n# install.packages('effectsize')\n# Voorbeeld proporties: p1 = .45, p2 = .30\n\nlibrary(effectsize)\n\ncontingency_table &lt;- matrix(c(40, 11,\n                              14, 27),ncol = 2)\n\ncohens_h(contingency_table)\n\nCohen's h |       95% CI\n------------------------\n0.93      | [0.52, 1.34]\n\n\nUit het voorbeeld leidde de R-code tot een Cohen’s \\(h\\) waarde van \\(h\\) = .93 [0.52, 1.34].\n\n\n9.2.4 Cohen’s \\(w\\)\nCohen’s \\(w\\) is een maat voor associatie analoog aan de phi-coëfficiënt, maar dan op tabellen groter dan 2x2. Hoewel Cohen’s \\(w\\) nuttig is voor poweranalyses, is het niet zo nuttig als een op zichzelf staande effectgrootte. Zoals Cohen (1988) stelt (pp. 221):\n\nAls maatstaf voor associatie is Cohen’s $w niet bekend en gemakkelijk.\n\nCohen’s \\(w\\) heeft precies dezelfde formule als de phi coëfficiënt met als enige verschil dat de \\(chi^2\\) statistiek uit een contingentietabel van elke grootte komt (vergelijking 7.2.5, Cohen 1988), \\[\nw = \\sqrt{\\frac{\\chi^2}{n}}\n\\]\nEn kan ook direct berekend worden uit Cramer’s \\(V\\) (vergelijking 7.2.7, Cohen 1988),\n\\[\nw = V \\times \\sqrt{k-1}\n\\]\nWaar \\(k\\) het aantal categorieën is in de variabele met het minste aantal categorieën. We kunnen de functie cohens_w() gebruiken in het pakket effectsize (Ben-Shachar, Lüdecke, and Makowski 2020).\n\n# Voorbeeld contingentietabel\n# 40 14\n# 11 27\n\ncontingency_table &lt;- matrix(c(40, 11, \n                              14, 27),ncol = 2)\n\ncohens_w(contingency_table,\n         alternative = \"two.sided\")\n\nCohen's w |       95% CI\n------------------------\n0.45      | [0.24, 0.65]\n\n\nIn de voorbeeldcode gaf de functie cohens_w de Cohen \\(w\\) waarde van \\(w\\) = .45 [0.24, 0.65].\n\n\n9.2.5 Ben-Shachar’s Fei (פ)\nBen-Shachar et al. (2023) introduceerden een nieuwe effectgrootte voor eendimensionale tabellen van tellingen/verhoudingen die ze aanduiden met de Hebreeuwse letter פ. Ben-Shachar’s פ is een correctie op Cohen’s \\(w\\) die aanpast voor de verwachte waarde en daardoor de waarde begrenst tussen 0 en 1. De vergelijking voor פ is als volgt gedefinieerd,\n\\[\n\\mathbf{פ }= \\sqrt{\\frac{\\chi^2}{n \\left(\\frac{1}{\\min\\left(P_E\\right)} -1\\right)}}\n\\]\nWaarbij \\(\\min(P_E)\\) de kleinste verwachte kans is. De formule voor Ben-Schachar’s פ kan ook worden uitgedrukt in termen van Cohen’s \\(omega\\),\n\\[\n\\mathbf{פ }= \\frac{\\omega}{\\sqrt{\\left(\\frac{1}{\\max(P_E)} -1\\right)}}\n\\]\nIn R kunnen we Ben-Shachar’s פ berekenen met de fei() functie in het effectsize pakket (Ben-Shachar, Lüdecke, and Makowski 2020).\n\n# Bijvoorbeeld:\n# Geobserveerde aantallen: 20, 50, 100 (geobserveerde proporties: .12, .29, .59)\n# Verwachte proporties: .5, .2, .3\n\nobserved_counts &lt;- c(20,50,100)\nexpected_probabilities &lt;- c(.5,.2,.3)\n\n\nfei(observed_counts,\n    p = expected_probabilities,\n    alternative = \"two.sided\")\n\nFei  |       95% CI\n-------------------\n0.39 | [0.31, 0.47]\n\n- Adjusted for uniform expected probabilities.\n\n\nIn de voorbeeldcode gaf de functie fei Ben-Shachars פ waarde van .39 [0.31, 0.47].\n\n\n9.2.6 Odds Ratio (\\(OR\\))\nOdds ratio meet de effectgrootte tussen twee binaire variabelen. Het wordt vaak gebruikt in medisch en gedragsinterventieonderzoek en met name in meta-analyses.\nLaten we ons een onderzoek voorstellen dat wordt uitgevoerd om de associatie tussen roken en de ontwikkeling van depressieve stoornis (MDD) te onderzoeken. De studie omvat een steekproef van 251 personen, die in twee groepen zijn ingedeeld: 125 rokers en 126 niet-rokers. De onderzoekers zijn geïnteresseerd in de kansen op het hebben van een depressieve stoornis (MDD) onder rokers in vergelijking met niet-rokers. Stel dat bij 25 rokers MDD werd vastgesteld en bij 100 niet, maar in de groep niet-rokers werd bij 12 personen MDD vastgesteld en bij 120 niet. De odds ratio zou dan zijn:\n\\[\nOR = \\frac{25/100}{12/120}= \\frac{.25}{.10} = 2.50\n\\]\nIn het algemeen kunnen we de odds-ratio berekenen op basis van een contingentietabel tussen binaire variabelen \\(X\\) (d.w.z. de behandeling) en \\(Y\\) (d.w.z. de uitkomst); zie Table 9.3).\n\n\n\nTable 9.3: Contingenctietabel tussen twee binaire variabelen\n\n\n\n\n\n\n\\(X=T\\)\n\\(X=C\\)\n\n\n\n\n\\(Y=0\\)\n\\(n_{T0}\\)\n\\(n_{C0}\\)\n\n\n\\(Y=1\\)\n\\(n_{T1}\\)\n\\(n_{C1}\\)\n\n\n\n\n\n\nUiteindelijk willen we de uitkomst tussen de behandelgroep (\\(X=T\\)) en de controlegroep (\\(X=C\\)) vergelijken. Daarom kunnen we de odds ratio als volgt berekenen,\n\\[\nOR = \\frac{n_{T1}/n_{T0}}{n_{C1}/n_{C0}}\n\\]\nDe standaardverdeling van de kansverhouding is asymmetrisch. Om betrouwbaarheidsintervallen te berekenen, kunnen we eerst de odds ratio omrekenen naar een log odds ratio (\\(LOR= \\log(OR)\\)). Daarna kunnen we de standaardfout van de logratio berekenen,\n\\[\nSE_{LOR} = \\sqrt{\\frac{1}{n_{T0}} + \\frac{1}{n_{T1}} + \\frac{1}{n_{C0}} + \\frac{1}{n_{C1}}}\n\\]\nMet de standaardfout van de log odds ratio kunnen we vervolgens het betrouwbaarheidsinterval van de odds ratio berekenen door terug te rekenen met behulp van de exponentiële functie,\n\\[\nCI_{OR} = \\exp(LOR \\pm 1.96\\times SE_{LOR})\n\\]\nIn R kunnen we het pakket effectsize gebruiken om de odds ratio en het betrouwbaarheidsinterval te berekenen:\n\n# Bijvoorbeeld:\n# Experimentele Groep: 10 ziek, 43 gezond\n# Controle Groep:  24 ziek, 41 gezond\n\n\ncontingency_table &lt;- matrix(c(10, 24,\n                              43, 41),ncol = 2)\n\noddsratio(contingency_table,\n          alternative = \"two.sided\")\n\nOdds ratio |       95% CI\n-------------------------\n0.40       | [0.17, 0.93]\n\n\nDe uitvoer van de code voor dit voorbeeld toont een kansverhouding van \\(OR\\) = 0,40 [0,17, 0,93].\n\n\n9.2.7 Risk Difference/Risico Verschil (\\(RD\\))\nRisicoverschil kan worden gebruikt om het verschil tussen twee verhoudingen te interpreteren. Als we de contingentietabel uit Table 9.3 gebruiken en een risicoverschil berekenen tussen de behandelgroep en de controlegroep. We kunnen eerst het aandeel berekenen van de gevallen waarin de uitkomst \\(Y=1\\) is binnen de controlegroep en de behandelgroep:\n\\[\np_C=\\frac{n_{C1}}{n_{C0}+n_{C1}}\n\\]\n\\[\np_T=\\frac{n_{T1}}{n_{T0}+n_{T1}}\n\\]\nMet behulp van deze verhoudingen kunnen we vervolgens het risicoverschil (\\(RD\\)) berekenen,\n\\[\nRD = p_T - p_C.\n\\]\nDe bijbehorende standaardfout is,\n\\[\nSE_{RD} = \\sqrt{\\frac{p_C(1-p_C)}{n_C} + \\frac{p_T(1-p_T)}{n_T} }\n\\]\nWaarbij \\(n_C\\) en \\(n_T\\) de totale steekproefgrootten binnen de controle- respectievelijk de behandelgroep zijn. De standaardfout kan dan worden gebruikt om de 95%-betrouwbaarheidsintervallen te berekenen,\n\\[\nCI_{RD} = RD \\pm 1.96 \\times SE_{RD}\n\\]\nDe formule voor het verschil in risico is vrij eenvoudig, dus we kunnen deze berekenen met basis-R.\n\n# Bijvoorbeeld: \n# Experimentele groep: proportie gevallen = .5, sample size = 40\n# Controle groep: proportie gevallen = .3, sample size = 45\n\npT &lt;- .50\npC &lt;- .30\nnT &lt;- 40\nnC &lt;- 45\n\nRD &lt;- pT - pC\n\nSE &lt;- sqrt( pC*(1-pC)/nC + pT*(1-pT)/nT )\n\n# Bereken 95% CIs\nRDlow &lt;- RD - 1.96*SE\nRDhigh &lt;- RD + 1.96*SE\n\ndata.frame(\n  RD = MOTE::apa(RD),\n  RDlow = MOTE::apa(RDlow),\n  RDhigh = MOTE::apa(RDhigh)\n  )\n\n     RD  RDlow RDhigh\n1 0.200 -0.005  0.405\n\n\n\n\n9.2.8 Relatieve Risico (\\(RR\\))\nHet relatieve risico, vaak de “risico ratio” genoemd, berekent de verhouding tussen het aantal gevallen in de behandelgroep en het aantal gevallen in de controlegroep. De interpretatie is eenvoudig: “individuen die de behandeling krijgen hebben een \\(RR\\) hogere kans op het ervaren van de uitkomst in vergelijking met controles.” Om het relatieve risico te berekenen, moeten we eerst de proportie uitkomstgevallen in de behandelings- en controlegroep berekenen\n\\[\np_C=\\frac{n_{C1}}{n_{C0}+n_{C1}}\n\\]\n\\[\np_T=\\frac{n_{T1}}{n_{T0}+n_{T1}}\n\\]\nDan kunnen we het relatieve risico berekenen,\n\\[\nRR=\\frac{p_T}{p_C}\n\\]\nDe bijbehorende standaardfout kan als volgt worden berekend,\n\\[\nSE_{RR} = \\sqrt{\\frac{p_T}{n_T} + \\frac{p_C}{n_C}}\n\\]\nDe betrouwbaarheidsintervallen kunnen worden berekend uit de standaardfout,\n\\[\nCI_{RR} = RR\\pm 1.96\\times SE_{RR}\n\\]\nOm het relatieve risico te berekenen, kunnen we eenvoudigweg de bovenstaande vergelijkingen gebruiken in basis R.\n\n# Bijvoorbeeld:\n# Experimentele Groep: 10 ziek, 43 gezond, 53 totaal\n# Controle Groep:  24 ziek, 41 gezond, 65 totaal\n\npT &lt;- 10/(43+10)\npC &lt;- 24/(41+24)\nnT &lt;- 53\nnC &lt;- 65\n\nRR &lt;- pT / pC\n\nSE &lt;- sqrt(pT/nT + pC/nC)\n\nRRlow &lt;- RR - 1.96*SE\nRRhigh &lt;- RR + 1.96*SE\n\n# print pearson correlation and confidence intervals\ndata.frame(RR = MOTE::apa(RR), \n           RRlow = MOTE::apa(RRlow), \n           RRhigh = MOTE::apa(RRhigh))\n\n     RR RRlow RRhigh\n1 0.511 0.323  0.699\n\n\n\n\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.\n\n\nBen-Shachar, Mattan S., Indrajeet Patil, Rémi Thériault, Brenton M. Wiernik, and Daniel Lüdecke. 2023. “Phi, Fei, Fo, Fum: Effect Sizes for Categorical Data That Use the Chi-Squared Statistic.” Mathematics 11 (9): 1982. https://doi.org/10.3390/math11091982.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral Sciences. Academic Press.\n\n\nFaul, Franz, Edgar Erdfelder, Axel Buchner, and Albert-Georg Lang. 2009. “Statistical Power Analyses Using G*Power 3.1: Tests for Correlation and Regression Analyses.” Behavior Research Methods 41 (4): 1149–60. https://doi.org/10.3758/BRM.41.4.1149.\n\n\nGuilford, J. P. 1965. “The Minimal Phi Coefficient and the Maximal Phi.” Educational and Psychological Measurement 25 (1): 3–8. https://doi.org/10.1177/001316446502500101.\n\n\nPeters, Gjalt-Jorn Ygram, and Stefan Gruijters. 2023. Ufs: A Collection of Utilities. https://ufs.opens.science.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Categoriale/Proportionele Data</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#anovas",
    "href": "Effect-Sizes-for-ANOVAs.html#anovas",
    "title": "10  Effect Sizes for ANOVAs",
    "section": "10.1 ANOVAs",
    "text": "10.1 ANOVAs\nFor ANOVAs/F-tests, you will always need to report two kinds of effects: the omnibus effect of the factor(s) and the effect of planned contrasts or post hoc comparisons.\nFor instance, imagine that you are comparing three groups/conditions with a one-way ANOVA. The ANOVA will first return an F-statistic, the degrees of freedom, and the associated p-value. Here, you need to calculate the size of this omnibus factor effect in eta-squared, partial eta-squared, or generalized eta-squared.\nSuppose the omnibus effect is significant. You now know that there is at least one group that differs from the others. You want to know which group(s) differ from the others, and how much they differ. Therefore, you conduct post hoc comparisons on these groups. Because post hoc comparisons compare each group with the others in pairs, you will get a t-statistic and p-value for each comparison. For this, you can calculate and report a standardized mean difference.\nImagine that you have two independent variables or factors, and you conduct a two-by-two factorial ANOVA. The first thing to do then is look at the interaction. If the interaction is significant, you again report the associated omnibus effect size measures, and proceed to analyze the simple effects. Depending on your research question, you compare the levels of one IV on each level of the other IV. You will report d or g for these simple effects. If the interaction is not significant, you look at the main effects and report the associated omnibus effect. You then proceed to analyze the main effect by comparing the levels of one IV while collapsing/aggregating the levels of the other IV. You will report d or g for these pairwise comparisons. Note that lower-order effects are not directly interpretable if higher-order effects are significant. If you have a significant interaction in a two-way ANOVA, you cannot interpret the main effects directly. If you have a significant three-way interaction in a three-way ANOVA, you cannot interpret the main effects or the two-way interactions directly, regardless of whether they are significant or not."
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#sec-aov-table",
    "href": "Effect-Sizes-for-ANOVAs.html#sec-aov-table",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.2 ANOVA tabellen",
    "text": "10.2 ANOVA tabellen\nEen ANOVA-tabel bestaat over het algemeen uit de groeperingsfactoren (+ residuen), de som van de kwadraten, de vrijheidsgraden, het gemiddelde kwadraat, de F-statistiek en de p-waarde. In basis-R kunnen we een ANOVA-tabel maken met de functie aov() om het ANOVA-model te genereren en vervolgens met summary.aov() om de tabel te extraheren. Voor een voorbeeldcase gebruiken we het palmerpenguins datasetpakket en onderzoeken we de verschillen in de lichaamsmassa (de uitkomst) van drie pinguïnsoorten (de voorspellende/groeperende variabele):\n\nlibrary(palmerpenguins)\n\n# construct anova model \n# formula structure: outcome ~ grouping variable\nANOVA_mdl &lt;- aov(body_mass_g ~ species, \n                 data = penguins) # dataset\n\nANOVA_table &lt;- summary.aov(ANOVA_mdl)\nANOVA_table\n\n             Df    Sum Sq  Mean Sq F value Pr(&gt;F)    \nspecies       2 146864214 73432107   343.6 &lt;2e-16 ***\nResiduals   339  72443483   213698                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2 observations deleted due to missingness\n\n\nStandaard rapporteert summary.aov() de \\(\\eta^2\\) waarde niet, maar we zullen dit verder bespreken in Section 10.7.1. De resultaten tonen aan dat de gemiddelde lichaamsmassa van de drie pinguïnsoorten (Adelie, Gentoo, Chinstrap) significant van elkaar verschillen.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#one-way-between-subjects-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#one-way-between-subjects-anova",
    "title": "10  Effect Sizes for ANOVAs",
    "section": "10.3 One-way between-subjects ANOVA",
    "text": "10.3 One-way between-subjects ANOVA\nOne-way between-subject ANOVA is an extension of independent-samples t-tests. The null hypothesis is that all k means of k independent groups are identical, whereas the alternative hypothesis is that there are at least two means from these k groups differ. The assumptions include: (1) independence of observations, (2) normality of residuals, and (3) equality (or homogeneity) of variances (homoscedasticity).1\nNote. Sometimes you may encounter a between-subject one-way ANOVA which compares only two conditions, particularly when the paper is old. This is essentially a t-test, and the F-statistic is just t-squared. It is preferable to report Cohen’s d for these tests. If you are calculating the effect size for such tests, it’s best to calculate Cohen’s d, or convert the provided eta-squared to Cohen’s d, as Cohen’s d can show the direction of the effect. Subsequent analyses (e.g., power analysis) can also be based on Cohen’s d.\nIt’s very easy to determine eta-squared with an F-statistic and the two degrees of freedom from a one-way ANOVA 2. Note that in the case of a one-way between-subject ANOVA, eta-squared is equal to partial eta-squared.\n\n10.3.1 Determining degrees of freedom\nPlease refer to the following table to determine the degrees of freedom for ANOVA effects, if they are not reported or if you are doubtful that they have been misreported.\n\n\n\nDegrees of freedom\n\n\n\n\n\nBetween subjects ANOVA\n\n\n\nEffect\n\\(k-1\\)\n\n\nError\n\\(n-k\\)\n\n\nTotal\n\\(n-1\\)\n\n\n\n\n\n10.3.2 Calculating eta-squared from F-statistic and degrees of freedom\nUsing the formula below, we can calculate \\(\\eta^2\\) of an ANOVA model using the F-statistic and the degrees of freedom,\n\\[\n\\eta^2 = \\frac{df_\\text{effect}\\times F}{df_\\text{effect} \\times F + df_\\text{error}}.\n\\]\nIn R, we can use the F_to_eta2() function from the effectsize package (Ben-Shachar, Lüdecke, and Makowski 2020):\n\nlibrary(effectsize)\n\nn = 154 # number of subjects\nk = 3 # number of groups\nf = 84.3 # F-statistic\n\ndf_effect = k - 1\ndf_error = n - k\n\nF_to_eta2(f = f,\n          df = df_effect,\n          df_error = df_error,\n          alternative = 'two.sided') # obtain two sided CIs\n\nEta2 (partial) |       95% CI\n-----------------------------\n0.53           | [0.42, 0.61]\n\n\n\n\n10.3.3 Calculating eta-squared from an ANOVA table\nLet’s use the table from the ANOVA model in Section 10.2:\n\n\nOne-way ANOVA table\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nspecies\n2\n146864214\n73432107.1\n343.6263\n0\n\n\nResiduals\n339\n72443483\n213697.6\nNA\nNA\n\n\n\n\nFrom this table we can use the sum of squares from the grouping variable (species) and the total sum of squares (\\(SS_\\text{total} = SS_\\text{effect} + SS_\\text{error}\\)) to calculate the \\(\\eta^2\\) value using the following equation:\n\\[\n\\eta^2 = \\frac{SS_\\text{effect}}{SS_\\text{total}} = \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}}\n\\]\nIn R, we can use the eta.full.SS() function in the MOTE package (Buchanan et al. 2019) to obtain \\(\\eta^2\\) from an ANOVA table.\n\nlibrary(MOTE)\n\neta &lt;- eta.full.SS(dfm = 2,  # effect degrees of freedom\n                   dfe = 339, # error degrees of freedom\n                   ssm = 146864214, # sum of squares for the effect\n                   sst = 146864214 + 72443483, # total sum of squares\n                   Fvalue = 343.6263,\n                   a = .05)\n\ndata.frame(eta_squared = apa(eta$eta),\n           etalow = apa(eta$etalow),\n           etahigh = apa(eta$etahigh))\n\n  eta_squared etalow etahigh\n1       0.670  0.606   0.722\n\n\nThe example code outputs \\(\\eta^2\\) = .67 [.61, .72]. This suggests that species accounts for 67% of the total variation in body mass between penguins.\n\n\n10.3.4 Calculating Cohen’s d for post-hoc comparisons\nIn an omnibus ANOVA, the p-value is telling us whether the means from all groups come from the same population mean, however this does not inform us about which groups differ and by how much. Using the same example as before, let’s say we want to answer a specific question such as: what is the difference in body mass between Adelie penguins and Gentoo penguins? To answer this question, we can calculate the raw mean difference between the two groups. In R, we can do that with the following code:\n\nMadelie &lt;- mean(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nMgentoo &lt;- mean(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\n\nMgentoo - Madelie\n\n[1] 1375.354\n\n\nBased on the mean difference, Gentoo penguins are on average 1375 grams heavier than Adelia penguins in total body mass. We can also calculate a standardized mean difference using the escalc() function in the metafor package (Viechtbauer 2010).\n\nlibrary(metafor)\n\n# Means, SDs, and sample sizes for each group\nMadelie &lt;- mean(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nMgentoo &lt;- mean(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\nSDadelie &lt;- sd(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nSDgentoo &lt;- sd(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\nNadelie &lt;- sum(penguins$species=='Adelie', na.rm=T)\nNgentoo &lt;- sum(penguins$species=='Gentoo', na.rm=T)\n\nsummary(\n  escalc(measure = 'SMD',\n         m1i = Mgentoo,\n         m2i = Madelie,\n         sd1i = SDgentoo,\n         sd2i = SDadelie,\n         n1i = Ngentoo,\n         n2i = Nadelie)\n)\n\n\n      yi     vi    sei      zi   pval  ci.lb  ci.ub \n1 2.8602 0.0295 0.1716 16.6629 &lt;.0001 2.5237 3.1966 \n\n\nThe standardized mean difference between Adelie and Gentoo penguins is \\(d\\) = 2.86 [2.52, 3.19], demonstrating that Gentoo penguins have body mass 2.86 standard deviations larger than Adelie penguins.\nWe can also quantify contrasts from summary statistics reported from the ANOVA table and the within group means. We can calculate the standardized mean difference using the means from both groups and the mean squared error (\\(MSE\\)) the following equation:\n\\[\nd = \\frac{M_1 - M_2}{\\sqrt{MSE}}\n\\]\nThis method gives a standardized mean difference equivalent to the Cohen’s \\(d\\) with the pooled standard deviation in the denominator (see chapter on mean differences). Therefore if we obtain the mean squared errors (i.e., MS of residuals) from Section 10.3.3 and we obtain the means (means: Gentoo = 5076, Adelie = 3701), we can calculate the standardized mean difference as: \\(\\frac{5076 - 3701}{\\sqrt{213697.6}} = \\frac{1375}{462.27   } = 2.974\\). The discrepency between the standardized mean difference provided by the escalc() function is due to the fact that the function automatically applies a small sample correction factor thus reducing the overall effect.\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nspecies\n2\n146864214\n73432107.1\n343.6263\n0\n\n\nResiduals\n339\n72443483\n213697.6\nNA\nNA\n\n\n\n\n\n\n\n\n\n\nBeware the assumptions.\n\n\n\nNote that this method is ONLY valid when you are willing to assume equal variances among groups (homoscedasticity), and when you conduct a Fisher’s one-way ANOVA (rather than Welch’s). This method is also impractical if you are calculating from reported statistics, and MSE is not reported (which is typically the case).\nIf you are unwilling to assume homogeneity of variances, then calculate Cohen’s d between groups as if there are only two groups for comparison. However, you should know that it also makes little sense to conduct a Fisher’s ANOVA in such situations. You may want to switch to Welch’s ANOVA, which does not assume homoscedasticity. If variances differ greatly, you may want to use alternative standardized effect size measures, such as Glass’ delta, and calculate confidence intervals using bootstrap.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#one-way-repeated-measures-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#one-way-repeated-measures-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.4 One-way repeated measures ANOVA",
    "text": "10.4 One-way repeated measures ANOVA\nOne-way repeated measures ANOVA (rmANOVA) is an extension of paired-samples t-tests, with the difference being it can be used in two or more groups.\n\n10.4.1 Determining degrees of freedom\nPlease refer to the following table to determine the degrees of freedom for repeated measure ANOVA effects.\n\n\n\nDegrees of freedom\n\n\n\n\n\nWithin-subject ANOVA (repeated measures)\n\n\n\nEffect\n\\(k-1\\)\n\n\nError-between\n\\((n-1)\\times(k-1)\\)\n\n\nError-within\n\\((n-1)\\cdot (k-1)\\)\n\n\nTotal (within)\n\\(n\\cdot (k-1)\\)\n\n\n\n\n\n10.4.2 Eta-squared from rmANOVA statistics\nCommonly, we use eta-squared (\\(\\eta^2\\)) or partial eta-squared (\\(\\eta_p^2\\)) as the effect size measure for one-way rmANOVAs, for which these two are in fact equal. Let’s construct an rmANOVA model use example data from the datarium package (Kassambara 2019). The selfesteem data set simply shows self-esteem scores over three repeated measurements within the same subjects.\n\n### load in and re-format data\nlibrary(tidyr)\ndata(\"selfesteem\", package = \"datarium\")\nselfesteem &lt;- tidyr::pivot_longer(selfesteem,cols = c(\"t1\",\"t2\",\"t3\"))\ncolnames(selfesteem) &lt;- c(\"subject\",\"time\",\"self_esteem\")\n####\n\nrmANOVA_mdl = aov(formula = self_esteem ~ time + Error(subject),\n                  data = selfesteem)\nsummary(rmANOVA_mdl)\n\n\nError: subject\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals  1 0.07667 0.07667               \n\nError: Within\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntime       2 102.46   51.23   63.07 1.06e-10 ***\nResiduals 26  21.12    0.81                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\nThere are two tables displayed here, the table on top displays the between subject effects and the table below shows the within subject effects.The equations and functions to calculate \\(\\eta^2\\) mentioned in the one-way between-subjects ANOVAs section also apply here:\n\\[\n\\eta^2 = \\frac{df_\\text{effect}\\times F}{df_\\text{effect} \\times F + df_\\text{error-within}},\n\\]\n\\[\n\\eta^2 = \\frac{SS_\\text{effect}}{SS_\\text{total}}\n\\]\nNote that here \\(SS_\\text{total}\\) does not include \\(SS_\\text{error-between}\\) because we are not interested in it by conducting a rmANOVA. This analysis targets an effect that we think should happen on each subject, regardless of how these subjects will vary from each other. In other words, between-subjects variance can be large or small, but we do not care about it when we examine whether there is an effect or not across repeated measures. Therefore the total sum of squares can be defined as\n\\[\nSS_\\text{total} = SS_\\text{effect} + SS_\\text{error-within}\n\\]\nTherefore we can calculate \\(\\eta^2\\) from the rmANOVA table as,\n\\[\n\\eta^2 = \\frac{102.46}{21.12 + 102.46} = .83\n\\]\nWe can plug the rmANOVA model into the eta_squared() function from the effectsize package in R (Ben-Shachar, Lüdecke, and Makowski 2020) to calculate \\(\\eta^2\\).\n\nlibrary(effectsize)\n\neta_squared(rmANOVA_mdl,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nGroup  | Parameter | Eta2 (partial) |       95% CI\n--------------------------------------------------\nWithin |      time |           0.83 | [0.69, 0.89]\n\n\nAs expected, we find the same point-estimate from our hand calculation. To calculate \\(\\eta^2\\) from the F-statistic and degrees of freedom we can use the MOTE package (Buchanan et al. 2019) as we did in Section 10.3.3\n\nlibrary(MOTE)\n\neta &lt;- eta.full.SS(dfm = 2,  # effect degrees of freedom\n                   dfe = 26, # error degrees of freedom\n                   ssm = 102.46, # sum of squares for the effect\n                   sst = 102.46 + 21.12, # total sum of squares\n                   Fvalue = 63.07,\n                   a = .05)\n\ndata.frame(eta_squared = apa(eta$eta),\n           etalow = apa(eta$etalow),\n           etahigh = apa(eta$etahigh))\n\n  eta_squared etalow etahigh\n1       0.829  0.644   0.910\n\n\nNote the discrepency between confidence intervals returned by MOTE and effectsize this is due to differences in the calculation.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#two-way-between-subjects-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#two-way-between-subjects-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.5 Two-Way between-subjects ANOVA",
    "text": "10.5 Two-Way between-subjects ANOVA\nTwo-way between-subjects ANOVA is used when there are two predictor grouping variables in the model. Note again that between subjects means that each group contain different subjects.\n\n10.5.1 Determining degrees of freedom\nPlease refer to the following table to determine the degrees of freedom for two-way ANOVA effects (Morse 2018). Note that \\(k_1\\) is the number of groups in the first variable, and \\(k_2\\) is the number of groups in the second variable.\n\n\n\nDegrees of freedom\n\n\n\n\n\nWithin subjects ANOVA\n\n\n\nMain Effect (of one variable)\n\\(k_1-1\\) or \\(k_2-1\\)\n\n\nInteraction Effect\n\\((k_1-1)\\times (k_2-1)\\)\n\n\nError\n\\(n-k_1\\cdot k_2\\)\n\n\nTotal\n\\(n-1\\)\n\n\n\n\n\n10.5.2 Eta-squared from Two-Way ANOVA statistics\nFor Two-way ANOVAs we can obtain \\(\\eta^2_p\\) for each predictor in the model. Let’s construct our ANOVA model using data from the palmerpenguins dataset (Horst, Hill, and Gorman 2020). In this example we want to see how the species and the sex of the penguin explains variance in body mass.\n\nlibrary(palmerpenguins)\n\nANOVA2_mdl &lt;- aov(body_mass_g ~ species + sex + species:sex,\n                  data = penguins)\n\nsummary(ANOVA2_mdl)\n\n             Df    Sum Sq  Mean Sq F value   Pr(&gt;F)    \nspecies       2 145190219 72595110 758.358  &lt; 2e-16 ***\nsex           1  37090262 37090262 387.460  &lt; 2e-16 ***\nspecies:sex   2   1676557   838278   8.757 0.000197 ***\nResiduals   327  31302628    95727                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n11 observations deleted due to missingness\n\n\n\n\n\n\n\n\n\n\n\nThe results show that species, sex, and the interaction between the two account for substantial variance in body mass. We can obtain the contributions of species, sex, and their interaction by computing the partial eta-squared value (\\(\\eta_p^2\\)). To do this using similar formulas to \\(\\eta^2\\) from the one-way ANOVAs. The difference between the formulas for \\(\\eta_p^2\\) anf \\(\\eta^2\\) is that \\(\\eta_p^2\\) does not use the total sum of squares in the denominator, instead it uses the residual sum of squares (\\(SS_\\text{error}\\)) and the sum of squares from the effect of interest (\\(SS_\\text{effect}\\); i.e., species or sex but not both). For example,\n\\[\n\\small{\\text{For species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{145190219}{145190219+ 31302628} = .82}\n\\] \\[\n\\small{\\text{For sex:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{37090262}{37090262 + 31302628} = .54}\n\\] \\[\n\\small{\\text{For sex}\\times\\text{species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{1676557}{1676557+ 31302628} = .05}\n\\] We can also easily do this in R using the eta_squared function in the effectsize package (Ben-Shachar, Lüdecke, and Makowski 2020) and setting the argument partial = TRUE.\n\nlibrary(effectsize)\n\neta_squared(ANOVA2_mdl,\n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter   | Eta2 (partial) |       95% CI\n-------------------------------------------\nspecies     |           0.82 | [0.79, 0.85]\nsex         |           0.54 | [0.48, 0.60]\nspecies:sex |           0.05 | [0.01, 0.10]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#two-way-repeated-measures-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#two-way-repeated-measures-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.6 Two-way repeated measures ANOVA",
    "text": "10.6 Two-way repeated measures ANOVA\nA two-way repeated measures ANOVA (rmANOVA) would indicate that subjects are exposed to each condition along two variables.\n\n10.6.1 Determing degrees of freedom\nPlease refer to the following table to determine the degrees of freedom for two-way rmANOVA effects (Morse 2018). Note that \\(k_1\\) is the number of groups in the first variable, and \\(k_2\\) is the number of groups in the second variable.\n\n\n\nDegrees of freedom\n\n\n\n\n\nBetween subjects ANOVA\n\n\n\nMain Effect (of one variable)\n\\(k_1-1\\) or \\(k_2-1\\)\n\n\nInteraction Effect\n\\((k_1-1)\\times (k_2-1)\\)\n\n\nError-between\n\\((k_1 \\cdot k_2) - 1\\)\n\n\nError-within\n\\((n - 1)\\times (k_1\\cdot k_2 - 1)\\)\n\n\nTotal\n\\(n-1\\)\n\n\n\n\n\n10.6.2 Eta-squared from Two-way rmANOVA\nFor a two-way repeated measures ANOVA, we can use the weightloss data set from the datarius package (Kassambara 2019). This data set contains a diet condition and a control condition that tracked subjects across time (3 time points) for each of condition.\n\n### load in and re-format data\nlibrary(tidyr)\ndata(\"weightloss\", package = \"datarium\")\nweightloss &lt;- tidyr::pivot_longer(weightloss,cols = c(\"t1\",\"t2\",\"t3\"))\ncolnames(weightloss) &lt;- c(\"subject\",\"diet\",\"exercises\",\"time\", \"weight_loss\")\nweightloss &lt;- weightloss[weightloss$diet=='no',] # remove the diet intervention trials\n####\n\nrmANOVA2_mdl = aov(formula = weight_loss ~ time + exercises + time:exercises + Error(subject),\n                   data = weightloss)\nsummary(rmANOVA2_mdl)\n\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals 11  20.64   1.877               \n\nError: Within\n               Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntime            2 129.26   64.63   50.57 3.45e-13 ***\nexercises       1 101.03  101.03   79.05 3.16e-12 ***\ntime:exercises  2  92.55   46.28   36.21 9.26e-11 ***\nResiduals      55  70.29    1.28                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\nFrom the table and graph above, we can see that there is substantial within-person change in weight loss under the exercise condition and no discernible increase in weight loss without exercising. This suggests that there is a substantial interaction effect. Like we did in the between-subjects two-way ANOVA, we can calculate the partial eta squared values from the ANOVA table\n\\[\n\\small{\\text{For time:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{129.26}{129.26+ 70.29} = .65}\n\\] \\[\n\\small{\\text{For exercise:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{101.03}{101.03 + 70.29} = .59}\n\\] \\[\n\\small{\\text{For sex}\\times\\text{species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{92.55}{92.55+ 70.29} = .57}\n\\]\nRemember for the partial eta-squared, the denominator is not the total sum of squares rather it is the effect sum of squares and the error. In the repeated measures ANOVA, the error should only be for the within subject error because the variance between subjects is not something we are interested about. We can also calculate this in R using the eta_squared() function again.\n\nlibrary(effectsize)\n\neta_squared(rmANOVA2_mdl,\n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nGroup  |      Parameter | Eta2 (partial) |       95% CI\n-------------------------------------------------------\nWithin |           time |           0.65 | [0.49, 0.75]\nWithin |      exercises |           0.59 | [0.42, 0.70]\nWithin | time:exercises |           0.57 | [0.39, 0.69]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#effect-sizes-for-anovas",
    "href": "Effect-Sizes-for-ANOVAs.html#effect-sizes-for-anovas",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.7 Effect Sizes for ANOVAs",
    "text": "10.7 Effect Sizes for ANOVAs\nANOVA (Analysis of Variance) is a statistical method used to compare means across multiple groups or conditions. It is mostly used when the outcome variable is continuous and the predictor variables are categorical. Commonly used effect size measures for ANOVAs / F-tests include: eta-squared (\\(\\eta^2\\)), partial eta-squared (\\(\\eta_p^2\\)), generalized eta-squared (\\(\\eta^2_G\\)), omega-squared (\\(\\omega^2\\)), partial omega-squared (\\(\\omega\\)), generalized omega-squared (\\(\\omega^2_G\\)), Cohen’s \\(f\\).\n\n\n\n\n\n\n\n\nType\nDescription\nSection\n\n\n\n\n\\(\\eta^2\\) - eta-squared\nMeasures the variance explained of the whole ANOVA model.\nSection 10.7.1\n\n\n\\(\\eta^2_p\\) - Partial eta-squared\nMeasures the variance explained by a specific factor in the model.\nSection 10.7.2\n\n\n\\(\\eta^2_G\\) - Generalized eta-squared\nSimilar to \\(\\eta^2\\), but uses the sum of squares of all non-manipulated variables in the calculation. This allows meta-analysts to compare \\(\\eta_G\\) across different designs.\nSection 10.7.3\n\n\n\\(\\omega^2,\\omega^2_p,\\omega^2_G\\) - Omega squared corrections\nCorrections to bias observed in \\(\\eta^2\\) measures. Can be interpreted in the same way as \\(\\eta^2\\).\nSection 10.7.4\n\n\n\\(f\\) - Cohen’s f\nThis effect size can be interpreted as the average Cohen’s \\(d\\) between each group.\nSection 10.7.5\n\n\n\n\n10.7.1 Eta-Squared (\\(\\eta^2\\))\nEta-squared is the ratio between the between-group variance and the total variance. It describes the proportion of the total variability in the data that are accounted for by a particular factor. Therefore, it is a measure of variance explained. To calculate eta-squared (\\(\\eta^2\\)) we need to first calculate the total sum of squares (\\(SS_{\\text{total}}\\)) and the effect sum of squares (\\(SS_{\\text{effect}}\\)),\n\\[\nSS_{\\text{total}} = \\sum_{i=1}^n (y_i-\\bar{y})^2\n\\]\nWhere \\(\\bar{y}\\) is the grand mean (i.e., the mean of all data points collapsed across groups). To calculate the sum of squares of the effect, we can take the predicted \\(y\\) values (\\(\\hat{y}_i\\)). In the case of categorical predictors, \\(\\hat{y}_i\\) is equal to the mean of the outcome within that individual’s respective group. Therefore the sum of squares of the effect can be calculated using the following formula:\n\\[\nSS_{\\text{effect}} = \\sum_{i=1}^n (\\hat{y}_i-\\bar{y})^2.\n\\]\nNow we can calculate the eta-squared value,\n\\[\n\\eta^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{total}}}\n\\]\nThe standard error of eta-square can be approximated from Olkin and Finn (1995):\n\\[\nSE_{\\eta^2}=\\sqrt{\\frac{4\\eta^2\\left(1-\\eta^2\\right)^2\\left(n+k-1\\right)^2}{\\left(n^2-1\\right)\\left(3+n\\right)}}\n\\]\nThe sampling distribution for \\(\\eta^2\\) is asymmetric as all the values are bounded in the range, 0 to 1. The confidence interval surrounding \\(\\eta^2\\) will likewise be asymmetric so instead of calculating the confidence interval from the standard error, we can instead use a non-central F-distribution using the degrees of freedom between groups (e.g., for three groups: \\(df_b=k-1=3-1=2\\)) and the degrees of freedom within groups (e.g., for 100 subjects and three groups: \\(df_b=n-k=100-3=97\\)) to obtain the confidence intervals. Another option is to use bootstrapping procedure (i.e., resampling the observed data points to construct a sampling distribution around \\(\\eta^2\\), see Kirby and Gerlanc 2013) and then take the .025 and .975 quantiles of that distribution. The R code below will compute the proper confidence interval.\nWhere \\(n\\) is the total sample size and \\(k\\) is the number of predictors. In R, we can calculate \\(\\eta^2\\) from a one-way ANOVA using the penguin data set from the palmerpenguins data package. The aov function in base R allows the analyst to model an ANOVA with categorical predictors on the right side (species) of the ~ and the outcome on the left side (body mass of penguin). We can then use the eta_squared function in the effectsize package to calculate the point estimate and confidence intervals.\n\n# Example:\n# group: species\n# outcome: body mass\n\nlibrary(palmerpenguins)\nlibrary(effectsize)\n\n# One-Way ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\neta_squared(mdl1, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.71]\n\n\nThe species of the penguin explains the majority of the variation in body mass showing an eta-squared value of \\(\\eta^2\\) = .67 [.62, .71]. Let us now do the same thing with a two-way ANOVA, using both species and sex as our categorical predictors.\n\n# Example:\n# group: species and sex\n# outcome: body mass\n\n# Two-Way ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\neta_squared(mdl2, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.72]\nsex       | 0.17 | [0.10, 0.24]\n\n\nNotice that the \\(\\eta^2\\) does not change for species since the sum of squares is divided by the total sum of squares rather than the residual sum of squares (see partial eta squared). The example shows an eta-squared value for species of \\(\\eta^2\\) = .67 [.62, .72] and for sex \\(\\eta^2\\) = .17 [.10, .24].\n\n\n10.7.2 Partial Eta-Squared (\\(\\eta^2_p\\))\nPartial eta-squared is the most commonly reported effect size measure for F-tests. It describes the proportion of variability associated with an effect when the variability associated with all other effects identified in the analysis has been removed from consideration (hence, it is “partial”). If you have access to an ANOVA table, the partial eta-squared for an effect is calculated as:\n\\[\n\\eta_p^2 = \\frac{ SS_{\\text{effect}}}{SS_{\\text{effect}}+SS_{\\text{error}}}\n\\]\nThere are two things to take note of here:\n\nIn a one-way ANOVA (one categorical predictor), partial eta-squared and eta-squared are equivalent since \\(SS_{\\text{total}} = SS_{\\text{effect}}+SS_{\\text{error}}\\)\nIf there are multiple predictors, the denominator will only include the sum of squares of the effect of interest rather than the effect of all predictors (which is the case for the non-partial eta squared).\n\nIn R, let us compare the partial eta-squared values for a one-way ANOVA and a two-way ANOVA using the eta_squared function in the effectsize package.\n\n# Example:\n# group: species\n# outcome: body mass\n\n\n# One-Way ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\neta_squared(mdl1, \n            partial = TRUE,\n            alternative = \"two.sided\") \n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.71]\n\n\nThe species of the penguin explains the majority of the variation in body mass showing a partial eta-squared value of \\(\\eta^2\\) = \\(\\eta^2_p\\) = .67 [.62, .71]. Let us now do the same thing with a two-way ANOVA, using both species and sex as our categorical predictors.\n\n# Example:\n# group: species and sex\n# outcome: body mass\n\n# Two-Way ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\neta_squared(mdl2, \n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 (partial) |       95% CI\n-----------------------------------------\nspecies   |           0.81 | [0.78, 0.84]\nsex       |           0.53 | [0.46, 0.59]\n\n\nOnce we run a two-way ANOVA, the eta-squared value for species begins to differ. The example shows a partial eta-squared value for species of \\(\\eta^2_p\\) = .81 [.78, .84] and for sex \\(\\eta^2\\) = .53 [.46, .59].\n\n\n10.7.3 Generalized Eta-Squared (\\(\\eta^2_G\\))\nGeneralized eta-squared was devised to allow effect size comparisons across studies with different designs, which eta-squared and partial eta-squared cannot help with (refer to for details). If you can (either you are confident that you calculated it right, or the statistical software that you use just happens to return this measure), report generalized eta-squared in addition to eta-squared or partial eta-squared. The biggest advantage of generalized eta-squared is that it facilitates meta-analysis, which is important for the accumulation of knowledge. To calculate generalized eta-squared, the denominator should be the sums of squares of all the non-manipulated variables (i.e., variance of purely individual differences in the outcome rather than individual differences in treatment effects). Note the formula will depend on the design of the study. In R, the eta_squared function in the effectsize package supports the calculation of generalized eta-squared by using the generalized=TRUE argument.\n\n\n10.7.4 Omega squared corrections (\\(\\omega^2\\), \\(\\omega^2_p\\))\nSimilar to Hedges’ correction for small sample bias in standardized mean differences, \\(\\eta^2\\) is also biased. We can apply a correction to \\(\\eta^2\\) and obtain a relatively unbiased estimate of the population proportion of variance explained by the predictor. To calculate \\(\\omega\\), we need to calculate the within group mean squared errors:\n\\[\nMS_{\\text{within}} = \\frac{1}{n}\\sum_{i=1}^n (y_i-\\hat{y}_i)^2.\n\\] Where the predicted values of the outcome, \\(\\hat{y}_i\\), are the mean value for the individual’s respective group.\n\\[\n\\omega^2 = \\frac{SS_{\\text{effect}}-(k-1)\\times MS_{\\text{within}}}{SS_{\\text{total}} + MS_{\\text{within}}}\n\\]\nWhere \\(k\\) is the number of groups in the predictor (effect) variable. For partial omega-squared values, we need the mean squared error of effect and the residuals which can easily be calculated from their sum of squares:\n\\[\nMS_{\\text{effect}} = \\frac{SS_{\\text{effect}}}{n}\n\\] \\[\nMS_{\\text{error}} = \\frac{SS_{\\text{error}}}{n}\n\\] Then to calculate the partial omega squared we can use the following formula:\n\\[\n\\omega_p^2 = \\frac{(k-1)(MS_{\\text{effect}} - MS_{\\text{error}})}{(k-1)\\times MS_{\\text{effect}} + (n-k-1)\\times MS_{\\text{error}}}\n\\]\nIn R, we can use the omega_squared function in the effectsize package to calculate both \\(\\omega^2\\) and \\(\\omega^2_p\\). For the first example we will use a one-way ANOVA.\n\n# Example:\n# group: species\n# outcome: body mass\n\nlibrary(palmerpenguins)\n\n# One-Way ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\n# omega-squared\nomega_squared(mdl1, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.61, 0.71]\n\n# partial omega-squared\nomega_squared(mdl1, \n              partial = TRUE,\n              alternative = \"two.sided\")\n\nFor one-way between subjects designs, partial omega squared is\n  equivalent to omega squared. Returning omega squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.61, 0.71]\n\n\nThe species of the penguin explains the majority of the variation in body mass showing an omega-squared value of \\(\\omega^2\\) = .67 [.61, .71]. Note that the partial and non-partial omega squared values do not show a difference as expected in a one-way ANOVA. Let us now do the same thing with a two-way ANOVA, using both species and sex as our categorical predictors.\n\n# Example:\n# group: species and sex\n# outcome: body mass\n\n# Two-Way ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\n# omega-squared\nomega_squared(mdl2, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.62, 0.72]\nsex       |   0.17 | [0.10, 0.24]\n\n# partial omega-squared\nomega_squared(mdl2, \n              partial = TRUE,\n              alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 (partial) |       95% CI\n-------------------------------------------\nspecies   |             0.81 | [0.78, 0.84]\nsex       |             0.53 | [0.46, 0.58]\n\n\nOnce we run a two-way ANOVA, the eta-squared value for species diverge. The example shows a partial eta-squared value for species of \\(\\omega^2_p\\) = .81 [.78, .84] and for sex \\(\\omega^2\\) = .53 [.46, .58].\n\n\n10.7.5 Cohen’s \\(f\\)\nCohen’s \\(f\\) is defined as the ratio of the standard deviations of the group means and the common standard deviation within each of the groups (note that ANOVA assumes equal variances among groups). Cohen’s \\(f\\) is the effect size measure asked for by G*Power for power analysis for F-tests. This can be calculated easily from the eta-squared value,\n\\[\nf = \\sqrt{\\frac{\\eta^2}{1-\\eta^2}}\n\\]\nor by the \\(\\omega^2\\) value,\n\\[\nf = \\sqrt{\\frac{\\omega^2}{1-\\omega^2}}\n\\]\nCohen’s \\(f\\) can be interpreted as “the average Cohen’s \\(d\\) (i.e., standardized mean difference) between groups”. Note that there is no directionality to this effect size (\\(f\\) is always greater than zero), therefore two studies showing the same \\(f\\) with the same groups, can have very different patterns of group mean differences. Note that Cohen’s \\(f\\) is also often reported as \\(f^2\\). The confidence intervals for Cohen’s \\(f\\) can be computed from the upper bounds and lower bounds of the confidence intervals from eta-square or omega-square using the formulas to calculate \\(f\\) (e.g., for the upper bound \\(f_{UP} = \\sqrt{\\frac{\\eta^2_{UP}}{1-\\eta^2_{UP}}}\\)).\nIn R, we can use the cohens_f function in the effectsize package to calculate Cohen’s \\(f\\). We will again use example data from the palmerpenguins package.\n\n# Example:\n# group: species\n# outcome: body mass\n\n# ANOVA\nmdl &lt;- aov(data = penguins,\n           body_mass_g ~ species)   \n\ncohens_f(mdl,alternative = \"two.sided\")\n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Cohen's f |       95% CI\n------------------------------------\nspecies   |      1.42 | [1.27, 1.57]\n\n\nIn the example above, the difference in body mass between the three penguin species was very large showing a Cohen’s \\(f\\) of 1.42 [1.27, 1.57].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#reporting-anova-results",
    "href": "Effect-Sizes-for-ANOVAs.html#reporting-anova-results",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.8 Reporting ANOVA results",
    "text": "10.8 Reporting ANOVA results\nFor ANOVAs/F-tests, you will always need to report two kinds of effects: the omnibus effect of the factor(s) and the effect of planned contrasts or post hoc comparisons.\nFor instance, imagine that you are comparing three groups/conditions with a one-way ANOVA. The ANOVA will first return an F-statistic, the degrees of freedom, and the associated p-value. Here, you need to calculate the size of this omnibus factor effect in eta-squared, partial eta-squared, or generalized eta-squared. Suppose the omnibus effect is significant. You now know that there is at least one group that differs from the others. You want to know which group(s) differ from the others, and how much they differ. Therefore, you conduct post hoc comparisons on these groups. Because post hoc comparisons compare each group with the others in pairs, you will get a t-statistic and p-value for each comparison. For this, you need to calculate and report Cohen’s \\(d\\) or Hedges’ \\(g\\).\nImagine that you have two independent variables or factors, and you conduct a two-by-two factorial ANOVA. The first thing to do then is look at the interaction. If the interaction is significant, you again report the associated omnibus effect size measures, and proceed to analyze the simple effects. Depending on your research question, you compare the levels of one IV on each level of the other IV. You will report d or g for these simple effects. If the interaction is not significant, you look at the main effects and report the associated omnibus effect. You then proceed to analyze the main effect by comparing the levels of one IV while collapsing/aggregating the levels of the other IV. You will report \\(d\\) or \\(g\\) for these pairwise comparisons.\nNote that lower-order effects are not directly interpretable if higher-order effects are significant. If you have a significant interaction in a two-way ANOVA, you cannot interpret the main effects directly. If you have a significant three-way interaction in a three-way ANOVA, you cannot interpret the main effects or the two-way interactions directly, regardless of whether they are significant or not.\nIn R, we can use the summary function to display the anova table. We can also append the table to include, for example, partial omega squared values and their respective confidence intervals\n\n# ANOVA mdl\nmdl &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)   \n\n# calculate partial omega-squared values\nomega_values &lt;- omega_squared(mdl, alternative = \"two.sided\")\n\n# create table of partial omega-squared values\nomega_table &lt;- data.frame(omega_sq = MOTE::apa(c(omega_values$Omega2_partial,NA)),\n                     omega_low = MOTE::apa(c(omega_values$CI_low,NA)),\n                     omega_high = MOTE::apa(c(omega_values$CI_high,NA)))\n\n# append omega values to summary of anova table\ncbind(summary(mdl)[[1]],\n      omega_table)\n\n             Df    Sum Sq    Mean Sq  F value        Pr(&gt;F) omega_sq omega_low\nspecies       2 145190219 72595109.6 724.2080 3.079053e-121    0.813     0.781\nsex           1  37090262 37090261.8 370.0121  8.729411e-56    0.526     0.457\nResiduals   329  32979185   100240.7       NA            NA       NA        NA\n            omega_high\nspecies          0.838\nsex              0.585\nResiduals           NA\n\n\n\n\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.\n\n\nBuchanan, Erin M., Amber Gillenwaters, John E. Scofield, and K. D. Valentine. 2019. MOTE: Measure of the Effect: Package to Assist in Effect Size Calculations and Their Confidence Intervals. http://github.com/doomlab/MOTE.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\n\n\nKassambara, Alboukadel. 2019. Datarium: Data Bank for Statistical Analysis and Visualization. https://CRAN.R-project.org/package=datarium.\n\n\nKirby, Kris N, and Daniel Gerlanc. 2013. “BootES: An r Package for Bootstrap Confidence Intervals on Effect Sizes.” Behavior Research Methods 45: 905–27.\n\n\nMorse, David. 2018. “How to Calculate Degrees of Freedom When Using Two Way ANOVA with Unequal Sample Size?”\n\n\nOlkin, Ingram, and Jeremy D. Finn. 1995. “Correlations Redux.” Psychological Bulletin 118 (1): 155–64. https://doi.org/10.1037/0033-2909.118.1.155.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in R with the metafor Package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#footnotes",
    "href": "Effect-Sizes-for-ANOVAs.html#footnotes",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "",
    "text": "Er zijn varianten van ANOVA’s waarbij elk van deze aannames geschonden kan worden.↩︎\nBekijk deze forum discussie voor uitleg.↩︎",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Differences-in-Variance.html#sec-vr",
    "href": "Differences-in-Variance.html#sec-vr",
    "title": "11  Differences in Variability",
    "section": "11.1 Variability Ratios",
    "text": "11.1 Variability Ratios\n\n11.1.1 Natural Logarithm of Variability Ratio for Independent Groups (\\(lnVR_\\text{ind}\\))\nThe variability ratio for independent groups can be calculated by taking the natural logarithm of the standard deviation within one group divided by the standard deviation in another group,\n\\[\nlnVR_\\text{ind}=\\ln\\left(\\frac{S_T}{S_C}\\right) + CF\n\\]\nWhere \\(CF\\) is a small sample correction factor calculated as,\n\\[\nCF=\\frac{1}{2(n_T-1)}-\\frac{1}{2(n_C-1)}\n\\]\nA \\(lnVR\\) of zero therefore would indicate no difference in variation between the two groups, a \\(lnVR\\) of &gt;0 would indicate larger variance in group 1, and \\(lnVR\\) of &lt;0 would indicate larger variance in group 2. The standard error of the VR can be calculated as,\n\\[\nSE_{lnVR_\\text{ind}}=\\sqrt{\\frac{n_T}{2(n_T-1)^2}+\\frac{n_C}{2(n_C-1)^2}}\n\\]\nIn R, we can simply use the metafor packages escalc() function from the metafor package (Viechtbauer 2010) as follows:\n\n# Example:\n# Group 1: standard deviation = 4.5, sample size = 50\n# Group 2: standard deviation = 3.5, sample size = 50\n\nlibrary(metafor)\n\n# prepare the data\nSD1 &lt;- 4.5\nSD2 &lt;- 3.5\nn1 &lt;- n2 &lt;- 50\n\nlnVRind &lt;- escalc(\n    measure = \"VR\",\n    sd1i = SD1,\n    sd2i = SD2,\n    n1i = n1,\n    n2i = n2\n  )\n\n\nlnVRind$SE &lt;- sqrt(lnVRind$vi)\n\n# calculate confidence interval\nlnVRind_low &lt;- lnVRind$yi - 1.96*lnVRind$SE\nlnVRind_high &lt;- lnVRind$yi + 1.96*lnVRind$SE\n\n# print the VR value and confidence intervals\ndata.frame(lnVRind = MOTE::apa(lnVRind$yi),\n           lnVRind_low = MOTE::apa(lnVRind_low),\n           lnVRind_high = MOTE::apa(lnVRind_high))\n\n  lnVRind lnVRind_low lnVRind_high\n1   0.251      -0.029        0.531\n\n\nFrom the example, we obtain a natural log variability ratio of \\(lnVR_\\text{ind}\\) = 0.25 [-0.03, 0.53].\n\n\n11.1.2 Natural Logarithm of Variability Ratio for Dependent Groups (\\(lnVR_\\text{dep}\\))\nThe variability ratio for dependent groups can similarly be calculated by taking the natural logarithm of the standard deviation within one group divided by the standard deviation in another group,\n\\[\nlnVR_\\text{dep}=\\ln\\left(\\frac{S_T}{S_C}\\right)\n\\]\nNote, the correction factor for small sample size bias is not relevant here as due to its calculation its value is zero.\n\\[\nSE_{lnVR_\\text{dep}}=\\sqrt{\\frac{n}{n-1} - \\frac{r^2}{n-1} +  \\frac{r^4\\left(S^8_T+S^8_C\\right)}{2(n-1)^2 S^4_T+S^4_C}}\n\\]\nIn R, we can simply use the metafor packages escalc() function as follows:\n\n# Example:\n# Group 1: standard deviation = 4.5\n# Group 2: standard deviation = 3.5\n# Sample size = 50\n# Correlation = 0.4\n\nlibrary(metafor)\n\n# prepare the data\nSD1 &lt;- 4.5\nSD2 &lt;- 3.5\nn &lt;- 50\nr &lt;- 0.4\n\n# use escalc to compute lnVRdep\nlnVRdep &lt;- escalc(\n  measure = \"VRC\",\n  sd1i = SD1,\n  sd2i = SD2,\n  ni = n1,\n  ri = r\n)\n\n\nlnVRdep$SE &lt;- sqrt(lnVRdep$vi)\n\n# calculate confidence interval\nlnVRdep_low &lt;- lnVRdep$yi - 1.96*lnVRdep$SE\nlnVRdep_high &lt;- lnVRdep$yi + 1.96*lnVRdep$SE\n\n# print the VR value and confidence intervals\ndata.frame(lnVRdep = MOTE::apa(lnVRdep$yi),\n           lnVRdep_low = MOTE::apa(lnVRdep_low),\n           v_high = MOTE::apa(lnVRdep_high))\n\n  lnVRdep lnVRdep_low v_high\n1   0.251      -0.005  0.508",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Verschillen in Variabiliteit</span>"
    ]
  },
  {
    "objectID": "Differences-in-Variance.html#sec-cvr",
    "href": "Differences-in-Variance.html#sec-cvr",
    "title": "11  Differences in Variability",
    "section": "11.2 Coefficient of Variation Ratios",
    "text": "11.2 Coefficient of Variation Ratios\n\n11.2.1 Natural Logarithm of Coefficient of Variation Ratio for independent groups (lnCVR_)\nThe coefficient of variation ratio for independent groups can be calculated by taking the natural logarithm of the coefficient of variation within one group divided by the coefficient of variation in another group,\n\\[\nlnCVR_\\text{ind}=\\ln\\left(\\frac{CV_T}{CV_C}\\right) + CF\n\\]\nWhere \\(CV_T =S_T / M_T\\), \\(CV_C =S_C / M_C\\), and \\(M\\) indicates the mean of the respective group. The correction factor, \\(CF\\), is a small sample size bias correction factor that combines that from the lnRR (presented earlier) and the lnVR calculated as,\n\\[\nCF=\\frac{1}{2(n_T-1)}-\\frac{1}{2(n_C-1)} + \\frac{S_T^2}{2(n_TM_T^2)} + \\frac{S_C^2}{2(n_CM_C^2)}\n\\] In R, we can simply use the escalc() function from the metafor package as follows:\n\n# Example:\n# Group 1: mean = 22.4, standard deviation = 4.5, sample size = 50\n# Group 2: mean = 20.1, standard deviation = 3.5, sample size = 50\n\nlibrary(metafor)\n\n# prepare the data\nM1 &lt;- 22.4\nM2 &lt;- 20.1\nSD1 &lt;- 4.5\nSD2 &lt;- 3.5\nn1 &lt;- n2 &lt;- 50\n\nlnCVRind &lt;- escalc(\n  measure = \"CVR\",\n  m1i = M1,\n  m2i = M2,\n  sd1i = SD1,\n  sd2i = SD2,\n  n1i = n1,\n  n2i = n2\n)\n\nlnCVRind$SE &lt;- sqrt(lnCVRind$vi) \n\n# calculate confidence interval\nlnCVRind_low &lt;- lnCVRind$yi - 1.96*lnCVRind$SE\nlnCVRind_high &lt;- lnCVRind$yi + 1.96*lnCVRind$SE\n\n# print the VR value and confidence intervals\ndata.frame(lnCVRind = MOTE::apa(lnCVRind$yi),\n           lnCVRind_low = MOTE::apa(lnCVRind_low),\n           lnCVRind_high = MOTE::apa(lnCVRind_high))\n\n  lnCVRind lnCVRind_low lnCVRind_high\n1    0.143       -0.147         0.433\n\n\n\n\n11.2.2 Natural Logarithm of Coefficient of Variation Ratio for independent groups (\\(lnCVR_\\text{dep}\\))\nThe coefficient of variation ratio for dependent groups can be similarly calculated by taking the natural logarithm of the coefficient of variation within one group divided by the coefficient of variation in another group,\n\\[\nlnCVR_\\text{dep}=\\ln\\left(\\frac{CV_T}{CV_C}\\right) + CF\n\\]\nWhere \\(CV_T =S_T / M_T\\), \\(CV_C =S_C / M_C\\) and CF is a small sample size bias correction factor that combines that from the \\(lnVR\\) (presented earlier) and the \\(lnVR\\) (note again for dependent cases this is zero and so omitted) calculated as,\n\\[\nCF = \\frac{S^2_T}{2n M_T^2} - \\frac{S^2_C}{2nM_C^2}\n\\]\nThe standard error of the \\(lnCVR_\\text{dep}\\) can be calculated as,\n\\[\n\\small{SE_{lnCVR_\\text{dep}} = \\sqrt{\\frac{S^2_T}{n M_T^2} + \\frac{S^2_T}{nM_T^2} + \\frac{S^4_T}{2n^2 M_T^4} + \\frac{S^4_T}{2n^2 M_T^4} + \\frac{2rS_CS_T}{n M_C M_T} + \\frac{r^2S^2_T S^2_C (M^4_T + M^4_C)}{2n^2M_T^4M^4_C}}}\n\\] In R, we can simply use the metafor packages escalc() function as follows:\n\n# Example:\n# Group 1: standard deviation = 4.5\n# Group 2: standard deviation = 3.5\n# Sample size = 50\n# Correlation = 0.4\nlibrary(metafor)\n\n# prepare the data\nM1 &lt;- 22.4\nM2 &lt;- 20.1\nSD1 &lt;- 4.5\nSD2 &lt;- 3.5\nn &lt;- 50\nr &lt;- 0.4\n\nlnCVRdep &lt;- escalc(\n  measure = \"CVRC\",\n  m1i = M1,\n  m2i = M2,\n  sd1i = SD1,\n  sd2i = SD2,\n  ni = n1,\n  ri = r\n)\n\nlnCVRdep$SE &lt;- sqrt(lnCVRdep$vi)\n\n# calculate confidence interval\nlnCVRdep_low &lt;- lnCVRdep$yi - 1.96*lnCVRdep$SE\nlnCVRdep_high &lt;- lnCVRdep$yi + 1.96*lnCVRdep$SE\n\n# print the CVR value and confidence intervals\ndata.frame(lnCVRdep = MOTE::apa(lnCVRdep$yi),\n           lnCVRdep_low = MOTE::apa(lnCVRdep_low),\n           lnCVRdep_high = MOTE::apa(lnCVRdep_high))\n\n  lnCVRdep lnCVRdep_low lnCVRdep_high\n1    0.143       -0.120         0.406\n\n\n\n\n\n\nSenior, Alistair M., Wolfgang Viechtbauer, and Shinichi Nakagawa. 2020. “Revisiting and Expanding the Meta-Analysis of Variation: The Log Coefficient of Variation Ratio.” Research Synthesis Methods 11 (4): 553–67. https://doi.org/10.1002/jrsm.1423.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in R with the metafor Package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Verschillen in Variabiliteit</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html",
    "href": "Standardized-Mean-Differences.html",
    "title": "7  Gemiddelde verschillen",
    "section": "",
    "text": "Hier is een tabel voor elke effectgrootte die in dit hoofdstuk is besproken:",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#vertekening-in-kleine-steekproeven-van-d-waarden",
    "href": "Standardized-Mean-Differences.html#vertekening-in-kleine-steekproeven-van-d-waarden",
    "title": "7  Gemiddelde verschillen",
    "section": "7.6 Vertekening in kleine steekproeven van \\(d\\) waarden",
    "text": "7.6 Vertekening in kleine steekproeven van \\(d\\) waarden\nAlle bovenstaande schatters van \\(d\\) zijn vertekende schattingen van de populatiewaarde \\(d\\), meer bepaald overschatten ze allemaal de populatiewaarde bij kleine steekproeven. Om voor deze vertekening te corrigeren, kunnen we een correctiefactor toepassen op basis van de vrijheidsgraden. De vrijheidsgraden hangen grotendeels af van de gebruikte schatter. De vrijheidsgraden voor elke schatter staan hieronder vermeld:\n\nSingle Group design (\\(d_s\\)): \\(df = n-1\\)\nBetween Groups - Pooled Standard Deviation (\\(d_p\\)): \\(df = n_1+n_2-2\\)\nBetween Groups - Control Group Standard Deviation (\\(d_\\Delta\\)): \\(df = n_C-1\\)\nRepeated Measures - all types (\\(d_z\\), \\(d_{rm}\\), \\(d_{av}\\), \\(d_{b}\\)): \\(df = n-1\\)\nPretest-Posttest-Control Separate Standard Deviation (\\(d_{PPC1}\\)): \\(df=n_C−1\\)\nPretest-Posttest-Control Pooled Pretest Standard Deviation (\\(d_{PPC2}\\)): \\(df=n_T+n_C−2\\)\nPretest-Posttest-Control Pooled Pretest and Posttest Standard Deviation (\\(d_{PPC3}\\)): \\(df=2(n_T+n_C−2)\\)\n\nWith the appropriate degrees of freedom, we can use the following correction factor, \\(CF\\), to obtain an unbiased estimate of the population standardized mean difference:\n\\[\nCF = \\frac{\\Gamma\\left(\\frac{df}{2}\\right)}{\\Gamma\\left(\\frac{df-1}{2}\\right)\\sqrt{\\frac{df}{2}}}\n\\]\nWhere \\(\\Gamma(\\cdot)\\) is the gamma function. An approximation of this complex formula given by Hedges (1981) can be written as \\(CF\\approx 1-\\frac{3}{4\\cdot df -1}\\). In R, this can be calculated using,\n\n# Example:\n# Group 1 sample size = 20\n# Group 2 sample size = 18\n\nn1 &lt;- 20\nn2 &lt;- 18\n\ndf &lt;- n1 + n2 - 2\n\nCF &lt;- gamma(df/2) / ( sqrt(df/2) * gamma((df-1)/2) )\n\nCF\n\n[1] 0.9789964\n\n\nThis correction factor can then be applied to any of the estimators mentioned above,\n\\[\nd^* = d\\times CF\n\\]\nThe corrected \\(d\\) value, \\(d^*\\), is commonly referred to as Hedges’ \\(g\\) or just \\(g\\). To avoid notation confusion we will just add an asterisk to \\(d\\) to denote the correction. We also need to correct the standard error for \\(d^*\\)\n\\[\nSE_{d^*} = SE_{d} \\times CF\n\\]\nThese standard errors can then be used to calculate the confidence interval of the corrected \\(d\\) value,\n\\[\nCI_{d*} = d^* \\pm 1.96\\times SE_{d^*}\n\\]\n\n# Example:\n# Cohen's d = .50, SE = .10\n\nd = .50\nSE = .10\n\n# correct d value and CIs small sample bias\nd_corrected &lt;- d * CF\nSE_corrected &lt;- SE * CF\ndlow_corrected &lt;- d_corrected - 1.96*SE_corrected\ndhigh_corrected &lt;- d_corrected + 1.96*SE_corrected\n\n# print just the d value and confidence intervals\ndata.frame(d = apa(d), \n           dlow = apa(dlow_corrected), \n           dhigh = apa(dhigh_corrected))\n\n      d  dlow dhigh\n1 0.500 0.298 0.681\n\n\nThe output shows that the corrected effect size is \\(d^*\\) = 0.50, 95% CI [0.30, 0.68].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Standardized-Mean-Differences.html#vertekening-van-d-waarden-in-kleine-steekproeven",
    "href": "Standardized-Mean-Differences.html#vertekening-van-d-waarden-in-kleine-steekproeven",
    "title": "7  Gemiddelde verschillen",
    "section": "7.6 Vertekening van \\(d\\) waarden in kleine steekproeven",
    "text": "7.6 Vertekening van \\(d\\) waarden in kleine steekproeven\nAlle bovenstaande schatters van \\(d\\) zijn vertekende schattingen van de populatiewaarde \\(d\\), vooral overschatten ze allemaal de populatiewaarde bij kleine steekproeven. Om voor deze vertekening te corrigeren, kunnen we een correctiefactor toepassen op basis van de vrijheidsgraden. De vrijheidsgraden hangen grotendeels af van de gebruikte schatter. De vrijheidsgraden voor elke schatter staan hieronder vermeld:\n\nEnkelvoudig Groep design (\\(d_s\\)): \\(df = n-1\\)\nTussen Groepen - Gepoolde Standaard Deviatie (\\(d_p\\)): \\(df = n_1+n_2-2\\)\nTussen Groepen - Controle Groep Standaard Deviatie (\\(d_\\Delta\\)): \\(df = n_C-1\\)\nHerhaalde metingen - alle types (\\(d_z\\), \\(d_{rm}\\), \\(d_{av}\\), \\(d_{b}\\)): \\(df = n-1\\)\nPretest-Posttest-Controle Afzonderlijke Standaard Deviatie (\\(d_{PPC1}\\)): \\(df=n_C−1\\)\nPretest-Posttest-Controle Gepoolde Pretest Standaard Deviatie (\\(d_{PPC2}\\)): \\(df=n_T+n_C−2\\)\nPretest-Posttest-Controle Gepooled Pretest en Posttest Standaard Deviatie (\\(d_{PPC3}\\)): \\(df=2(n_T+n_C−2)\\)\n\nMet de juiste vrijheidsgraden kunnen we de volgende correctiefactor, \\(CF\\), gebruiken om een onvertekende schatting van het gestandaardiseerde gemiddelde verschil van de populatie te krijgen:\n\\[\nCF = \\frac{\\Gamma\\left(\\frac{df}{2}\\right)}{\\Gamma\\left(\\frac{df-1}{2}\\right)\\sqrt{\\frac{df}{2}}}\n\\]\nWaarbij \\(Gamma(\\cdot)\\) de gammafunctie is. Een benadering van deze complexe formule gegeven door Hedges (1981) kan worden geschreven als \\(CF\\approx 1-\\frac{3}{4\\cdot df -1}\\). In R kan dit worden berekend met,\n\n# Voorbeeld:\n# Groep 1 sample omvang = 20\n# Groep 2 sample omvang = 18\n\nn1 &lt;- 20\nn2 &lt;- 18\n\ndf &lt;- n1 + n2 - 2\n\nCF &lt;- gamma(df/2) / ( sqrt(df/2) * gamma((df-1)/2) )\n\nCF\n\n[1] 0.9789964\n\n\nDeze correctiefactor kan dan worden toegepast op elk van de bovengenoemde schatters,\n\\[\nd^* = d\\times CF\n\\]\nDe gecorrigeerde \\(d\\) waarde, \\(d^*\\), wordt gewoonlijk Hedges’ \\(g\\) of gewoon \\(g\\) genoemd. Om verwarring in de notatie te voorkomen voegen we een sterretje toe aan \\(d\\) om de correctie aan te geven. We moeten ook de standaardfout voor \\(d^*\\) corrigeren\n\\[\nSE_{d^*} = SE_{d} \\times CF\n\\]\nDeze standaardfouten kunnen dan worden gebruikt om het betrouwbaarheidsinterval van de gecorrigeerde \\(d\\) -waarde te berekenen,\n\\[\nCI_{d*} = d^* \\pm 1.96\\times SE_{d^*}\n\\]\n\n# Voorbeeld:\n# Cohen's d = .50, SE = .10\n\nd = .50\nSE = .10\n\n# bereken d waarde en CI's van kleine sample bias\nd_corrected &lt;- d * CF\nSE_corrected &lt;- SE * CF\ndlow_corrected &lt;- d_corrected - 1.96*SE_corrected\ndhigh_corrected &lt;- d_corrected + 1.96*SE_corrected\n\n# druk alleen de d waarde en betrouwbaarheidsintrvallen af\ndata.frame(d = apa(d), \n           dlow = apa(dlow_corrected), \n           dhigh = apa(dhigh_corrected))\n\n      d  dlow dhigh\n1 0.500 0.298 0.681\n\n\nDe output laat zien dat de gecorrigeerde effectgrootte \\(d^*\\) = 0,50, 95% CI [0,30, 0,68].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Gemiddelde Verschillen</span>"
    ]
  },
  {
    "objectID": "Converting-to-Cohens-d.html",
    "href": "Converting-to-Cohens-d.html",
    "title": "15  Omzetten naar Cohens \\(d\\)",
    "section": "",
    "text": "15.1 Van onafhankelijke steekproef \\(t\\)-statistiek\nOm een gestandaardiseerd gemiddeld verschil (\\(d_p\\), d.w.z. gepoolde standaarddeviatiestandaardisator) tussen subjecten te berekenen, kunnen we de steekproefgrootte in elke groep (\\(n_1\\) en \\(n_2\\)) en de \\(t\\)-statistiek van een onafhankelijke t-test gebruiken en deze in de volgende formule stoppen:\n\\[\nd_{p} = t\\sqrt{\\frac{1}{n_1}+\\frac{1}{n_2} }\n\\]\nMet behulp van de t_to_d functie in het effectsize pakket kunnen we \\(t\\) omzetten naar \\(d_p\\).\n# Bijvoorbeeld:\n# ongepaarde t-statistiek = 3.25\n# n1 = 50, n2 = 40\n\nlibrary(effectsize)\n\nt &lt;- 3.25\nn1 &lt;- 50\nn2 &lt;- 40\n\nt_to_d(t, df_error = n1+n2-2, paired = FALSE)\n\nd    |       95% CI\n-------------------\n0.69 | [0.26, 1.12]",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Omrekenen naar Cohen's d</span>"
    ]
  },
  {
    "objectID": "Converting-to-Cohens-d.html#van-gepaarde-steekproef-t-statistiek",
    "href": "Converting-to-Cohens-d.html#van-gepaarde-steekproef-t-statistiek",
    "title": "15  Omzetten naar Cohens \\(d\\)",
    "section": "15.2 Van gepaarde steekproef \\(t\\)-statistiek",
    "text": "15.2 Van gepaarde steekproef \\(t\\)-statistiek\nOm een gestandaardiseerd gemiddeld verschil binnen een groep te berekenen (\\(d_z\\), d.w.z. verschilscorestandaardisator), kunnen we de steekproefgrootte in elke groep (\\(n_1\\) en \\(n_2\\)) en de \\(t\\)-statistiek van een gepaarde t-test van de steekproef gebruiken en deze in de volgende formule stoppen:\n\\[\nd_{z} = \\frac{t}{\\sqrt{n}}\n\\]\nMet behulp van de t_to_d functie in het effectsize pakket kunnen we \\(t\\) omzetten naar \\(d_z\\).\n\n# Bijvoorbeeld:\n# gepaarde t-statistiek = 3.25\n# n = 50\n\nt &lt;- 3.25\nn &lt;- 50\n\nt_to_d(t, df_error = n-1, paired = TRUE)\n\nd    |       95% CI\n-------------------\n0.46 | [0.17, 0.76]",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Omrekenen naar Cohen's d</span>"
    ]
  },
  {
    "objectID": "Converting-to-Cohens-d.html#van-pearson-correlatie",
    "href": "Converting-to-Cohens-d.html#van-pearson-correlatie",
    "title": "15  Omzetten naar Cohens \\(d\\)",
    "section": "15.3 Van Pearson Correlatie",
    "text": "15.3 Van Pearson Correlatie\nAls er een Pearson correlatie wordt berekend tussen een continue score en een dichotome score, dan wordt dit beschouwd als een punt-biseriële correlatie. De punt-biseriële correlatie kan worden omgezet in een \\(d_p\\) waarde met behulp van de volgende formule:\n\\[\nd_p = \\frac{r}{\\sqrt{1-r^2}} \\sqrt{\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}\n\\] Of als de steekproefgrootte binnen elke groep onbekend (of gelijk) is, dan wordt de vergelijking bij benadering,\n\\[\nd_p \\approx \\frac{r\\sqrt{4}}{\\sqrt{1-r^2}}\n\\]\nMet behulp van de r_to_d functie in het effectsize pakket kunnen we \\(r\\) omzetten naar \\(d_p\\).\n\n# Bijvoorbeeld:\n# r = 3.25\n# n1 = 50, n2 = 40\n\nr &lt;- .50\nn1 &lt;- 50\nn2 &lt;- 40\n\nr_to_d(r = r, n1 = n1, n2 = n2)\n\n[1] 1.148913",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Omrekenen naar Cohen's d</span>"
    ]
  },
  {
    "objectID": "Converting-to-Cohens-d.html#van-odds-ratio",
    "href": "Converting-to-Cohens-d.html#van-odds-ratio",
    "title": "15  Omzetten naar Cohens \\(d\\)",
    "section": "15.4 Van Odds-Ratio",
    "text": "15.4 Van Odds-Ratio\nEen odds-ratio uit een contingentietabel kan ook worden omgezet in een \\(d_p\\). Merk op dat deze formule een benadering is:\n\\[\nd_{p} = \\frac{\\log(OR)\\sqrt{3}}{\\pi}\n\\]\nMet de functie oddsratio_to_d in het pakket effectsize kunnen we \\(OR\\) omzetten in \\(d_p\\).\n\n# Bijvoorbeeld  :\n# OR = 1.62\n\nOR &lt;- 1.46\n\noddsratio_to_d(OR = OR)\n\n[1] 0.2086429",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Omrekenen naar Cohen's d</span>"
    ]
  },
  {
    "objectID": "Converting-to-Correlation.html",
    "href": "Converting-to-Correlation.html",
    "title": "16  Omzetten naar Pearson Correlation",
    "section": "",
    "text": "16.1 Van \\(t\\)-statistiek\nVan een \\(t\\) statistiek die berekend is met een correlatietest, kunnen we de correlatiecoëfficiënt berekenen met de volgende formule:\n\\[\nr = \\sqrt{\\frac{t^2}{t^2 + n-2}}\n\\]\nGebruik de t_to_r functie in het effectsize pakket om \\(t\\) naar \\(r\\) te converteren.\n# Bijvoorbeeld:\n# t = 4.14, n = 50\n\nlibrary(effectsize)\n\nt &lt;- 4.14\nn &lt;- 50\n\nt_to_r(t = t, df = n-2)\n\nr    |       95% CI\n-------------------\n0.51 | [0.28, 0.67]",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Omrekenen naar Correlaties</span>"
    ]
  },
  {
    "objectID": "Converting-to-Odds-Ratio.html",
    "href": "Converting-to-Odds-Ratio.html",
    "title": "17  Converteren naar Odds Ratio",
    "section": "",
    "text": "17.1 Van Cohen’s \\(d\\)\nWe kunnen een oddsratio berekenen op basis van de \\(d\\) van Cohen (\\(d_p\\)) tussen groepen:\n\\[\nOR = \\exp\\left(\\frac{d_p \\pi}{\\sqrt{3}}\\right)\n\\]\nWaarbij \\(exp(\\cdot)\\) een exponentiële transformatie is (dit inverteert de logaritme). Met de functie d_to_oddsratio in het pakket effectsize kunnen we \\(d\\) omrekenen naar \\(OR\\).\n# Bijvoorbeeld:\n# d = 0.60, n1 = 50, n2 = 70\n\nlibrary(effectsize)\n\nd &lt;- 0.60\nn1 &lt;- 50\nn2 &lt;- 70\n\nd_to_oddsratio(d = d, n1 = n1, n2 = n2)\n\n[1] 2.969162",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Omrekenen naar Odds Ratios</span>"
    ]
  },
  {
    "objectID": "Conclusion.html",
    "href": "Conclusion.html",
    "title": "18  Beperkingen en toekomstige richtingen",
    "section": "",
    "text": "18.1 Conclusie\nRobuuste kwantificering van studieresultaten is een centrale pijler van open en reproduceerbare wetenschap. Met deze gezamenlijke verzameling van toegepaste instructies wil onze gids het berekenen van effectgroottes en betrouwbaarheidsintervallen toegankelijker maken. We hopen dat deze hulpmiddelen zowel jonge onderzoekers als ervaren wetenschappers in verschillende disciplines in staat stellen om deze cruciale statistische praktijken in hun werkproces op te nemen. Wij zijn van mening dat een meer wijdverspreide en doordachte toepassing van deze methoden de collectieve nauwkeurigheid, transparantie en impact van wetenschappelijk onderzoek enorm zal versterken.",
    "crumbs": [
      "**Conclusie**",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Conclusie</span>"
    ]
  },
  {
    "objectID": "Converting-to-Correlation.html#van-cohens-d",
    "href": "Converting-to-Correlation.html#van-cohens-d",
    "title": "16  Omzetten naar Pearson Correlation",
    "section": "16.2 Van Cohen’s \\(d\\)",
    "text": "16.2 Van Cohen’s \\(d\\)\nVan een Cohen’s \\(d\\) waarde tussen groepen (\\(d_p\\)) kunnen we de correlatiecoëfficiënt berekenen met de volgende formule:\n\\[\nr = \\frac{d_p}{\\sqrt{d_p^2+\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}\n\\]\nMet de d_to_r functie in het effectsize pakket kunnen we \\(d_p\\) naar \\(r\\) converteren.\n\n# Bijvoorbeeld:\n# d = 0.60, n1 = 50, n2 = 70\n\nd &lt;- 0.60\nn1 &lt;- 50\nn2 &lt;- 70\n\nd_to_r(d = d, n1 = n1, n2 = n2)\n\n[1] 0.2858532",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Omrekenen naar Correlaties</span>"
    ]
  },
  {
    "objectID": "Converting-to-Correlation.html#van-odds-ratio",
    "href": "Converting-to-Correlation.html#van-odds-ratio",
    "title": "16  Omzetten naar Pearson Correlation",
    "section": "16.3 Van Odds-Ratio",
    "text": "16.3 Van Odds-Ratio\nDe correlatiecoëfficiënt van een kansverhouding kan worden berekend met de volgende formule:\n\\[\nr = \\frac{\\log(OR)\\times\\sqrt{3}}{\\pi\\sqrt{\\frac{3\\log(OR)^2}{\\pi^2}+\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}\n\\]\nGebruik de oddsratio_to_r functie in het effectsize pakket om \\(OR\\) naar \\(r\\) te converteren.\n\n# Bijvoorbeeld:\n# OR = 2.21, n1 = 50, n2 = 70\n\nOR &lt;- 2.21\nn1 &lt;- 50\nn2 &lt;- 70\n\noddsratio_to_r(OR=OR, n1 = n1, n2 = n2)\n\n[1] 0.2124017",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Omrekenen naar Correlaties</span>"
    ]
  },
  {
    "objectID": "Converting-to-Odds-Ratio.html#van-een-pearson-correlatie",
    "href": "Converting-to-Odds-Ratio.html#van-een-pearson-correlatie",
    "title": "17  Converteren naar Odds Ratio",
    "section": "17.2 Van een Pearson Correlatie",
    "text": "17.2 Van een Pearson Correlatie\nWe kunnen een odds ratio uit een Pearson correlatie berekenen met de volgende formule:\n\\[\nOR = \\exp\\left(\\frac{r\\pi \\sqrt{\\frac{n_1+n_2-2}{n_1} + \\frac{n_1+n_2-2}{n_2}}}{\\sqrt{3(1-r^2)}}\\right)\n\\]\nAls de steekproefomvang gelijk is, kan deze vergelijking worden vereenvoudigd tot ongeveer,\n\\[\nOR = \\exp\\left(\\frac{r\\pi \\sqrt{4}}{\\sqrt{3(1-r^2)}}\\right)\n\\]\nGebruik de r_to_oddsratio functie in het effectsize pakket om \\(d\\) naar \\(OR\\) te converteren.\n\n# Bijvoorbeeld\n# r = .50, n1 = 50, n2 = 70\n\nr &lt;- .40\nn1 &lt;- 50\nn2 &lt;- 70\n\nr_to_oddsratio(r = r, n1 = n1, n2 = n2)\n\n[1] 4.870584",
    "crumbs": [
      "**Effect Sizes Omrekenen**",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Omrekenen naar Odds Ratios</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Gids voor Effect Sizes en Betrouwbaarheids Intervallen",
    "section": "",
    "text": "Welkom\nDeze gids voor samenwerking op het gebied van effect sizes en betrouwbaarheidsintervallen is bedoeld om academici, studenten en onderzoekers te voorzien van praktische, stapsgewijze instructies. Hij is er voor het berekenen van effect sizes en betrouwbaarheidsintervallen voor veelgebruikte statistische toetsen in de gedrags-, cognitieve en sociale wetenschappen, met name wanneer originele gegevens niet beschikbaar zijn en wanneer gerapporteerde informatie onvolledig is. De gids introduceert ook algemene achtergrondinformatie over effect sizes en betrouwbaarheidsintervallen, evenals nuttige R-pakketten voor de berekening ervan. Veel van de methoden en procedures die in deze gids worden beschreven, zijn gebaseerd op R of op R gebaseerde Shiny Apps die zijn ontwikkeld door de wetenschappelijke gemeenschap. We waren gemotiveerd om ons op R te richten omdat we de reproduceerbaarheid van onze onderzoeksresultaten willen maximaliseren en de meest reproduceerbare onderzoeksplanning en data-analyse workflow willen aanmoedigen, hoewel we waar mogelijk ook andere methoden documenteren ter referentie van onze lezers. We werken deze open educatieve bron regelmatig bij, omdat pakketten vaak worden bijgewerkt en er van tijd tot tijd nieuwe pakketten worden ontwikkeld in dit snel veranderende Open Scholarship-tijdperk.",
    "crumbs": [
      "Basis"
    ]
  },
  {
    "objectID": "Artifacts-and-Bias.html",
    "href": "Artifacts-and-Bias.html",
    "title": "14  Artefacten en vertekeningen in effectmaten",
    "section": "",
    "text": "14.1 Bronnen\nSchattingen van effectgroottes zoals correlatiecoëfficiënten en Cohen’s \\(d\\) waarden kunnen sterk vertekend zijn door verschillende statistische artefacten zoals meetfouten en selectie-effecten (bijv. bereikbeperking). Er zijn methoden ontwikkeld om te corrigeren voor de vertekening in effectgroottes en deze correcties worden “artefactcorrecties” genoemd. Formules voor artefactcorrectie kunnen complex zijn en daarom worden lezers verwezen naar andere bronnen die hieronder worden vermeld:",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Artifacten en Vertekeningen in Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Artifacts-and-Bias.html#bronnen",
    "href": "Artifacts-and-Bias.html#bronnen",
    "title": "14  Artefacten en vertekeningen in effectmaten",
    "section": "",
    "text": "Jané (2023) : Een open tekstboek dat vergelijkingen en R-code bevat voor verschillende soorten artefactcorrecties. Nog niet uitgebracht.\nHunter and Schmidt (1990) : Klassiek leerboek over artefactcorrecties. Hunter en Schmidt pionierden met de methodologie voor meta-analyses in de stijl van artefactcorrectie.\nWiernik and Dahlke (2020) : Een paper dat dient als een verkorte versie van het boek van Hunter en Schmidt. Het bevat de meeste vergelijkingen die nodig zijn om effectgroottes te corrigeren.\nDahlke and Wiernik (2019) : Een R-pakket voor het uitvoeren van meta-analyses met artefactcorrectie. Bevat alle functies die nodig zijn om effectgroottes te corrigeren voor artefacten in R.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Artifacten en Vertekeningen in Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Artifacts-and-Bias.html#corrigeren-voor-meetfouten",
    "href": "Artifacts-and-Bias.html#corrigeren-voor-meetfouten",
    "title": "14  Artefacten en vertekeningen in effectmaten",
    "section": "14.2 Corrigeren voor meetfouten",
    "text": "14.2 Corrigeren voor meetfouten\nAls we betrouwbaarheidsschattingen hebben van de variabelen die van belang zijn, kunnen we een Pearson correlatie of een gestandaardiseerd gemiddeld verschil (Cohen’s \\(d\\)) corrigeren voor meetfouten. Niet-differentiële meetfouten verzwakken Pearson correlaties en Cohen’s \\(d\\) daarom kunnen we correctiefactoren toepassen om voor deze vertekening te corrigeren. Voor een Pearson correlatie kunnen we de correctie voor verzwakking gebruiken die voor het eerst werd ontwikkeld door Spearman (1904),\n\\[\nr_c  = \\frac{r_\\text{obs}}{\\sqrt{r_{xx'}r_{yy'}}}\n\\tag{14.1}\\] waarbij \\(r_c\\) de gecorrigeerde correlatie is, \\(r_text{obs}\\) de waargenomen correlatie, \\(r_{xx'}\\) de betrouwbaarheid van \\(x\\) en \\(r_{yy'}\\) de betrouwbaarheid van \\(y\\). Betrouwbaarheidscoëfficiënten kunnen op een aantal verschillende manieren worden geschat, maar de twee meest gebruikte schatters zijn Cronbach Alpha en test-hertestbetrouwbaarheid. Alpha meet de interne consistentie van een set subcomponentmetingen (bijv. antwoorden op vragen in een vragenlijst) terwijl test-hertestbetrouwbaarheid de stabiliteit in de tijd meet.\nEen Cohen’s \\(d\\) kan op dezelfde manier worden gecorrigeerd als een correlatiecoëfficiënt, maar omdat het maar één continue variabele heeft, kunnen we gewoon corrigeren voor betrouwbaarheid in de continue variabele\n\\[\nd_c  = \\frac{d_\\text{obs}}{\\sqrt{r_{yy'}}}\n\\] In het geval van een Cohen’s d is het echter belangrijk dat \\(r_{yy'}\\) de gepoolde betrouwbaarheid binnen de groep is (bereken de gepoolde betrouwbaarheid op dezelfde manier als je de gepoolde standaardafwijking berekent voor de noemer van Cohen’s \\(d\\)). Als je alleen de betrouwbaarheid van de totale steekproef hebt (wat vaker wordt gerapporteerd), kun je dit proces in drie stappen volgen (Wiernik and Dahlke 2020),\n\nConverteer de d-waarde naar een punt-biseriële correlatie (zie het gedeelte over conversies)\n\nCorrigeer de punt-biseriële correlatie met Equation 14.1 (door \\(r_{xx'}=1\\) in te stellen)\n\nConverteer het terug naar een Cohen’s \\(d\\)\n\nMerk op dat betrouwbaarheidsintervallen voor \\(r_c\\) en \\(d_c\\) ook gecorrigeerd moeten worden. Een Pearson-correlatie zou bijvoorbeeld zo moeten worden gecorrigeerd dat, \\[\nCI_{r_c} = \\left[\\frac{r_\\text{lower-bound}}{\\sqrt{r_{xx'}r_{yy'}}},\\frac{r_\\text{upper-bound}}{\\sqrt{r_{xx'}r_{yy'}}}\\right]\n\\]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Artifacten en Vertekeningen in Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Artifacts-and-Bias.html#corrigeren-voor-bereikbeperking",
    "href": "Artifacts-and-Bias.html#corrigeren-voor-bereikbeperking",
    "title": "14  Artefacten en vertekeningen in effectmaten",
    "section": "14.3 Corrigeren voor bereikbeperking",
    "text": "14.3 Corrigeren voor bereikbeperking\nCorrecties voor bereikbeperking kunnen behoorlijk complex zijn, afhankelijk van het selectieproces. Het proces voor het corrigeren van Pearson correlaties en Cohen’s \\(d\\) voor bereikbeperking wordt beschreven in tabel 3 van Wiernik and Dahlke (2020).\n\n\n\n\nDahlke, Jeffrey A., and Brenton M. Wiernik. 2019. “psychmeta: An r Package for Psychometric Meta-Analysis.” Applied Psychological Measurement 43 (5): 415–16. https://doi.org/10.1177/0146621618795933.\n\n\nHunter, John E., and Frank L. Schmidt. 1990. Methods of meta-analysis: correcting error and bias in research findings. Newbury Park: Sage Publications.\n\n\nJané, Matthew B. 2023. Artifact Corrections for Effect Sizes: Implementation in r and Application to Meta-Analysis. (n.p.). https://matthewbjane.quarto.pub/artifact-corrections-for-effect-sizes/.\n\n\nSpearman, C. 1904. “The Proof and Measurement of Association Between Two Things.” International Journal of Epidemiology 39 (5): 1137–50. https://doi.org/10.1093/ije/dyq191.\n\n\nWiernik, Brenton M., and Jeffrey A. Dahlke. 2020. “Obtaining Unbiased Results in Meta-Analysis: The Importance of Correcting for Statistical Artifacts.” Advances in Methods and Practices in Psychological Science 3 (1): 94–123. https://doi.org/10.1177/2515245919885611.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Artifacten en Vertekeningen in Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Regression.html",
    "href": "Regression.html",
    "title": "13  Regressie",
    "section": "",
    "text": "13.1 Regressie Overzicht\nIn een enkelvoudige lineaire regressie is er slechts één voorspeller (\\(x\\)) en één uitkomst (\\(y\\)) in het regressiemodel,\n\\[\ny = b_0 + b_1 x + e\n\\]\nWe kunnen dit model visualiseren door gegevens uit het palmerpinguïn-datapakket te tonen:\nwaarbij \\(b_0\\) de interceptcoëfficiënt is, \\(b_1\\) de hellingscoëfficiënt en \\(e\\) de foutterm die normaal verdeeld is met een gemiddelde van nul en een variantie van \\(sigma^2\\). Voor een enkelvoudige lineaire regressie kunnen we een niet-gestandaardiseerde regressiecoëfficiënt verkrijgen door de optimale waarde van \\(b_0\\) en \\(b_1\\) te vinden die de variantie in \\(e\\), namelijk \\(\\sigma^2\\), minimaliseert. In een meervoudige regressie kunnen we \\(y\\) modelleren als een functie van meerdere voorspellende variabelen zodat,\n\\[\ny = b_0 + b_1 x_{1} + b_2 x_{2} +... + e\n\\] Waarbij de coëfficiënten allemaal samen worden geoptimaliseerd om de foutvariantie te minimaliseren. De lijn van de regressievergelijking is onze voorspelde waarde van \\(y_i\\), maar kan ook worden geïnterpreteerd als het gemiddelde van \\(y\\) gegeven een bepaalde waarde van \\(x\\). In een regressievergelijking kunnen we complexere modellen maken met niet-lineaire termen zoals interacties of polynomen (of eender welke functie van \\(x\\)). We kunnen bijvoorbeeld een model maken met een hoofdeffect, \\(x_1\\), een kwadratische polynomiale term, \\(x^2_1\\) en een interactieterm, \\(x_1 x_2\\),\n\\[\ny_i = b_0 + b_1 x_{1} + b_2 x^2_{2}  + b_2 x_{1} x_{2} + e_i\n\\]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Regression.html#effect-sizes-voor-een-lineaire-regressie",
    "href": "Regression.html#effect-sizes-voor-een-lineaire-regressie",
    "title": "13  Regressie",
    "section": "13.2 Effect Sizes voor een Lineaire Regressie",
    "text": "13.2 Effect Sizes voor een Lineaire Regressie\nAls we de variantie in de uitkomst willen berekenen die door alle voorspellende variabelen wordt verklaard, kunnen we een \\(R^2\\)-waarde berekenen. De \\(R^2\\)-waarde kan op twee manieren worden geïnterpreteerd:\n\nde variantie in \\(y\\) verklaard door de voorspellende variabelen\n\nhet kwadraat van de correlatie tussen voorspelde \\(y\\) waarden en waargenomen (werkelijke) \\(y\\) waarden.\n\nOp dezelfde manier kunnen we ook de vierkantswortel van \\(R^2\\) nemen om de correlatie tussen voorspelde en waargenomen \\(y\\) waarden te krijgen. We kunnen vrij eenvoudig een lineair regressiemodel construeren in basis-R met de functie lm(). We zullen de palmerpenguins dataset gebruiken voor ons voorbeeld.\n\nlibrary(palmerpenguins)\n\n\nmdl &lt;- lm(bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n          data = penguins)\n\nsummary(mdl)\n\n\nCall:\nlm(formula = bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n    data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.8831  -2.7734  -0.3268   2.3128  19.7630 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -28.14701    5.51435  -5.104 5.54e-07 ***\nflipper_length_mm   0.30569    0.01902  16.073  &lt; 2e-16 ***\nbill_depth_mm       0.62103    0.13543   4.586 6.38e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.009 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4638,    Adjusted R-squared:  0.4607 \nF-statistic: 146.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nWe zullen zien dat het lineaire regressieoverzicht twee \\(R^2\\) waarden geeft. De eerste is de traditionele \\(R^2\\) en de andere is de aangepaste \\(R^2\\). De aangepaste \\(R^2_text{adj}\\) past een correctiefactor toe omdat \\(R^2\\) vaak een vertekend beeld geeft als er meer voorspellende variabelen en een kleinere steekproefomvang zijn. Als we de bijdrage van elke term in het regressiemodel willen weten, kunnen we ook semi-partiële \\(sr^2\\) waarden gebruiken die vergelijkbaar zijn met partiële eta kwadraten in het ANOVA gedeelte van dit boek. In R kunnen we \\(sr^2\\) berekenen met de functie r2_semipartial() in het pakket effectsize (Ben-Shachar, Lüdecke, and Makowski 2020):\n\nlibrary(effectsize)\n\nr2_semipartial(mdl,alternative = \"two.sided\")\n\nTerm              |  sr2 |       95% CI\n---------------------------------------\nflipper_length_mm | 0.41 | [0.33, 0.49]\nbill_depth_mm     | 0.03 | [0.01, 0.06]\n\n\nEen gestandaardiseerde effectgrootte voor elke term kan ook worden berekend door de regressiecoëfficiënten te standaardiseren. Gestandaardiseerde regressiecoëfficiënten worden berekend door de schaal van de voorspellende en de uitkomstvariabelen te veranderen in z-scores (d.w.z. het gemiddelde en de variantie op respectievelijk nul en één te zetten).\n\nstand_mdl &lt;- lm(scale(bill_length_mm) ~ scale(flipper_length_mm) + scale(bill_depth_mm), \n                data = penguins)\n\nsummary(stand_mdl)\n\n\nCall:\nlm(formula = scale(bill_length_mm) ~ scale(flipper_length_mm) + \n    scale(bill_depth_mm), data = penguins)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9934 -0.5080 -0.0599  0.4236  3.6199 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              2.898e-16  3.971e-02   0.000        1    \nscale(flipper_length_mm) 7.873e-01  4.899e-02  16.073  &lt; 2e-16 ***\nscale(bill_depth_mm)     2.246e-01  4.899e-02   4.586 6.38e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7344 on 339 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4638,    Adjusted R-squared:  0.4607 \nF-statistic: 146.6 on 2 and 339 DF,  p-value: &lt; 2.2e-16\n\n\nAls alternatief kunnen we de standardise functie gebruiken in het effectsize pakket:\n\nstandardise(mdl)\n\n\nCall:\nlm(formula = bill_length_mm ~ flipper_length_mm + bill_depth_mm, \n    data = data_std)\n\nCoefficients:\n      (Intercept)  flipper_length_mm      bill_depth_mm  \n        2.898e-16          7.873e-01          2.246e-01",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Regression.html#pearson-correlatie-vs-regressiecoëfficiënten-in-eenvoudige-lineaire-regressies",
    "href": "Regression.html#pearson-correlatie-vs-regressiecoëfficiënten-in-eenvoudige-lineaire-regressies",
    "title": "13  Regressie",
    "section": "13.3 Pearson correlatie vs regressiecoëfficiënten in eenvoudige lineaire regressies",
    "text": "13.3 Pearson correlatie vs regressiecoëfficiënten in eenvoudige lineaire regressies\nEen hellingscoëfficiënt in een enkelvoudig lineair regressiemodel kan worden gedefinieerd als de covariantie tussen voorspeller \\(x\\) en uitkomst \\(y\\) gedeeld door de variantie in \\(x\\),\n\\[\nb_1 = \\frac{\\text{Cov}(x,y)}{S_x^2}\n\\]\nWaarbij \\(S_x\\) de standaardafwijking van \\(x\\) is (het kwadraat van de standaardafwijking is de variantie). Een Pearson correlatie is gedefinieerd als,\n\\[\nr = \\frac{\\text{Cov}(x,y)}{S_xS_y}\n\\]\nWe zien dat deze formules erg op elkaar lijken, in feite kunnen we \\(r\\) uitdrukken als een functie van \\(b_1\\) zodat,\n\\[\nr = b_1 \\frac{S_x}{S_y}\n\\]\nDat betekent dat als \\(S_x=S_y\\) dan is \\(r = b_1\\). Bovendien, als de regressiecoëfficiënt gestandaardiseerd is, zouden de uitkomst- en voorspellingsvariabele beide een variantie van 1 hebben, waardoor \\(S_x=S_y = 1\\). Daarom is een gestandaardiseerde regressiecoëfficiënt gelijk aan een Pearson correlatie.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Regression.html#multi-level-regressie-modellen",
    "href": "Regression.html#multi-level-regressie-modellen",
    "title": "13  Regressie",
    "section": "13.4 Multi-Level Regressie modellen",
    "text": "13.4 Multi-Level Regressie modellen\nWe kunnen de regressiecoëfficiënten zoals het intercept en de helling willekeurig laten variëren met betrekking tot een of andere groeperingsvariabele. Stel bijvoorbeeld dat we denken dat het intercept zal variëren tussen de verschillende soorten pinguïns als we kijken naar de relatie tussen lichaamsmassa en snavellengte. Met behulp van het lme4 pakket in R kunnen we een model construeren dat de interceptcoëfficiënt laat variëren tussen soorten.\n\nlibrary(palmerpenguins)\nlibrary(lme4)\n\n\nml_mdl &lt;- lmer(bill_length_mm ~ 1 + flipper_length_mm + (1 | species),\n            data = penguins)\nsummary(ml_mdl)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: bill_length_mm ~ 1 + flipper_length_mm + (1 | species)\n   Data: penguins\n\nREML criterion at convergence: 1640.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.5568 -0.6666  0.0109  0.7020  4.7678 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n species  (Intercept) 20.06    4.479   \n Residual              6.74    2.596   \nNumber of obs: 342, groups:  species, 3\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)        1.81165    4.97514   0.364\nflipper_length_mm  0.21507    0.02113  10.177\n\nCorrelation of Fixed Effects:\n            (Intr)\nflppr_lngt_ -0.854\n\n\nMerk op dat we in de tabel willekeurige effecten en vaste effecten hebben. De willekeurige effecten tonen de groeperende (categorische) variabele waarop de parameter mag variëren en vervolgens de parameter die varieert, wat in ons geval de interceptcoëfficiënt is. Het bevat ook de variantie van het intercept, dat is de mate waarin het intercept varieert tussen soorten. Voor de termen met een vast effect zien we het intercept weergegeven evenals de helling, dit toont het gemiddelde van het intercept over de soorten heen en omdat de helling gelijk is over de soorten heen, is de helling slechts een enkele waarde. Laten we eens visualiseren hoe dit model eruit ziet:\n\n\n\n\n\n\n\n\n\nMerk op dat in de bovenstaande grafiek de hellingen vastliggen en gelijk zijn voor elke soort en dat alleen de intercepts (d.w.z. de verticale hoogte van elke lijn) verschillen. We kunnen de helling ook laten variëren als we dat willen door de formule aan te passen:\n\nlibrary(palmerpenguins)\nlibrary(lme4)\n\n\nml_mdl &lt;- lmer(bill_length_mm ~ 1 + flipper_length_mm + (1 + flipper_length_mm | species),\n            data = penguins)\nsummary(ml_mdl)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: bill_length_mm ~ 1 + flipper_length_mm + (1 + flipper_length_mm |  \n    species)\n   Data: penguins\n\nREML criterion at convergence: 1638.2\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.6326 -0.6657  0.0083  0.6843  4.9531 \n\nRandom effects:\n Groups   Name              Variance  Std.Dev. Corr \n species  (Intercept)       3.0062118 1.73384       \n          flipper_length_mm 0.0007402 0.02721  -0.61\n Residual                   6.6886861 2.58625       \nNumber of obs: 342, groups:  species, 3\n\nFixed effects:\n                  Estimate Std. Error t value\n(Intercept)        1.56035    4.32870   0.360\nflipper_length_mm  0.21609    0.02623   8.237\n\nCorrelation of Fixed Effects:\n            (Intr)\nflppr_lngt_ -0.863\noptimizer (nloptwrap) convergence code: 0 (OK)\nunable to evaluate scaled gradient\nModel failed to converge: degenerate  Hessian with 1 negative eigenvalues\n\n\nDoor de helling te variëren wordt flipper_length_mm opgenomen in de random effect termen. Merk ook op dat de samenvatting de correlatie tussen de random effect termen weergeeft, wat nuttig kan zijn om te weten of er een sterke relatie is tussen het intercept en de helling bij verschillende soorten. Nu zien we dat de random effect termen nu de hellingscoëfficiënt bevatten die overeenkomt met de flipper_length_mm voorspellingsvariabele. Laten we het volgende visualiseren\n\n\n\n\n\n\n\n\n\nDe plot hierboven toont een lichte variatie in de helling tussen de drie soorten, maar de helling varieert niet zo veel. Voor modellen met meerdere niveaus kunnen we een voorwaardelijke \\(R^2\\) en een marginale \\(R^2\\) berekenen die elk hieronder worden beschreven\n\nMarginale \\(R^2\\): de variantie die alleen door de vaste effecten wordt verklaard.\nVoorwaardelijke \\(R^2\\): de variantie die wordt verklaard in het hele model, inclusief de termen voor zowel vaste effecten als willekeurige effecten.\n\nIn R kunnen we het pakket MuMIn (Bartoń 2023) gebruiken om zowel de marginale als de voorwaardelijke \\(R^2\\) te berekenen:\n\nlibrary(MuMIn)\n\nr.squaredGLMM(ml_mdl)\n\n           R2m       R2c\n[1,] 0.2470201 0.8210591\n\n\n\n\n\n\nBartoń, Kamil. 2023. MuMIn: Multi-Model Inference. https://CRAN.R-project.org/package=MuMIn.\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Regressie</span>"
    ]
  },
  {
    "objectID": "Non-Parametric-Effect-Sizes.html",
    "href": "Non-Parametric-Effect-Sizes.html",
    "title": "12  Non-Parametric Tests",
    "section": "",
    "text": "Here is a table for every effect size discussed in this chapter:",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Non-Parametrische Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Differences-in-Variance.html",
    "href": "Differences-in-Variance.html",
    "title": "11  Differences in Variability",
    "section": "",
    "text": "Here is a table for every effect size discussed in this chapter:",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Verschillen in Variabiliteit</span>"
    ]
  },
  {
    "objectID": "Categorical-Proportional-Data.html",
    "href": "Categorical-Proportional-Data.html",
    "title": "9  Effect Sizes voor Categoriale Variabelen",
    "section": "",
    "text": "Hier is een tabel voor elke effect size besproken in dit hoofdstuk:",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Categoriale/Proportionele Data</span>"
    ]
  },
  {
    "objectID": "Reporting-Effect-Sizes.html",
    "href": "Reporting-Effect-Sizes.html",
    "title": "3  Rapporteren van Effect Sizes",
    "section": "",
    "text": "3.1 Transparantie\nWanneer u effectgroottes en hun berekeningen rapporteert, moet u prioriteit geven aan transparantie en reproduceerbaarheid. Welke tool u ook gebruikt om uw effectgrootte te berekenen (R wordt hier het meest aanbevolen), u moet ervoor zorgen dat anderen gemakkelijk uw procedures kunnen volgen en dezelfde resultaten kunnen verkrijgen. Dit betekent dat als je online calculators gebruikt (wat wordt afgeraden) of standalone programma’s (JAMOVI wordt het meest aanbevolen; je kunt ook JASP gebruiken, dat op dit moment echter geen toegang geeft tot syntax), je screenshots moet toevoegen die de invoer en uitvoer vastleggen, met duidelijke uitleg. Als je R, Python of andere programmeertalen gebruikt, moet je je codes kopiëren en plakken in je aanvullend document (of je scripts indienen bij open online repositories), idealiter met annotaties en commentaar waarin de codes worden uitgelegd. inputs en outputs.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Rapporteren van Effect Sizes</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html",
    "href": "Effect-Sizes-for-ANOVAs.html",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "",
    "text": "10.1 ANOVAs\nVoor ANOVA’s/F-tests moet je altijd twee soorten effecten rapporteren: het omnibuseffect van de factor(en) en het effect van geplande contrasten of post-hocvergelijkingen.\nStel je bijvoorbeeld voor dat je drie groepen/condities vergelijkt met een eenzijdige ANOVA. De ANOVA zal eerst een F-statistiek, de vrijheidsgraden en de bijbehorende p-waarde opleveren. Hier moet u de grootte van dit omnibusfactoreffect berekenen in eta-kwadraat, partiële eta-kwadraat of gegeneraliseerde eta-kwadraat.\nStel dat het omnibuseffect significant is. U weet nu dat er ten minste één groep verschilt van de anderen. Je wilt weten welke groep(en) verschilt (verschillen) van de anderen en hoeveel ze verschilt (verschillen). Daarom voer je post hoc vergelijkingen uit op deze groepen. Omdat post hoc vergelijkingen elke groep paarsgewijs vergelijken met de anderen, krijg je een t-statistiek en p-waarde voor elke vergelijking. Hiervoor kun je een gestandaardiseerd gemiddeld verschil berekenen en rapporteren.\nStel je voor dat je twee onafhankelijke variabelen of factoren hebt en je voert een twee-bij-twee factorial ANOVA uit. Het eerste wat je dan doet, is kijken naar de interactie. Als de interactie significant is, rapporteer je opnieuw de bijbehorende omnibus effectgrootte maten, en ga je verder met het analyseren van de enkelvoudige effecten. Afhankelijk van je onderzoeksvraag vergelijk je de niveaus van de ene IV op elk niveau van de andere IV. U rapporteert d of g voor deze enkelvoudige effecten. Als de interactie niet significant is, kijkt u naar de hoofdeffecten en rapporteert u het bijbehorende omnibuseffect. Vervolgens analyseert u het hoofdeffect door de niveaus van één IV te vergelijken terwijl u de niveaus van de andere IV samenvoegt/aggregeert. U rapporteert d of g voor deze paarsgewijze vergelijkingen. Merk op dat effecten van lagere orde niet direct interpreteerbaar zijn als effecten van hogere orde significant zijn. Als je een significante interactie hebt in een tweezijdige ANOVA, kun je de hoofdeffecten niet direct interpreteren. Als u een significante drieweginteractie hebt in een drieweg ANOVA, kunt u de hoofdeffecten of de tweerichtingsinteracties niet rechtstreeks interpreteren, ongeacht of ze significant zijn of niet.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Categorical-Proportional-Data.html#verhoudingstest-met-één-steekproef",
    "href": "Categorical-Proportional-Data.html#verhoudingstest-met-één-steekproef",
    "title": "9  Effect Sizes voor Categoriale Variabelen",
    "section": "9.1 Verhoudingstest met één steekproef",
    "text": "9.1 Verhoudingstest met één steekproef\nAls we een enkele steekproef hebben en we willen het verschil bepalen tussen een proportie en een interessante proportie. We kunnen eerst de teststatistiek berekenen door de geobserveerde proportie (\\(p\\)) te vergelijken met de proportie van belang (\\(p_0\\)):\n\\[\nz = \\frac{p-p_0}{\\sqrt{\\frac{p(1-p)}{n}}},\n\\] waarbij \\(n\\) de steekproefgrootte is. Merk op dat dit alleen geldig is als de proportie van belang toeval is (\\(p_0=.50\\)) omdat de steekproefverdeling met een proportie van .50 normaal is. Maar als de proportie die van belang is niet .50 is, dan moeten we in plaats daarvan Cohen’s \\(h\\) berekenen (zie Section 9.2.3 voor details), die de schaal transformeert zodat de verdelingen normaal zijn ongeacht de proportie. De test-statistiek met Cohen’s \\(h\\),\n\\[\nz = h\\sqrt{n}\n\\]\nLaten we proberen de verhouding te testen tegen toeval (\\(p_0=.50\\)) in R. We kunnen dan de p-waarde in basis-R berekenen met de functie pnorm():\n\n# Bv:\np &lt;- .7 # geobserveerde proportie\np0 &lt;- .5 # proportie waarin geïnteresseerd \nn &lt;- 50 # steekproef omvang\n\nz &lt;- (p-p0) / sqrt(p*(1-p)/n)\n\npval &lt;- 2*(1-pnorm(z)) # twee koppige test\n\ndata.frame(z,pval)\n\n         z        pval\n1 3.086067 0.002028231\n\n\nResultaten tonen een significant verschil met toeval met \\(z\\) = 3.09 en p-val = .002",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Categoriale/Proportionele Data</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#eenzijdige-anova-tussen-proefpersonen",
    "href": "Effect-Sizes-for-ANOVAs.html#eenzijdige-anova-tussen-proefpersonen",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.3 Eenzijdige ANOVA tussen proefpersonen",
    "text": "10.3 Eenzijdige ANOVA tussen proefpersonen\nANOVA is een uitbreiding van onafhankelijke t-tests. De nulhypothese is dat alle k gemiddelden van k onafhankelijke groepen identiek zijn, terwijl de alternatieve hypothese is dat er minstens twee gemiddelden van deze k groepen verschillen. De aannames zijn onder andere: (1) onafhankelijkheid van waarnemingen, (2) normaliteit van residuen, en (3) gelijkheid (of homogeniteit) van varianties (homoscedasticiteit).1\nOpmerking. Soms kun je een between-subject one-way ANOVA tegenkomen die slechts twee condities vergelijkt, vooral als het papier oud is. Dit is in wezen een t-toets en de F-statistiek is gewoon t-kwadraat. Het verdient de voorkeur om Cohen’s d voor deze tests te rapporteren. Als je de effectgrootte voor dergelijke tests berekent, kun je het beste Cohen’s d berekenen, of de verstrekte eta-kwadraat omrekenen naar Cohen’s d, omdat Cohen’s d de richting van het effect kan laten zien. Latere analyses (bijv. poweranalyse) kunnen ook worden gebaseerd op Cohen’s d.\nHet is heel eenvoudig om eta-kwadraat te bepalen met een F-statistiek en de twee vrijheidsgraden van een eenzijdige ANOVA 2. Merk op dat in het geval van een eenzijdige ANOVA, eta-kwadraat gelijk is aan partiële eta-kwadraat.\n\n10.3.1 Vrijheidsgraden vaststellen\nRaadpleeg de volgende tabel om de vrijheidsgraden voor ANOVA-effecten te bepalen, als ze niet zijn gerapporteerd of als je twijfelt of ze verkeerd zijn gerapporteerd.\n\n\n\nVrijheidsgraden\n\n\n\n\n\nTussen subjecten ANOVA\n\n\n\nEffect\n\\(k-1\\)\n\n\nFout\n\\(n-k\\)\n\n\nTotaal\n\\(n-1\\)\n\n\n\n\n\n10.3.2 Berekening van eta-kwadraat uit F-statistiek en vrijheidsgraden\nMet de onderstaande formule kunnen we \\(eta^2\\) van een ANOVA-model berekenen met behulp van de F-statistiek en de vrijheidsgraden,\n\\[\n\\eta^2 = \\frac{df_\\text{effect}\\times F}{df_\\text{effect} \\times F + df_\\text{fout}}.\n\\]\nIn R kunnen we de F_to_eta2() functie uit het effectsize pakket gebruiken (Ben-Shachar, Lüdecke, and Makowski 2020):\n\nlibrary(effectsize)\n\nn = 154 # aantal subjecten\nk = 3 # aantal groepen\nf = 84.3 # F-statistiek\n\ndf_effect = k - 1\ndf_error = n - k\n\nF_to_eta2(f = f,\n          df = df_effect,\n          df_error = df_error,\n          alternative = 'two.sided') # verkrijgen van tweezijdig CIs\n\nEta2 (partial) |       95% CI\n-----------------------------\n0.53           | [0.42, 0.61]\n\n\n\n\n10.3.3 Het berekenen van het kwadraat van een ANOVA-tabel\nLaten we de tabel van het ANOVA-model in Section 10.2 gebruiken::\n\nEenzijdige ANOVA-tabel\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nspecies\n2\n146864214\n73432107.1\n343.6263\n0\n\n\nResiduals\n339\n72443483\n213697.6\nNA\nNA\n\n\n\nUit deze tabel kunnen we de som van de kwadraten van de groepsvariabele (soorten) en de totale som van de kwadraten (\\(SS_\\text{totaal} = SS_\\text{effect} + SS_\\text{fout}\\)) gebruiken om de waarde van \\(eta^2\\) te berekenen met de volgende vergelijking:\n\\[\n\\eta^2 = \\frac{SS_\\text{effect}}{SS_\\text{totaal}} = \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{fout}}\n\\]\nIn R kunnen we de eta.full.SS() functie uit het MOTE pakket (Buchanan et al. 2019) gebruiken om \\(\\eta^2\\) uit een ANOVA tabel te verkrijgen.\n\nlibrary(MOTE)\n\neta &lt;- eta.full.SS(dfm = 2,  # effect vrijheidsgraden\n                   dfe = 339, # fout vrijheidsgraden\n                   ssm = 146864214, # `sum of squares` voor het effect\n                   sst = 146864214 + 72443483, # totaal `sum of squares`\n                   Fvalue = 343.6263,\n                   a = .05)\n\ndata.frame(eta_squared = apa(eta$eta),\n           etalow = apa(eta$etalow),\n           etahigh = apa(eta$etahigh))\n\n  eta_squared etalow etahigh\n1       0.670  0.606   0.722\n\n\nDe voorbeeldcode geeft \\(\\eta^2\\) = .67 [.61, .72]. Dit suggereert dat de soort verantwoordelijk is voor 67% van de totale variatie in lichaamsmassa tussen pinguïns.\n\n\n10.3.4 Cohen’s d berekenen voor post-hocvergelijkingen\nIn een omnibus ANOVA vertelt de p-waarde ons of de gemiddelden van alle groepen uit hetzelfde populatiegemiddelde komen, maar dit informeert ons niet over welke groepen verschillen en met hoeveel. Met hetzelfde voorbeeld als hiervoor, stellen we dat we een specifieke vraag willen beantwoorden zoals: wat is het verschil in lichaamsmassa tussen adéliepinguïns en ezelspinguïns? Om deze vraag te beantwoorden, kunnen we het ruwe gemiddelde verschil tussen de twee groepen berekenen. In R kunnen we dat doen met de volgende code:\n\nMadelie &lt;- mean(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nMgentoo &lt;- mean(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\n\nMgentoo - Madelie\n\n[1] 1375.354\n\n\nGebaseerd op het gemiddelde verschil, zijn ezelspinguïns gemiddeld 1375 gram zwaarder dan Adelia pinguïns in totale lichaamsmassa. We kunnen ook een gestandaardiseerd gemiddeld verschil berekenen met de escalc() functie in het metafor pakket (Viechtbauer 2010).\n\nlibrary(metafor)\n\n# Gemiddelden, SDs en steekproefomvang voor elke groep\nMadelie &lt;- mean(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nMgentoo &lt;- mean(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\nSDadelie &lt;- sd(penguins$body_mass_g[penguins$species=='Adelie'], na.rm=T)\nSDgentoo &lt;- sd(penguins$body_mass_g[penguins$species=='Gentoo'], na.rm=T)\nNadelie &lt;- sum(penguins$species=='Adelie', na.rm=T)\nNgentoo &lt;- sum(penguins$species=='Gentoo', na.rm=T)\n\nsummary(\n  escalc(measure = 'SMD',\n         m1i = Mgentoo,\n         m2i = Madelie,\n         sd1i = SDgentoo,\n         sd2i = SDadelie,\n         n1i = Ngentoo,\n         n2i = Nadelie)\n)\n\n\n      yi     vi    sei      zi   pval  ci.lb  ci.ub \n1 2.8602 0.0295 0.1716 16.6629 &lt;.0001 2.5237 3.1966 \n\n\nHet gestandaardiseerde gemiddelde verschil tussen Adélie- en Ezelspinguïns is \\(d\\) = 2,86 [2,52, 3,19], wat aantoont dat Ezelspinguïns een lichaamsmassa hebben die 2,86 standaarddeviaties groter is dan die van Ezelspinguïns.\nWe kunnen ook contrasten kwantificeren op basis van samenvattende statistieken uit de ANOVA-tabel en de gemiddelden binnen de groep. We kunnen het gestandaardiseerde gemiddelde verschil berekenen met de gemiddelden van beide groepen en de gemiddelde gekwadrateerde fout (\\(MSE\\)) met de volgende vergelijking:\n\\[\nd = \\frac{M_1 - M_2}{\\sqrt{MSE}}\n\\]\nDeze methode geeft een gestandaardiseerd gemiddeld verschil dat gelijk is aan de Cohen’s \\(d\\) met de gepoolde standaardafwijking in de noemer (zie hoofdstuk over gemiddelde verschillen). Als we dus de gemiddelde gekwadrateerde fouten (d.w.z. MS van residuen) uit ?sec-eta-tabel halen en de gemiddelden verkrijgen (gemiddelden: Gentoo = 5076, Adelie = 3701), kunnen we het gestandaardiseerde gemiddelde verschil als volgt berekenen: \\(frac{5076 - 3701}{sqrt{213697.6}} = \\frac{1375}{462.27 }}. = 2.974\\). De discrepantie tussen het gestandaardiseerde gemiddelde verschil dat de functie escalc() geeft, komt doordat de functie automatisch een kleine steekproefcorrectiefactor toepast, waardoor het totale effect kleiner wordt.\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nspecies\n2\n146864214\n73432107.1\n343.6263\n0\n\n\nResiduals\n339\n72443483\n213697.6\nNA\nNA\n\n\n\n\n\n\n\n\n\nPas op voor de aannames.\n\n\n\nMerk op dat deze methode ALLEEN geldig is als je bereid bent om uit te gaan van gelijke varianties tussen groepen (homoscedasticiteit) en als je een Fisher’s one-way ANOVA uitvoert (in plaats van Welch’s). Deze methode is ook onpraktisch als je rekent met gerapporteerde statistieken en de MSE niet gerapporteerd wordt (wat meestal het geval is).\nAls je niet wilt uitgaan van homogeniteit van varianties, bereken dan Cohen’s d tussen groepen alsof er maar twee groepen zijn om te vergelijken. Je moet echter weten dat het ook weinig zin heeft om een Fisher’s ANOVA uit te voeren in zulke situaties. Je kunt beter overstappen op Welch’s ANOVA, die niet uitgaat van homoscedasticiteit. Als varianties sterk verschillen, kun je alternatieve gestandaardiseerde effectgroottematen gebruiken, zoals Glass’ delta, en betrouwbaarheidsintervallen berekenen met bootstrap.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#een-weg-herhaalde-metingen-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#een-weg-herhaalde-metingen-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.4 Een-weg herhaalde metingen ANOVA",
    "text": "10.4 Een-weg herhaalde metingen ANOVA\nEen-weg herhaalde metingen (One-way repeated measures ANOVA, rmANOVA) is een uitbreiding van t-tests met gepaarde steekproeven, met het verschil dat het kan worden gebruikt in twee of meer groepen.\n\n10.4.1 Vrijheidsgraden bepalen\nRaadpleeg de volgende tabel om de vrijheidsgraden voor ANOVA-effecten met herhaalde meting te bepalen.\n\n\n\nVrijheidsgraden\n\n\n\n\n\nTussen-subject ANOVA (herhaalde metingen)\n\n\n\nEffect\n\\(k-1\\)\n\n\nFout-tussen\n\\((n-1)\\times(k-1)\\)\n\n\nFout-binnen\n\\((n-1)\\cdot (k-1)\\)\n\n\nTotaal (binnen)\n\\(n\\cdot (k-1)\\)\n\n\n\n\n\n10.4.2 Eta-kwadraat van rmANOVA-statistieken\nGewoonlijk gebruiken we eta kwadraat (\\(\\eta^2\\)) of partiële eta kwadraat (\\(\\eta_p^2\\)) als maat voor de effectgrootte voor eenrichtings rmANOVA’s, waarvoor deze twee in feite gelijk zijn. Laten we een rmANOVA-model construeren met voorbeeldgegevens uit het pakket datarium (Kassambara 2019). De zelfwaardering/selfesteem dataset toont eenvoudig zelfwaarderingsscores over drie herhaalde metingen bij dezelfde proefpersonen.\n\n### laad in en herschik data\nlibrary(tidyr)\ndata(\"selfesteem\", package = \"datarium\")\nselfesteem &lt;- tidyr::pivot_longer(selfesteem,cols = c(\"t1\",\"t2\",\"t3\"))\ncolnames(selfesteem) &lt;- c(\"subject\",\"time\",\"self_esteem\")\n####\n\nrmANOVA_mdl = aov(formula = self_esteem ~ time + Error(subject),\n                  data = selfesteem)\nsummary(rmANOVA_mdl)\n\n\nError: subject\n          Df  Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals  1 0.07667 0.07667               \n\nError: Within\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntime       2 102.46   51.23   63.07 1.06e-10 ***\nResiduals 26  21.12    0.81                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\nEr worden hier twee tabellen weergegeven: de bovenste tabel geeft de effecten tussen de proefpersonen weer en de tabel eronder de effecten binnen de proefpersonen. De vergelijkingen en functies om \\(eta^2\\) te berekenen die in het hoofdstuk over ANOVA’s tussen de proefpersonen zijn genoemd, zijn hier ook van toepassing:\n\\[\n\\eta^2 = \\frac{df_\\text{effect}\\times F}{df_\\text{effect} \\times F + df_\\text{fout-within}},\n\\]\n\\[\n\\eta^2 = \\frac{SS_\\text{effect}}{SS_\\text{totaal}}\n\\]\nMerk op dat \\(SS_text{totaal}\\) hier geen \\(SS_text{fout-tussen}\\) bevat omdat we er niet in geïnteresseerd zijn door een rmANOVA uit te voeren. Deze analyse richt zich op een effect dat volgens ons bij elke proefpersoon zou moeten optreden, ongeacht hoe deze proefpersonen van elkaar verschillen. Met andere woorden, de variantie tussen de proefpersonen kan groot of klein zijn, maar we geven er niet om als we onderzoeken of er een effect is of niet over herhaalde metingen heen. Daarom kan de totale som van de kwadraten worden gedefinieerd als\n\\[\nSS_\\text{totaal} = SS_\\text{effect} + SS_\\text{fout-within}\n\\]\nDaarom kunnen we \\(\\eta^2\\) berekenen van de rmANOVA tabel als,\n\\[\n\\eta^2 = \\frac{102.46}{21.12 + 102.46} = .83\n\\]\nWe kunnen het rmANOVA model in de eta_squared() functie van het effectsize pakket in R (Ben-Shachar, Lüdecke, and Makowski 2020) stoppen om \\(eta^2\\) te berekenen.\n\nlibrary(effectsize)\n\neta_squared(rmANOVA_mdl,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nGroup  | Parameter | Eta2 (partial) |       95% CI\n--------------------------------------------------\nWithin |      time |           0.83 | [0.69, 0.89]\n\n\nZoals verwacht vinden we dezelfde puntschatting van onze handberekening. Om \\(\\eta^2\\) te berekenen uit de F-statistiek en vrijheidsgraden kunnen we het MOTE pakket (Buchanan et al. 2019) gebruiken zoals we deden in Section 10.3.3\n\nlibrary(MOTE)\n\neta &lt;- eta.full.SS(dfm = 2,  # effect vrijheidsgraden\n                   dfe = 26, # fout vrijheidsgraaden\n                   ssm = 102.46, # sum of squares voor het effect\n                   sst = 102.46 + 21.12, # totale sum of squares\n                   Fvalue = 63.07,\n                   a = .05)\n\ndata.frame(eta_squared = apa(eta$eta),\n           etalow = apa(eta$etalow),\n           etahigh = apa(eta$etahigh))\n\n  eta_squared etalow etahigh\n1       0.829  0.644   0.910\n\n\nLet op de discrepantie tussen betrouwbaarheidsintervallen die worden geretourneerd door MOTE en effectsize. Dit komt door verschillen in de berekening.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#twee-weg-tussen-subjecten-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#twee-weg-tussen-subjecten-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.5 Twee-weg tussen-subjecten ANOVA",
    "text": "10.5 Twee-weg tussen-subjecten ANOVA\nTwee-weg tussen-subjecten ANOVA wordt gebruikt als er twee voorspellende groepsvariabelen in het model zitten. Merk opnieuw op dat tussen proefpersonen betekent dat elke groep verschillende proefpersonen bevat.\n\n10.5.1 Vrijheidsgraden vaststellen\nRaadpleeg de volgende tabel om de vrijheidsgraden te bepalen voor tweezijdige ANOVA-effecten (Morse 2018). Merk op dat \\(k_1\\) het aantal groepen in de eerste variabele is en \\(k_2\\) het aantal groepen in de tweede variabele.\n\n\n\nVrijheidsgraden\n\n\n\n\n\nTussen subjecten ANOVA\n\n\n\nHoofd Effect (van éé variabele)\n\\(k_1-1\\) of \\(k_2-1\\)\n\n\nInteractie Effect\n\\((k_1-1)\\times (k_2-1)\\)\n\n\nFout\n\\(n-k_1\\cdot k_2\\)\n\n\nTotaal\n\\(n-1\\)\n\n\n\n\n\n10.5.2 Eta-kwadraat van twee-weg ANOVA-statistieken\nVoor tweezijdige ANOVA’s kunnen we \\(\\eta^2_p\\) krijgen voor elke voorspeller in het model. Laten we ons ANOVA-model construeren met gegevens uit de palmerpenguins dataset (Horst, Hill, and Gorman 2020). In dit voorbeeld willen we zien hoe de soort en het geslacht van de pinguïn de variantie in lichaamsmassa verklaren.\n\nlibrary(palmerpenguins)\n\nANOVA2_mdl &lt;- aov(body_mass_g ~ species + sex + species:sex,\n                  data = penguins)\n\nsummary(ANOVA2_mdl)\n\n             Df    Sum Sq  Mean Sq F value   Pr(&gt;F)    \nspecies       2 145190219 72595110 758.358  &lt; 2e-16 ***\nsex           1  37090262 37090262 387.460  &lt; 2e-16 ***\nspecies:sex   2   1676557   838278   8.757 0.000197 ***\nResiduals   327  31302628    95727                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n11 observations deleted due to missingness\n\n\n\n\n\n\n\n\n\n\n\nDe resultaten laten zien dat soort, geslacht en de interactie tussen de twee verantwoordelijk zijn voor substantiële variantie in lichaamsmassa. We kunnen de bijdragen van soort, geslacht en hun interactie berekenen door de partiële eta-kwadraatwaarde (\\(eta_p^2\\)) te berekenen. Hiervoor gebruiken we dezelfde formules als \\(\\eta^2\\) van de eenzijdige ANOVA’s. Het verschil tussen de formules voor \\(\\eta_p^2\\) en \\(\\eta^2\\) is dat \\(\\eta_p^2\\) niet de totale som van de kwadraten in de noemer gebruikt, maar de som van de restkwadraten (\\(SS_text{error}\\)) en de som van de kwadraten van het gewenste effect (\\(SS_text{effect}\\); d.w.z. soort of geslacht maar niet beide). Bijvoorbeeld,\n\\[\n\\small{\\text{For species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{145190219}{145190219+ 31302628} = .82}\n\\] \\[\n\\small{\\text{For sex:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{37090262}{37090262 + 31302628} = .54}\n\\] \\[\n\\small{\\text{For sex}\\times\\text{species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error}} = \\frac{1676557}{1676557+ 31302628} = .05}\n\\] We kunnen dit ook eenvoudig in R doen met de functie eta_squared in het pakket effectsize (Ben-Shachar, Lüdecke, and Makowski 2020) en het argument partial = TRUE instellen.\n\nlibrary(effectsize)\n\neta_squared(ANOVA2_mdl,\n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter   | Eta2 (partial) |       95% CI\n-------------------------------------------\nspecies     |           0.82 | [0.79, 0.85]\nsex         |           0.54 | [0.48, 0.60]\nspecies:sex |           0.05 | [0.01, 0.10]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#twee-weg-herhaalde-maatregelen-anova",
    "href": "Effect-Sizes-for-ANOVAs.html#twee-weg-herhaalde-maatregelen-anova",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.6 Twee-weg herhaalde maatregelen ANOVA",
    "text": "10.6 Twee-weg herhaalde maatregelen ANOVA\nEen twee-weg herhaalde maatregelen ANOVA (rmANOVA) zou aangeven dat proefpersonen aan elke conditie worden blootgesteld langs twee variabelen.\n\n10.6.1 Vrijhheidsgraden vaststellen\nRaadpleeg de volgende tabel om de vrijheidsgraden te bepalen voor tweeweg rmANOVA-effecten (Morse 2018). Merk op dat \\(k_1\\) het aantal groepen in de eerste variabele is en \\(k_2\\) het aantal groepen in de tweede variabele.\n\n\n\nVrijheidsgraden\n\n\n\n\n\nTussen subjecten ANOVA\n\n\n\nHoofd Effect (van één variabele)\n\\(k_1-1\\) of \\(k_2-1\\)\n\n\nInteractie Effect\n\\((k_1-1)\\times (k_2-1)\\)\n\n\nFout-tussen\n\\((k_1 \\cdot k_2) - 1\\)\n\n\nFout-binnen\n\\((n - 1)\\times (k_1\\cdot k_2 - 1)\\)\n\n\nTotaal\n\\(n-1\\)\n\n\n\n\n\n10.6.2 Eta-kwadraat van bidirectionele rmANOVA\nVoor een twee-weg herhaalde maatregelen ANOVA kunnen we de gewichtsverlies dataset uit het datarius pakket (Kassambara 2019) gebruiken. Deze dataset bevat een dieetconditie en een controleconditie die proefpersonen in de tijd volgde (3 tijdpunten) voor elke conditie.\n\n### laad in en herschik data\nlibrary(tidyr)\ndata(\"weightloss\", package = \"datarium\")\nweightloss &lt;- tidyr::pivot_longer(weightloss,cols = c(\"t1\",\"t2\",\"t3\"))\ncolnames(weightloss) &lt;- c(\"subject\",\"diet\",\"exercises\",\"time\", \"weight_loss\")\nweightloss &lt;- weightloss[weightloss$diet=='no',] # remove the diet intervention trials\n####\n\nrmANOVA2_mdl = aov(formula = weight_loss ~ time + exercises + time:exercises + Error(subject),\n                   data = weightloss)\nsummary(rmANOVA2_mdl)\n\n\nError: subject\n          Df Sum Sq Mean Sq F value Pr(&gt;F)\nResiduals 11  20.64   1.877               \n\nError: Within\n               Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntime            2 129.26   64.63   50.57 3.45e-13 ***\nexercises       1 101.03  101.03   79.05 3.16e-12 ***\ntime:exercises  2  92.55   46.28   36.21 9.26e-11 ***\nResiduals      55  70.29    1.28                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\n\n\n\nUit de bovenstaande tabel en grafiek kunnen we opmaken dat er een substantiële verandering in gewichtsverlies binnen de persoon is onder de conditie van lichaamsbeweging en geen waarneembare toename in gewichtsverlies zonder lichaamsbeweging. Dit suggereert dat er een substantieel interactie-effect is. Net als bij de tweezijdige ANOVA tussen de proefpersonen kunnen we de partiële gekwadrateerde waarden uit de ANOVA-tabel berekenen\n\\[\n\\small{\\text{For time:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{129.26}{129.26+ 70.29} = .65}\n\\] \\[\n\\small{\\text{For exercise:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{101.03}{101.03 + 70.29} = .59}\n\\] \\[\n\\small{\\text{For sex}\\times\\text{species:}\\;\\;\\;\\; \\eta_p^2= \\frac{SS_\\text{effect}}{SS_\\text{effect} + SS_\\text{error-within}} = \\frac{92.55}{92.55+ 70.29} = .57}\n\\]\nOnthoud voor de partiële gemeta-kwadraat dat de noemer niet de totale som van de kwadraten is, maar de som van de effectkwadraten en de fout. In de ANOVA met herhaalde maatregelen moet de fout alleen de fout binnen de proefpersoon zijn, omdat we niet geïnteresseerd zijn in de variantie tussen proefpersonen. We kunnen dit ook in R berekenen met de functie eta_kwadraat().\n\nlibrary(effectsize)\n\neta_squared(rmANOVA2_mdl,\n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nGroup  |      Parameter | Eta2 (partial) |       95% CI\n-------------------------------------------------------\nWithin |           time |           0.65 | [0.49, 0.75]\nWithin |      exercises |           0.59 | [0.42, 0.70]\nWithin | time:exercises |           0.57 | [0.39, 0.69]",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#effect-sizes-voor-anovas",
    "href": "Effect-Sizes-for-ANOVAs.html#effect-sizes-voor-anovas",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.7 Effect Sizes voor ANOVAs",
    "text": "10.7 Effect Sizes voor ANOVAs\nANOVA (Analysis of Variance) is een statistische methode die wordt gebruikt om gemiddelden over meerdere groepen of omstandigheden te vergelijken. Het wordt meestal gebruikt als de uitkomstvariabele continu is en de voorspellende variabelen categorisch. Veelgebruikte effectgroottematen voor ANOVA’s / F-tests zijn: eta-kwadraat (\\(\\eta^2\\)), partieel eta-kwadraat (\\(\\eta_p^2\\)), gegeneraliseerd eta-kwadraat (\\(\\eta^2_G\\)), omega-kwadraat (\\(\\omega^2\\)), partieel omega-kwadraat (\\(\\omega\\)), gegeneraliseerd omega-kwadraat (\\(\\omega^2_G\\)), Cohen’s \\(f\\).\n\n\n\n\n\n\n\n\nType\nBeschrijving\nSection\n\n\n\n\n\\(\\eta^2\\) - eta-kwadraat\nMeet de verklaarde variantie van het hele ANOVA-model.\nSection 10.7.1\n\n\n\\(\\eta^2_p\\) - Partiële eta-kwadraat\nMeet de variantie die wordt verklaard door een specifieke factor in het model.\nSection 10.7.2\n\n\n\\(\\eta^2_G\\) - Gegeneraliseerd eta-kwadraat\nVergelijkbaar met \\(\\eta^2\\), maar gebruikt de som van de kwadraten van alle niet-gemanipuleerde variabelen in de berekening. Dit stelt meta-analisten in staat om \\(\\eta_G\\) over verschillende ontwerpen te vergelijken.\nSection 10.7.3\n\n\n\\(\\omega^2,\\omega^2_p,\\omega^2_G\\) - Omega kwadraat correcties\nCorrecties voor vertekening in metingen van \\(\\eta^2\\). Kan op dezelfde manier geïnterpreteerd worden als \\(\\eta^2\\).\nSection 10.7.4\n\n\n\\(f\\) - Cohen’s f\nDeze effectgrootte kan worden geïnterpreteerd als de gemiddelde Cohen’s \\(d\\) tussen elke groep.\nSection 10.7.5\n\n\n\n\n10.7.1 Eta-kwadraat (\\(\\eta^2\\))\nEta-kwadraat is de verhouding tussen de variantie tussen groepen en de totale variantie. Het beschrijft het deel van de totale variantie in de gegevens dat wordt verklaard door een bepaalde factor. Daarom is het een maat voor verklaarde variantie. Om het kwadraat te berekenen (\\(\\eta^2\\)) moeten we eerst de totale som van de kwadraten (\\(SS_{\\text{total}}\\)) en de som van de effectkwadraten (\\(SS_{\\text{effect}}\\)) berekenen,\n\\[\nSS_{\\text{total}} = \\sum_{i=1}^n (y_i-\\bar{y})^2\n\\]\nWaarbij \\(bar{y}\\) het grote gemiddelde is (d.w.z. het gemiddelde van alle gegevenspunten samengevoegd over de groepen). Om de som van de kwadraten van het effect te berekenen, kunnen we de voorspelde \\(y\\) waarden nemen (\\(\\hat{y}_i\\)). In het geval van categorische voorspellers is \\(\\hat{y}_i\\) gelijk aan het gemiddelde van de uitkomst binnen de respectievelijke groep van dat individu. Daarom kan de som van de kwadraten van het effect worden berekend met de volgende formule:\n\\[\nSS_{\\text{effect}} = \\sum_{i=1}^n (\\hat{y}_i-\\bar{y})^2.\n\\]\nNu kunnen we de waarde van de kwadraten berekenen,\n\\[\n\\eta^2 = \\frac{SS_{\\text{effect}}}{SS_{\\text{total}}}\n\\]\nDe standaardfout van eta-kwadraat kan worden benaderd op basis van Olkin and Finn (1995):\n\\[\nSE_{\\eta^2}=\\sqrt{\\frac{4\\eta^2\\left(1-\\eta^2\\right)^2\\left(n+k-1\\right)^2}{\\left(n^2-1\\right)\\left(3+n\\right)}}\n\\]\nDe steekproefverdeling voor \\(\\eta^2\\) is asymmetrisch omdat alle waarden begrensd zijn in het bereik van 0 tot 1. Het betrouwbaarheidsinterval rond \\(\\eta^2\\) zal ook asymmetrisch zijn, dus in plaats van het betrouwbaarheidsinterval te berekenen op basis van de standaardfout, kunnen we in plaats daarvan een niet-centrale F-verdeling gebruiken met de vrijheidsgraden tussen groepen (bijv, voor drie groepen: \\(df_b=k-1=3-1=2\\)) en de vrijheidsgraden binnen groepen (bijvoorbeeld voor 100 proefpersonen en drie groepen: \\(df_b=n-k=100-3=97\\)) om de betrouwbaarheidsintervallen te verkrijgen. Een andere optie is om de bootstrappingprocedure te gebruiken (d.w.z. het opnieuw bemonsteren van de waargenomen gegevenspunten om een steekproefverdeling rond \\(\\eta^2\\) te construeren, zie Kirby and Gerlanc 2013) en dan de .025- en .975-kwantielen van die verdeling te nemen. De R-code hieronder berekent het juiste betrouwbaarheidsinterval.\nWaarbij \\(n\\) de totale steekproefgrootte is en \\(k\\) het aantal voorspellers. In R kunnen we \\(\\eta^2\\) berekenen van een eenzijdige ANOVA met behulp van de pinguïndataset uit het gegevenspakket palmerpenguins. Met de aov functie in basis-R kan de analist een ANOVA modelleren met categorische voorspellers aan de rechterkant (soort) van de ~ en de uitkomst aan de linkerkant (lichaamsmassa van de pinguïn). We kunnen dan de eta_squared functie in het effectsize pakket gebruiken om de puntschatting en betrouwbaarheidsintervallen te berekenen.\n\n# Bijvoorbeeld:\n# groep: soorten\n# uitkomst: lichaamsgewicht\n\nlibrary(palmerpenguins)\nlibrary(effectsize)\n\n# Een-Wag ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\neta_squared(mdl1, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.71]\n\n\nDe soort pinguïn verklaart het grootste deel van de variatie in lichaamsmassa met een kwadraatwaarde van \\(eta^2\\) = .67 [.62, .71]. Laten we nu hetzelfde doen met een tweezijdige ANOVA, met zowel soort als seks als categorische voorspellers.\n\n# Bijvoorbeeld:\n# groep: soorten en geslacht\n# uitkomst: lichaamsgewicht\n\n# Twee-Weg ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\neta_squared(mdl2, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.72]\nsex       | 0.17 | [0.10, 0.24]\n\n\nMerk op dat de \\(\\eta^2\\) niet verandert voor soorten omdat de som van de kwadraten wordt gedeeld door de totale som van de kwadraten in plaats van de residuele som van de kwadraten (zie partiële eta kwadraat). In het voorbeeld is de kwadratische eta voor de soorten .67 en voor het geslacht .17.\n\n\n10.7.2 Partiële Eta-Kwadraat (\\(\\eta^2_p\\))\nPartiële eta-kwadraat is de meest gerapporteerde effectgrootte voor F-tests. Het beschrijft het deel van de variabiliteit dat is geassocieerd met een effect wanneer de variabiliteit die is geassocieerd met alle andere effecten die zijn geïdentificeerd in de analyse buiten beschouwing is gelaten (vandaar dat het “partieel” is). Als je toegang hebt tot een ANOVA-tabel, wordt de partiële eta-kwadraat voor een effect als volgt berekend:\n\\[\n\\eta_p^2 = \\frac{ SS_{\\text{effect}}}{SS_{\\text{effect}}+SS_{\\text{fout}}}\n\\]\nEr zijn twee dingen waar je op moet letten:\n\nIn een eenzijdige ANOVA (één categorische voorspeller) zijn partiële eta-kwadraat en eta-kwadraat gelijkwaardig, aangezien \\(SS_{\\text{total}} = SS_{\\text{effect}}+SS_{\\text{fout}}\\).\n\nAls er meerdere voorspellers zijn, omvat de noemer alleen de som van de kwadraten van het effect van belang in plaats van het effect van alle voorspellers (wat het geval is voor de niet-partiële eta-kwadraat).\n\nLaten we in R de partiële eta-kwadraatwaarden voor een eenzijdige ANOVA en een tweeweg ANOVA vergelijken met behulp van de functie eta_squared in het pakket effectsize.\n\n# Voorbeeld:\n# groep: soorten\n# uitkomst: lichaamsgewicht\n\n\n# One-Way ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\neta_squared(mdl1, \n            partial = TRUE,\n            alternative = \"two.sided\") \n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Eta2 |       95% CI\n-------------------------------\nspecies   | 0.67 | [0.62, 0.71]\n\n\nDe soort pinguïn verklaart het grootste deel van de variatie in lichaamsmassa met een gedeeltelijke kwadraatwaarde van \\(eta^2\\) = \\(eta^2_p\\) = .67 [.62, .71]. Laten we nu hetzelfde doen met een tweezijdige ANOVA, met zowel soort als geslacht als onze categorische voorspellers.\n\n# Voorbeeld:\n# groep: soorten en geslacht\n# uitkomst: lichaamsgewicht\n\n# Twee-Weg ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\neta_squared(mdl2, \n            partial = TRUE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Eta2 (partial) |       95% CI\n-----------------------------------------\nspecies   |           0.81 | [0.78, 0.84]\nsex       |           0.53 | [0.46, 0.59]\n\n\nZodra we een tweezijdige ANOVA uitvoeren, begint de eta-kwadraatwaarde voor soorten te verschillen. Het voorbeeld toont een gedeeltelijke kwadraatwaarde voor soorten van \\(\\eta^2_p\\) = .81 [.78, .84] en voor geslacht \\(\\eta^2\\) = .53 [.46, .59].\n\n\n10.7.3 Gegeneraliseerde Eta-Kwadraat (\\(\\eta^2_G\\))\nGegeneraliseerd eta-kwadraat is ontwikkeld om effectgroottevergelijkingen mogelijk te maken tussen onderzoeken met verschillende designs, waar eta-kwadraat en partieel eta-kwadraat niet bij kunnen helpen (zie voor meer informatie). Als het kan (je bent er zeker van dat je het goed hebt berekend, of de statistische software die je gebruikt geeft toevallig deze maat weer), rapporteer dan naast eta-kwadraat of partieel eta-kwadraat ook gegeneraliseerd eta-kwadraat. Het grootste voordeel van veralgemeend kwadraat is dat het meta-analyse vergemakkelijkt, wat belangrijk is voor het vergaren van kennis. Om de gegeneraliseerde gemeta-kwadraat te berekenen, moet de noemer de som van de kwadraten van alle niet-gemanipuleerde variabelen zijn (d.w.z. variantie van puur individuele verschillen in de uitkomst in plaats van individuele verschillen in behandelingseffecten). Merk op dat de formule afhankelijk is van de opzet van het onderzoek. In R ondersteunt de eta_squared functie in het effectsize pakket de berekening van gegeneraliseerde eta-squared door het generalized=TRUE argument te gebruiken.\n\n\n10.7.4 Omega kwadraat correcties (\\(\\omega^2\\), \\(\\omega^2_p\\))\nVergelijkbaar met Hedges’ correctie voor small sample bias in gestandaardiseerde gemiddelde verschillen, is \\(eta^2\\) ook vertekend. We kunnen een correctie toepassen op \\(\\eta^2\\) en een relatief onvertekende schatting krijgen van het aandeel van de populatie in de variantie dat verklaard wordt door de voorspeller. Om \\(omega\\) te berekenen moeten we de gemiddelde gekwadrateerde fouten binnen de groep berekenen:\n\\[\nMS_{\\text{binnen}} = \\frac{1}{n}\\sum_{i=1}^n (y_i-\\hat{y}_i)^2.\n\\] Waar de voorspelde waarden van de uitkomst, \\(hat{y}_i\\), de gemiddelde waarde zijn voor de respectieve groep van het individu\n\\[\n\\omega^2 = \\frac{SS_{\\text{effect}}-(k-1)\\times MS_{\\text{tussen}}}{SS_{\\text{totaal}} + MS_{\\text{tussen}}}\n\\]\nWaar \\(k\\) het aantal groepen in de voorspellende variabele (effect) is. Voor gedeeltelijke omega-kwadraatwaarden hebben we de gemiddelde gekwadrateerde fout van het effect en de residuen nodig, die eenvoudig kunnen worden berekend uit hun som van de kwadraten:\n\\[\nMS_{\\text{effect}} = \\frac{SS_{\\text{effect}}}{n}\n\\] \\[\nMS_{\\text{fout}} = \\frac{SS_{\\text{fout}}}{n}\n\\] Om dan de gedeeltelijke omega in het kwadraat te berekenen, kunnen we de volgende formule gebruiken:\n\\[\n\\omega_p^2 = \\frac{(k-1)(MS_{\\text{effect}} - MS_{\\text{fout}})}{(k-1)\\times MS_{\\text{effect}} + (n-k-1)\\times MS_{\\text{fout}}}\n\\]\nIn R kunnen we de omega_squared functie in het effectsize pakket gebruiken om zowel \\(omega^2\\) als \\(omega^2_p\\) te berekenen. Voor het eerste voorbeeld gebruiken we een eenzijdige ANOVA.\n\n# Voorbeeld:\n# groep: soorten\n# uitkomst: lichaamsgewicht\n\nlibrary(palmerpenguins)\n\n# Een-Weg ANOVA\nmdl1 &lt;- aov(data = penguins,\n           body_mass_g ~ species)\n\n# omega-kwadraat\nomega_squared(mdl1, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.61, 0.71]\n\n# partiële omega-kwadraat\nomega_squared(mdl1, \n              partial = TRUE,\n              alternative = \"two.sided\")\n\nFor one-way between subjects designs, partial omega squared is\n  equivalent to omega squared. Returning omega squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.61, 0.71]\n\n\nDe soort pinguïn verklaart het grootste deel van de variatie in lichaamsmassa met een omega-kwadraatwaarde van \\(omega^2\\) = .67 [.61, .71]. Merk op dat de gedeeltelijke en niet-partiële omega-kwadraatwaarden geen verschil laten zien zoals verwacht in een eenzijdige ANOVA. Laten we nu hetzelfde doen met een tweezijdige ANOVA, met zowel soort als geslacht als onze categorische voorspellers.\n\n# Voorbeeld:\n# groep: soorten en geslacht\n# uitkomst: lichaamsgewicht\n\n# Twee-Weg ANOVA\nmdl2 &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)\n\n# omega-kwadraat\nomega_squared(mdl2, \n            partial = FALSE,\n            alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 |       95% CI\n---------------------------------\nspecies   |   0.67 | [0.62, 0.72]\nsex       |   0.17 | [0.10, 0.24]\n\n# partiële omega-kwadraat\nomega_squared(mdl2, \n              partial = TRUE,\n              alternative = \"two.sided\")\n\n# Effect Size for ANOVA (Type I)\n\nParameter | Omega2 (partial) |       95% CI\n-------------------------------------------\nspecies   |             0.81 | [0.78, 0.84]\nsex       |             0.53 | [0.46, 0.58]\n\n\nZodra we een tweezijdige ANOVA uitvoeren, divergeren de eta-kwadraatwaarden voor soorten. Het voorbeeld toont een gedeeltelijke kwadraatwaarde voor soorten van \\(omega^2_p\\) = .81 [.78, .84] en voor geslacht \\(omega^2\\) = .53 [.46, .58].\n\n\n10.7.5 Cohen’s \\(f\\)\nCohen’s \\(f\\) wordt gedefinieerd als de verhouding van de standaarddeviaties van de groepsgemiddelden en de gemeenschappelijke standaarddeviatie binnen elk van de groepen (merk op dat ANOVA uitgaat van gelijke varianties tussen groepen). Cohen’s \\(f\\) is de maat voor de effectgrootte die door G*Power wordt gevraagd voor poweranalyse voor F-tests. Deze kan eenvoudig worden berekend uit de eta-kwadraatwaarde,\n\\[\nf = \\sqrt{\\frac{\\eta^2}{1-\\eta^2}}\n\\]\nof door de \\(omega^2\\) waarde,\n\\[\nf = \\sqrt{\\frac{\\omega^2}{1-\\omega^2}}\n\\]\nCohen’s \\(f\\) kan worden geïnterpreteerd als “de gemiddelde Cohen’s \\(d\\) (d.w.z. gestandaardiseerd gemiddeld verschil) tussen groepen”. Merk op dat deze effectgrootte geen richting heeft (\\(f\\) is altijd groter dan nul), dus twee onderzoeken met dezelfde \\(f\\) voor dezelfde groepen kunnen heel verschillende patronen van groepsgemiddelde verschillen hebben. Merk op dat Cohen’s \\(f\\) ook vaak wordt gerapporteerd als \\(f^2\\). De betrouwbaarheidsintervallen voor Cohen’s \\(f\\) kunnen worden berekend uit de boven- en ondergrenzen van de betrouwbaarheidsintervallen van eta kwadraat of omega kwadraat met behulp van de formules om \\(f\\) te berekenen (bijvoorbeeld voor de bovengrens \\(f_{UP} = \\sqrt{frac{\\eta^2_{UP}}{1-\\eta^2_{UP}}\\)).\nIn R kunnen we de cohens_f functie in het effectsize pakket gebruiken om Cohen’s \\(f\\) te berekenen. We gebruiken weer voorbeeldgegevens uit het pakket palmerpenguins.\n\n# Bijvoorbeeld:\n# groep: soorten\n# uitkomst: lichaamsgewicht\n\n# ANOVA\nmdl &lt;- aov(data = penguins,\n           body_mass_g ~ species)   \n\ncohens_f(mdl,alternative = \"two.sided\")\n\nFor one-way between subjects designs, partial eta squared is equivalent\n  to eta squared. Returning eta squared.\n\n\n# Effect Size for ANOVA\n\nParameter | Cohen's f |       95% CI\n------------------------------------\nspecies   |      1.42 | [1.27, 1.57]\n\n\nIn het bovenstaande voorbeeld was het verschil in lichaamsgewicht tussen de drie pinguïnsoorten erg groot met een Cohen’s \\(f\\) van 1,42 [1,27, 1,57].",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  },
  {
    "objectID": "Effect-Sizes-for-ANOVAs.html#anova-resultaten-rapporteren",
    "href": "Effect-Sizes-for-ANOVAs.html#anova-resultaten-rapporteren",
    "title": "10  Effect Sizes voor ANOVAs",
    "section": "10.8 ANOVA-resultaten rapporteren",
    "text": "10.8 ANOVA-resultaten rapporteren\nVoor ANOVA’s/F-tests moet je altijd twee soorten effecten rapporteren: het omnibuseffect van de factor(en) en het effect van geplande contrasten of post-hocvergelijkingen.\nStel je bijvoorbeeld voor dat je drie groepen/condities vergelijkt met een eenzijdige ANOVA. De ANOVA zal eerst een F-statistiek, de vrijheidsgraden en de bijbehorende p-waarde opleveren. Hier moet je de grootte van dit omnibus factor effect berekenen in eta-kwadraat, partiële eta-kwadraat of gegeneraliseerde eta-kwadraat. Stel dat het omnibuseffect significant is. U weet nu dat er ten minste één groep is die verschilt van de anderen. Je wilt weten welke groep(en) verschilt (verschillen) van de anderen en hoeveel ze verschilt (verschillen). Daarom voer je post hoc vergelijkingen uit op deze groepen. Omdat post hoc vergelijkingen elke groep paarsgewijs vergelijken met de anderen, krijg je een t-statistiek en p-waarde voor elke vergelijking. Hiervoor moet je Cohen’s \\(d\\) of Hedges’ \\(g\\) berekenen en rapporteren.\nStel je voor dat je twee onafhankelijke variabelen of factoren hebt en je voert een twee-bij-twee factorial ANOVA uit. Het eerste wat je dan doet, is kijken naar de interactie. Als de interactie significant is, rapporteer je opnieuw de bijbehorende omnibus effectgrootte maten en ga je verder met het analyseren van de enkelvoudige effecten. Afhankelijk van je onderzoeksvraag vergelijk je de niveaus van de ene OV op elk niveau van de andere OV. U rapporteert \\(d\\) of \\(g\\) voor deze enkelvoudige effecten. Als de interactie niet significant is, kijk je naar de hoofdeffecten en rapporteer je het bijbehorende omnibuseffect. Vervolgens analyseert u het hoofdeffect door de niveaus van één OV te vergelijken terwijl u de niveaus van de andere OV samenvoegt/aggregeert. U rapporteert \\(d\\) of \\(g\\) voor deze paarsgewijze vergelijkingen.\nMerk op dat effecten van lagere orde niet direct interpreteerbaar zijn als effecten van hogere orde significant zijn. Als je een significante interactie hebt in een tweezijdige ANOVA, kun je de hoofdeffecten niet direct interpreteren. Als u een significante drieweginteractie hebt in een drieweg ANOVA, kunt u de hoofdeffecten of de tweerichtingsinteracties niet rechtstreeks interpreteren, ongeacht of ze significant zijn of niet.\nIn R kunnen we de functie summary gebruiken om de anova-tabel weer te geven. We kunnen de tabel ook aanvullen met bijvoorbeeld gedeeltelijke omega kwadraatwaarden en hun respectievelijke betrouwbaarheidsintervallen.\n\n# ANOVA mdl\nmdl &lt;- aov(data = penguins,\n           body_mass_g ~ species + sex)   \n\n# bereken partiële omega-kwadraat waarden\nomega_values &lt;- omega_squared(mdl, alternative = \"two.sided\")\n\n# creëer tabel van partiële omega-kwadraat waarden\nomega_table &lt;- data.frame(omega_sq = MOTE::apa(c(omega_values$Omega2_partial,NA)),\n                     omega_low = MOTE::apa(c(omega_values$CI_low,NA)),\n                     omega_high = MOTE::apa(c(omega_values$CI_high,NA)))\n\n# omega waarden toevoegen aan samenvatting van anova tabel\ncbind(summary(mdl)[[1]],\n      omega_table)\n\n             Df    Sum Sq    Mean Sq  F value        Pr(&gt;F) omega_sq omega_low\nspecies       2 145190219 72595109.6 724.2080 3.079053e-121    0.813     0.781\nsex           1  37090262 37090261.8 370.0121  8.729411e-56    0.526     0.457\nResiduals   329  32979185   100240.7       NA            NA       NA        NA\n            omega_high\nspecies          0.838\nsex              0.585\nResiduals           NA\n\n\n\n\n\n\nBen-Shachar, Mattan S., Daniel Lüdecke, and Dominique Makowski. 2020. “effectsize: Estimation of Effect Size Indices and Standardized Parameters.” Journal of Open Source Software 5 (56): 2815. https://doi.org/10.21105/joss.02815.\n\n\nBuchanan, Erin M., Amber Gillenwaters, John E. Scofield, and K. D. Valentine. 2019. MOTE: Measure of the Effect: Package to Assist in Effect Size Calculations and Their Confidence Intervals. http://github.com/doomlab/MOTE.\n\n\nHorst, Allison Marie, Alison Presmanes Hill, and Kristen B Gorman. 2020. Palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://doi.org/10.5281/zenodo.3960218.\n\n\nKassambara, Alboukadel. 2019. Datarium: Data Bank for Statistical Analysis and Visualization. https://CRAN.R-project.org/package=datarium.\n\n\nKirby, Kris N, and Daniel Gerlanc. 2013. “BootES: An r Package for Bootstrap Confidence Intervals on Effect Sizes.” Behavior Research Methods 45: 905–27.\n\n\nMorse, David. 2018. “How to Calculate Degrees of Freedom When Using Two Way ANOVA with Unequal Sample Size?”\n\n\nOlkin, Ingram, and Jeremy D. Finn. 1995. “Correlations Redux.” Psychological Bulletin 118 (1): 155–64. https://doi.org/10.1037/0033-2909.118.1.155.\n\n\nViechtbauer, Wolfgang. 2010. “Conducting Meta-Analyses in R with the metafor Package.” Journal of Statistical Software 36 (3): 1–48. https://doi.org/10.18637/jss.v036.i03.",
    "crumbs": [
      "**Gestandaardiseerde Effect Sizes**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>ANOVA's</span>"
    ]
  }
]