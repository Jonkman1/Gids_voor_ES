# Effect Sizes voor Categoriale Variabelen

Voor dichotome relaties waarbij verhoudingen een rol spelen, zijn er veel variaties van effectgroottes die men kan gebruiken. Veelgebruikte effectgroottematen voor statistische procedures op categorische gegevens zijn: phi-coëfficiënt ($phi$), Cramer's $V$, Cohen's $h$, Cohen's $omega$, odds ratio ($OR$), risicoverschil ($RD$) en relatief risico ($RR$).


#### **Hier is een tabel voor elke effect size besproken in dit hoofdstuk:** {.unnumbered}


| Type                | Beschrijving | Section|
|:------|:---------|:----:|
| $\phi$ - phi coëfficient | Pearson correlatie tussen twee binaire variabele (b.v., 2x2 contingentietabellen).  | @sec-phi|
| $V$ - Cramer's *V* |  Meet de associatie tussen categorische variabelen. Vergelijkbaar met een coëfficiënt van $\phi$, maar bedoeld voor contingentietabellen groter dan 2x2. | @sec-v|
| $h$ - Cohen's *h* | Pearson correlatie tussen twee binaire variabelen. Moeilijk te interpreteren.  | @sec-h|
| $w$ - Cohen's *w* | Associatie tussen twee categorische variabelen en wordt op dezelfde manier berekend als de $\phi$ coëfficiënt. Als de coëfficiënt wordt berekend op een 2x2 contingentietabel, heeft hij dezelfde waarde als de $\phi$.  | @sec-w|
| $\boldsymbol{פ}$ - Ben-Shachar's Fei | Een correctie op Cohen's $w$ voor eendimensionale teltabellen.   | @sec-fei|
| $OR$ - Odds Ratio | Ratio van kansen dat een gebeurtenis zich voordoet tussen behandelings- en controlegroepen  | @sec-or|
| $RD$ - Risk Difference(Risico Verschil) | Verschil tussen verhoudingen in behandelings- en controlegroepen.  | @sec-rd|
| $RR$ - Relatieve Risico | Verhouding tussen de verhoudingen in de behandelings- en controlegroepen.  | @sec-rr|


## Verhoudingstest met één steekproef

Als we een enkele steekproef hebben en we willen het verschil bepalen tussen een proportie en een interessante proportie. We kunnen eerst de teststatistiek berekenen door de geobserveerde proportie ($p$) te vergelijken met de proportie van belang ($p_0$):

$$
z = \frac{p-p_0}{\sqrt{\frac{p(1-p)}{n}}},
$$
waarbij $n$ de steekproefgrootte is. Merk op dat dit alleen geldig is als de proportie van belang toeval is ($p_0=.50$) omdat de steekproefverdeling met een proportie van .50 normaal is. Maar als de proportie die van belang is niet .50 is, dan moeten we in plaats daarvan Cohen's $h$ berekenen (zie @sec-h voor details), die de schaal transformeert zodat de verdelingen normaal zijn ongeacht de proportie. De test-statistiek met Cohen's $h$,

$$
z = h\sqrt{n}
$$


Laten we proberen de verhouding te testen tegen toeval ($p_0=.50$) in R. We kunnen dan de *p*-waarde in basis-R berekenen met de functie `pnorm()`:

```{r}
# Bv:
p <- .7 # geobserveerde proportie
p0 <- .5 # proportie waarin geïnteresseerd 
n <- 50 # steekproef omvang

z <- (p-p0) / sqrt(p*(1-p)/n)

pval <- 2*(1-pnorm(z)) # twee koppige test

data.frame(z,pval)

```
Resultaten tonen een significant verschil met toeval met $z$ = 3.09 en *p*-val = .002


## Effect Sizes

### Phi Coëfficient ($\phi$) {#sec-phi}

De Phi-coëfficiënt ($\phi$) is een maat voor de associatie tussen twee binaire variabelen (daarom is hij ALLEEN van toepassing op 2 bij 2 contingentietabellen, d.w.z. dat elke variabele slechts twee niveaus heeft). Het is een speciaal geval van de Pearson correlatiecoëfficiënt en een $r$ voor twee binaire variabelen is gelijk aan phi. Merk op dat in tegenstelling tot $r$ die van -1 tot 1 gaat, phi van 0 tot 1 gaat. Ook geeft het teken van $r$ de richting van de associatie aan, terwijl we naar de tabel zelf moeten kijken om de richting van een associatie te bepalen op basis van een 2 bij 2 contingentietabel; phi geeft alleen een maat voor de sterkte. De 2 bij 2 contingentietabel wordt geïllustreerd door @tbl-contingency.


|       |  $X=0$   |  $X=1$   |
|:-----:|:--------:|:--------:|
| $Y=0$ | $n_{00}$ | $n_{10}$ |
| $Y=1$ | $n_{01}$ | $n_{11}$ |

: Contingentietabel tussen twee binaire variabelen {#tbl-contingency}

De steekproefgrootten binnen elke cel geven ons de nodige informatie om het verband tussen de twee variabelen te schatten. Een grote phi-coëfficiënt zou naar verwachting relatief grote steekproefgrootten hebben in de diagonale cellen ($n_{00}$ en $n_{11}$) en relatief kleine steekproefgrootten in de off-diagonale cellen ($n_{01}$ en $n_{10}$). Om phi te berekenen, kan het rechtstreeks worden berekend uit de cellen van de contingentietabel [aangepast van vergelijking 1, @guilford1965],

$$
\phi = \frac{n_{11}n_{00} -n_{10}n_{01}}{\sqrt{(n_{00} + n_{01})(n_{10} + n_{11})(n_{00} + n_{10})(n_{01} + n_{11})}}
$$

of handiger, van de $\chi^2$-statistiek [vergelijking 7.2.5, @cohen1988],

$$
\phi = \sqrt{\frac{\chi^2}{n}}
$$

Waar $n$ de totale steekproefgrootte is (d.w.z. de som van alle cellen). Met behulp van het pakket `effectsize` in R kunnen we de phi-coëfficiënt berekenen met de functie `phi`, rechtstreeks uit de contingentietabel:

```{r, echo = TRUE}
# Voorbeeld contingentietabel:
#  40  17
#  11  45

library(effectsize)

contingency_table <- matrix(c(40, 11,
                              17, 45),ncol = 2)

phi_coefficient <- phi(contingency_table, alternative = "two.sided")

phi_coefficient
```

In ons voorbeeld hebben we een phi-coëfficiënt van $\phi$ = .50 \[0.31, 0.69\].

### Cramer's $V$ {#sec-v}

Cramer's V, soms ook Cramer's phi ($\phi$) genoemd, is een algemene maat voor de effectgrootte van de associatie tussen twee nominale variabelen. Het is van toepassing op contingentietabellen van elke grootte ($2\times 2$, $3\times 3$, $3\times 4$, $5\times 3$, etc.). Cramer's $V$ op een controletabel van $2\times 2$ is gelijk aan de phi-coëfficiënt. Ter illustratie van een hogere orde contingentietabel staat @tbl-contingency-2 voor een $3\times 4$ contingentietabel van twee variabelen. @tbl-contingency-2 representeert een $3\times 4$ contingentie tabel van twee variabelen.

|       |  $X=0$   |  $X=1$   |  $X=2$   |  $X=3$   |
|-------|:--------:|:--------:|:--------:|:--------:|
| $Y=0$ | $n_{00}$ | $n_{10}$ | $n_{21}$ | $n_{31}$ |
| $Y=1$ | $n_{01}$ | $n_{11}$ | $n_{21}$ | $n_{31}$ |
| $Y=2$ | $n_{02}$ | $n_{12}$ | $n_{22}$ | $n_{32}$ |

: Contingentietabel tussen twee categoriale variabelen {#tbl-contingency-2}

Net als de phi-coëfficiënt varieert de waarde van Cramer's $V$ van 0 tot 1 en kan op dezelfde manier geïnterpreteerd worden als een phi-coëfficiënt. Ook hier kunnen we de statistiek van $\chi^2$ gebruiken om de waarde te berekenen, maar omdat er meer dan 2 niveaus voor elke variabele kunnen zijn, moeten we ook rekening houden met het aantal niveaus, $k$, van de variabele met het minste aantal niveaus (bijvoorbeeld bij een contingentietabel van $3 maal 4$ zou $k$ gelijk zijn aan 3). Cramer's $V$ wordt gedefinieerd als [vergelijking 7.2.6, @cohen1988],

$$
V = \sqrt{\frac{\chi^2}{n(k-1)}}
$$

De standaardfout van een Cramer's $V$ is vergelijkbaar met die van een Pearson correlatie en een $\phi$ coëfficiënt.

$$
SE_V = \sqrt{\frac{\left(1-V^2\right)^2}{n-1}}
$$

Waar $n$ de totale steekproefgrootte is (d.w.z. de som van alle cellen). Net als bij de Pearson correlatie kunnen we het betrouwbaarheidsinterval niet rechtstreeks uit de standaardfout berekenen, maar moeten we $V$ omrekenen naar een Z-statistiek van Fisher, $Z_V = \text{arctanh}(V)$. We kunnen dan het 95%-betrouwbaarheidsinterval voor $V$ berekenen door het betrouwbaarheidsinterval voor $Z_V$ terug te rekenen:

$$
SE_{Z_V} = \frac{1}{\sqrt{n-3}}
$$

$$
CI_{V} = \tanh(Z_V \pm 1.96\times SE_{Z_V})
$$

Met behulp van het `ufs` pakket [@ufs] kunnen we Cramer's $V$ en zijn 95% betrouwbaarheidsinterval berekenen met behulp van de Fisher's Z-methode zoals hierboven beschreven. Voor het voorbeeld kunnen we gegevens uit een 3 $times$ 3 contingentietabel gebruiken.

```{r, echo = TRUE,message=FALSE}
# Voorbeeld contingentie tabel:
#  40  14  12
#  11  27   9
#   5  10  34

library(ufs)

contingency_table <- matrix(c(40, 11,  5,
                              14, 27, 10,
                              12,  9, 34),ncol = 3)


V <- cramersV(contingency_table)
CI <- confIntV(contingency_table)

# print pearson correlation and confidence intervals
data.frame(V = MOTE::apa(V$output$cramersV), 
           Vlow = MOTE::apa(CI$output$confIntV.fisher[1]), 
           Vhigh = MOTE::apa(CI$output$confIntV.fisher[2]))

```

In ons voorbeeld hebben we een Cramer's $V$ of $V$ = .44 \[.31, .56\].

### Cohen's $h$ {#sec-h}

Cohen's $h$ is een maat voor de afstand tussen twee verhoudingen of waarschijnlijkheden. Het wordt soms ook het "verschil tussen arcsijnen" genoemd. Voor een gegeven proportie $p$ wordt de transformatie van de arcsinus gegeven door [vergelijking 6.2.1, @cohen1988]:

$$
\psi = 2\cdot \text{arcsin}(\sqrt{p}).
$$

Cohen's $h$ is het verschil tussen de arcsinus transformaties van twee verhoudingen [vergelijking 6.2.2, @cohen1988]:

$$
h = \psi_1 - \psi_2
$$

Cohen's $h$ wordt vaak gebruikt voor de poweranalyse van proportietests. Het is zelfs de vereiste effectgrootte in het programma *G Power* [@faul2009]. We kunnen de standaardfout van Cohen's $h$ berekenen,

$$
SE_h = \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}
$$

Omdat de steekproefverdeling van $h$ symmetrisch is, kunnen we de betrouwbaarheidsintervallen berekenen uit de standaardfout,

$$
CI_h = h \pm1.96\times SE_h
$$

Om Cohen's $h$ te berekenen, kunnen we de `cohens_h` functie in het `effectsize` pakket in R gebruiken.

```{r, echo = TRUE}
# installeer pakket als je dat al niet hebt gedaan
# install.packages('effectsize')
# Voorbeeld proporties: p1 = .45, p2 = .30

library(effectsize)

contingency_table <- matrix(c(40, 11,
                              14, 27),ncol = 2)

cohens_h(contingency_table)

```

Uit het voorbeeld leidde de R-code tot een Cohen's $h$ waarde van $h$ = .93 \[0.52, 1.34].

### Cohen's $w$ {#sec-w}

Cohen's $w$ is een maat voor associatie analoog aan de phi-coëfficiënt, maar dan op tabellen groter dan 2x2. Hoewel Cohen's $w$ nuttig is voor poweranalyses, is het niet zo nuttig als een op zichzelf staande effectgrootte. Zoals @cohen1988 stelt (pp. 221):

> Als maatstaf voor associatie is Cohen's $w niet bekend en gemakkelijk.

Cohen's $w$ heeft precies dezelfde formule als de phi coëfficiënt met als enige verschil dat de $chi^2$ statistiek uit een contingentietabel van elke grootte komt [vergelijking 7.2.5, @cohen1988],
$$
w = \sqrt{\frac{\chi^2}{n}}
$$

En kan ook direct berekend worden uit Cramer's $V$ [vergelijking 7.2.7, @cohen1988],

$$
w = V \times \sqrt{k-1}
$$

Waar $k$ het aantal categorieën is in de variabele met het minste aantal categorieën. We kunnen de functie `cohens_w()` gebruiken in het pakket `effectsize` [@effectsize].

```{r, echo =TRUE}
# Voorbeeld contingentietabel
# 40 14
# 11 27

contingency_table <- matrix(c(40, 11, 
                              14, 27),ncol = 2)

cohens_w(contingency_table,
         alternative = "two.sided")
```

In de voorbeeldcode gaf de functie `cohens_w` de Cohen $w$ waarde van $w$ = .45 [0.24, 0.65].

### Ben-Shachar's Fei (פ) {#sec-fei}

@benshachar2023 introduceerden een nieuwe effectgrootte voor eendimensionale tabellen van tellingen/verhoudingen die ze aanduiden met de Hebreeuwse letter פ. Ben-Shachar's פ is een correctie op Cohen's $w$ die aanpast voor de verwachte waarde en daardoor de waarde begrenst tussen 0 en 1. De vergelijking voor פ is als volgt gedefinieerd,

$$
\mathbf{פ }= \sqrt{\frac{\chi^2}{n \left(\frac{1}{\min\left(P_E\right)} -1\right)}}
$$

Waarbij $\min(P_E)$ de kleinste verwachte kans is. De formule voor Ben-Schachar's פ kan ook worden uitgedrukt in termen van Cohen's $omega$,

$$
\mathbf{פ }= \frac{\omega}{\sqrt{\left(\frac{1}{\max(P_E)} -1\right)}}
$$

In R kunnen we Ben-Shachar's פ berekenen met de `fei()` functie in het `effectsize` pakket [@effectsize].

```{r, echo =TRUE}
# Bijvoorbeeld:
# Geobserveerde aantallen: 20, 50, 100 (geobserveerde proporties: .12, .29, .59)
# Verwachte proporties: .5, .2, .3

observed_counts <- c(20,50,100)
expected_probabilities <- c(.5,.2,.3)


fei(observed_counts,
    p = expected_probabilities,
    alternative = "two.sided")
```

In de voorbeeldcode gaf de functie `fei` Ben-Shachars פ waarde van .39 \[0.31, 0.47].

### Odds Ratio ($OR$) {#sec-or}

Odds ratio meet de effectgrootte tussen twee binaire variabelen. Het wordt vaak gebruikt in medisch en gedragsinterventieonderzoek en met name in meta-analyses.

Laten we ons een onderzoek voorstellen dat wordt uitgevoerd om de associatie tussen roken en de ontwikkeling van depressieve stoornis (MDD) te onderzoeken. De studie omvat een steekproef van 251 personen, die in twee groepen zijn ingedeeld: 125 rokers en 126 niet-rokers. De onderzoekers zijn geïnteresseerd in de kansen op het hebben van een depressieve stoornis (MDD) onder rokers in vergelijking met niet-rokers. Stel dat bij 25 rokers MDD werd vastgesteld en bij 100 niet, maar in de groep niet-rokers werd bij 12 personen MDD vastgesteld en bij 120 niet. De odds ratio zou dan zijn:

$$
OR = \frac{25/100}{12/120}= \frac{.25}{.10} = 2.50
$$

In het algemeen kunnen we de odds-ratio berekenen op basis van een contingentietabel tussen binaire variabelen $X$ (d.w.z. de behandeling) en $Y$ (d.w.z. de uitkomst); zie @tbl-contingency-OR).

|       |  $X=T$   |  $X=C$   |
|:-----:|:--------:|:--------:|
| $Y=0$ | $n_{T0}$ | $n_{C0}$ |
| $Y=1$ | $n_{T1}$ | $n_{C1}$ |

: Contingenctietabel tussen twee binaire variabelen {#tbl-contingency-OR}

Uiteindelijk willen we de uitkomst tussen de behandelgroep ($X=T$) en de controlegroep ($X=C$) vergelijken. Daarom kunnen we de odds ratio als volgt berekenen,

$$
OR = \frac{n_{T1}/n_{T0}}{n_{C1}/n_{C0}}
$$

De standaardverdeling van de kansverhouding is asymmetrisch. Om betrouwbaarheidsintervallen te berekenen, kunnen we eerst de odds ratio omrekenen naar een log odds ratio ($LOR= \log(OR)$). Daarna kunnen we de standaardfout van de logratio berekenen,

$$
SE_{LOR} = \sqrt{\frac{1}{n_{T0}} + \frac{1}{n_{T1}} + \frac{1}{n_{C0}} + \frac{1}{n_{C1}}}
$$

Met de standaardfout van de log odds ratio kunnen we vervolgens het betrouwbaarheidsinterval van de odds ratio berekenen door terug te rekenen met behulp van de exponentiële functie,

$$
CI_{OR} = \exp(LOR \pm 1.96\times SE_{LOR})
$$

In R kunnen we het pakket `effectsize` gebruiken om de odds ratio en het betrouwbaarheidsinterval te berekenen:

```{R, echo=TRUE}
# Bijvoorbeeld:
# Experimentele Groep: 10 ziek, 43 gezond
# Controle Groep:  24 ziek, 41 gezond


contingency_table <- matrix(c(10, 24,
                              43, 41),ncol = 2)

oddsratio(contingency_table,
          alternative = "two.sided")
```

De uitvoer van de code voor dit voorbeeld toont een kansverhouding van $OR$ = 0,40 [0,17, 0,93].

### Risk Difference/Risico Verschil ($RD$) {#sec-rd}

Risicoverschil kan worden gebruikt om het verschil tussen twee verhoudingen te interpreteren. Als we de contingentietabel uit @tbl-contingency-OR gebruiken en een risicoverschil berekenen tussen de behandelgroep en de controlegroep. We kunnen eerst het aandeel berekenen van de gevallen waarin de uitkomst $Y=1$ is *binnen* de controlegroep en de behandelgroep:

$$
p_C=\frac{n_{C1}}{n_{C0}+n_{C1}}
$$

$$
p_T=\frac{n_{T1}}{n_{T0}+n_{T1}}
$$

Met behulp van deze verhoudingen kunnen we vervolgens het risicoverschil ($RD$) berekenen,

$$
RD = p_T - p_C.
$$

De bijbehorende standaardfout is,

$$
SE_{RD} = \sqrt{\frac{p_C(1-p_C)}{n_C} + \frac{p_T(1-p_T)}{n_T} }
$$

Waarbij $n_C$ en $n_T$ de totale steekproefgrootten *binnen* de controle- respectievelijk de behandelgroep zijn. De standaardfout kan dan worden gebruikt om de 95%-betrouwbaarheidsintervallen te berekenen,

$$
CI_{RD} = RD \pm 1.96 \times SE_{RD}
$$

De formule voor het verschil in risico is vrij eenvoudig, dus we kunnen deze berekenen met basis-R.

```{r, echo=TRUE}
# Bijvoorbeeld: 
# Experimentele groep: proportie gevallen = .5, sample size = 40
# Controle groep: proportie gevallen = .3, sample size = 45

pT <- .50
pC <- .30
nT <- 40
nC <- 45

RD <- pT - pC

SE <- sqrt( pC*(1-pC)/nC + pT*(1-pT)/nT )

# Bereken 95% CIs
RDlow <- RD - 1.96*SE
RDhigh <- RD + 1.96*SE

data.frame(
  RD = MOTE::apa(RD),
  RDlow = MOTE::apa(RDlow),
  RDhigh = MOTE::apa(RDhigh)
  )

```

### Relatieve Risico ($RR$) {#sec-rr}

Het relatieve risico, vaak de "risico ratio" genoemd, berekent de verhouding tussen het aantal gevallen in de behandelgroep en het aantal gevallen in de controlegroep. De interpretatie is eenvoudig: "individuen die de behandeling krijgen hebben een $RR$ hogere kans op het ervaren van de uitkomst in vergelijking met controles." Om het relatieve risico te berekenen, moeten we eerst de proportie uitkomstgevallen in de behandelings- en controlegroep berekenen

$$
p_C=\frac{n_{C1}}{n_{C0}+n_{C1}}
$$

$$
p_T=\frac{n_{T1}}{n_{T0}+n_{T1}}
$$

Dan kunnen we het relatieve risico berekenen,

$$
RR=\frac{p_T}{p_C}
$$

De bijbehorende standaardfout kan als volgt worden berekend,

$$
SE_{RR} = \sqrt{\frac{p_T}{n_T} + \frac{p_C}{n_C}}
$$

De betrouwbaarheidsintervallen kunnen worden berekend uit de standaardfout,

$$
CI_{RR} = RR\pm 1.96\times SE_{RR}
$$

Om het relatieve risico te berekenen, kunnen we eenvoudigweg de bovenstaande vergelijkingen gebruiken in basis R.

```{r, echo=TRUE}
# Bijvoorbeeld:
# Experimentele Groep: 10 ziek, 43 gezond, 53 totaal
# Controle Groep:  24 ziek, 41 gezond, 65 totaal

pT <- 10/(43+10)
pC <- 24/(41+24)
nT <- 53
nC <- 65

RR <- pT / pC

SE <- sqrt(pT/nT + pC/nC)

RRlow <- RR - 1.96*SE
RRhigh <- RR + 1.96*SE

# print pearson correlation and confidence intervals
data.frame(RR = MOTE::apa(RR), 
           RRlow = MOTE::apa(RRlow), 
           RRhigh = MOTE::apa(RRhigh))

```
